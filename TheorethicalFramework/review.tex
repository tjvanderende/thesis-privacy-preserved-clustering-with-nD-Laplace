\section{Literature review} \label{theory:literature-review}
In the search for related literature, we focused mainly on (L)DP mechanisms that can be used for general purposes (e.g. not only mean estimation), as this is the most comparable to our mechanism.
The related literature is divided into two parts:
\begin{enumerate}
  \item Differential privacy methods
  \item Cluster methods with (L)DP
\end{enumerate}
Afterward, we provide a summary for both in the form of a table.
This table includes components such as the type (LDP or DP) and whether there is a public code available.


\subsection{Differential privacy methods}
As was discussed in earlier sections, the Laplace method was the first one to establish \gls{dp} \citep{dwork_differential_2006}.

The first paper we discuss is provided by Soria-Comas et al. and considers the distribution of the dataset for the generating \citep{soria-comas_optimal_2013}.
Their work claims the Laplace mechanism is not optimal for a univariate function and aims at improving it by introducing their mechanism based on Laplace.
The method that is proposed performs slightly better than Laplace on multivariate/multiple queries.

Quan et al. also proposed a new method as an extension of Dwork et al.'s Laplace algorithm \citep{geng_staircase_2015}.
They introduced the staircase mechanism for 1-dimensional noise, which was later extended to support multidimensional data \citep{geng_staircase_2015}.
The mechanism aims to improve utility by adding the same level of privacy while adding less noise.
It is represented as a staircase-shaped probability density function, hence the name Staircase Mechanism (SM).
This mechanism accepts three configurable parameters, which are comparable to those of the Laplace mechanism.
The authors' work can handle multidimensional numerical data and preserve the  $(\epsilon$)-differential privacy, where $\epsilon$ is the privacy budget (see \ref{pure-dp}).
The previous two paragraphs, we have mainly focused on the literature that is interesting to us regarding differential privacy.
Next, the succeeding paragraphs will mainly center around related literature concerning local differential privacy.
%One disadvantage of the staircase mechanism is that it can produce an unbounded output, as noted by Wang et al. 
%This means that the perturbed data can exceed the original bounds of the data. 
%Additionally, the authors do not compare their results to comparable work in an experimental setting.

Another paper introduces a new local differential privacy (LDP) mechanism for working with numerical data \citep{nguyen_collecting_2016}
Their primary focus is on estimating means and frequencies, with a particular emphasis on machine learning techniques such as Support Vector Machines (SVM) and linear regression using Empirical Risk Minimization.
Initially, the authors analyze Duchi et al.'s method \citep{duchi_privacy_2013} and highlight several shortcomings.
To address these issues, they introduce Harmony as a mechanism for LDP perturbation.
This mechanism is be-able to perturb both categorical and numerical data and provides high accuracy for classification and regression tasks.
To compare Harmony to other methods they introduce the Hybrid Mechanism (HM), which is a combination of two existing methods for categorical and numerical data.
For this purpose they extend other work \citep{bassily_local_2015} for perturbing multidimensional categorical attributes and use Duchi et al.'s method for numerical data.
This allows them to compare their Harmony mechanism to the hybrid mechanism and measure the utility/accuracy differences.

Duchi et al. improved their method by proposing a formalization of the trade-off between statistical utility and (local) privacy, analyzing multiple types of estimation problems \citep{duchi_minimax_2017}.
Examples include mean, median, and density estimation.
To achieve this, they use minimax, a technique for finding the worst-case probability distribution.
Additionally, they focus on existing work and propose several optimization strategies for it.

Duchi et al.'s method was then extended by adding support for bounded and multidimensional data \citep{wang_collecting_2019}.
The authors introduce the Piecewise Mechanism (PM) to handle both numeric and categorical data and the Hybrid Mechanism (HM) which combines PM and Duchi et al.'s method for 1-dimensional data.
The effectiveness of their method is demonstrated using Support Vector Machines (SVM), linear regression, and mean estimation.
PM and HM are compared to Laplace and Duchi et al.'s solutions.
Optimized Unary Encoding (OUE) \citep{wang_locally_nodate} is also used for comparison, but for categorical data only, as this is not supported by the other methods.
% Instead of using the aforementioned techniques, categorical data is compared using frequency counting.


%\subsection{Geo-indistinguishability methods}
%\todo[inline]{Currently still work in progress}
\subsection{Cluster methods with (L)DP}
This chapter examines the various studies that have been conducted on clustering in combination with differential privacy.
Initially, we looked at the most fundamental papers in this field. Subsequently, the focus shifted toward researching well-known papers that have been published since 2020.

The first work we highlight was proposed by Nissim et al. and aims at improving differential privacy methods, such as Laplace, which uses sensitivity to compensate the noise for a function \citep{nissim_smooth_2007}.
In addition to compensating the function, they also consider the dataset itself.
The algorithm for this is called "smooth sensitivity" and is used for instance-specific noise.
To apply it, the authors introduce a method/framework to effectively calculate it.
To demonstrate the effectiveness of the method, they use K-means, among other cluster algorithms.
Their method requires the calculation of cluster distances, using Wasserstein distance instead of Euclidean distance.
%Although, it preserves $(\epsilon, \delta)$-LDP it does not provide any experiments with real world datasets.

Another study focuses on both interactive and non-interactive approaches for differential privacy in K-Means \citep{su_differentially_2015-1}.
The study builds upon the work that was done for DPLloyd, an interactive privacy extension of K-Means described by Blum et al. \citep{blum_practical_2005}.
The DPLLoyd mechanism partitions an n-dimensional dataset into a grid and releases the count for each grid by adding Laplacian noise to each count.
Another part of their research focuses on determining the width of the data cells.
The grid estimation method used in their research is called the extended uniform grid approach (EUG), and the complete K-Means method is called EUGkM.
The experiment consists of evaluating it against the DPLloyd mechanism, which performs better in an interactive setting.
Therefore, they combine their algorithm for combining both aspects into a hybrid approach (EUGkM + DPLloyd approach) and show a better final performance.

The study of Nissim et al. researches the idea of finding the smallest possible radius in the Euclidean space  $R^d$ for a set of $n$ points \citep{nissim_clustering_2018}.
They propose a new solution that uses locality-sensitive hashing (LSH) for differential privacy and use it to find 1-cluster in the $d$-dimensional Euclidean space.
This method works for differential privacy (LSH-GoodCenter), but they also extend this to the local model (LDP-GoodCenter).
The algorithm to find this radius is used to count the points enclosed by the radius and Laplace noise is added to the count to preserve differential privacy. The mechanism is combined and applied to work with the K-Means algorithm (LDP-K-Mean).
This mechanism was extended later in a paper proposed by Kaplan et al. and introduces a similar LDP method \citep{kaplan_differentially_2018}.
They aim to reduce the number of interactions needed between the server and users to one, instead of the $O(k\log n)$ required for Nissam et al.’s solution \citep{nissim_clustering_2018}.
To increase the success probability, they use the same idea but extend it to have multiple centers instead of a single large one.
They call it the LSH-Procedure and the algorithm Private-Centers is applied to generate centers to use with K-Means.
Then, they apply the same method to the LDP method that was also originally proposed by Nissam et al. (LDP-GoodCenter).
The most recent work by Stemmer et al. focuses on improving the work that was done by Kaplan et al. \citep{kaplan_differentially_2018,stemmer_locally_2021}.
Because the original mechanism has a higher additive error, which means the noise that is added introduces a lot of error.
To solve this, the authors aim at reducing this error by improving the original GoodCenter algorithm \citep{nissim_clustering_2018}.
Their extended method is called WeightedCenters and also adds weights to candidate centers.
%So, in addition to calculating the centroids for each iteration, it also calculates the weights for each.
In the final iteration, the weights are used to create the K-Means or K-Median clusters.

Sun et al. proposed a mechanism for distributed clustering using local differential privacy (LDP) to preserve distance-based information.
They claim to have the first non-interactive LDP algorithm for clustering \citep{su_differentially_2015-1}.
This means, they are being able to perturb the data locally at once and sent it to the server to cluster with both K-Means and DBSCAN.
They encode the client-side data into an anonymous hamming space using Bit Vector (BV) and modify the encoding to preserve Euclidean distance.
As their mechanism only shares distance information they were not able to use K-Means directly.
To overcome this, they modified the algorithm and called it K-Cluster.
Finally, the method is evaluated using Normalized Mutual Information (NMI) and Average Estimated Error (AEE).
%\todo[inline]{PrivBV}

Xia et al. noticed the shortcoming of Sun et al.'s work which is the need to share privacy-sensitive distance information \citep{xia_distributed_2020-1}.
Therefore, they propose a new interactive method for distributed K-means clustering using LDP.
The method converts features to binary strings and uses the Random Response mechanism (RR) to perturb each feature into a feature vector.
The privacy cost depends on the length of the bits of each feature transformation, meaning that a longer length yields more information at the cost of the privacy budget.
In each iteration, the serverside calculates and sends K-means centroids to each user, who recalculates distances until the centroids become stable.
The approach has the disadvantage of a high correlation between user data and the clusters.
To solve this problem, the algorithm is improved by having the client-side send not only the user data but also a set of random zero strings.
The server side then performs similar calculations to determine the true cluster.
Huang et al. propose a private distributed K-means clustering algorithm for interval data that addresses a shortcoming in Xia et al.'s work by using Condensed Local Differential Privacy (CLDP) for small-scale values and LDP for large-scale values \citep{9679364}.
They preserve distance using a Square Wave (SW) mechanism and apply a classical K-Means algorithm on the server side to the perturbed data.

A very recent mechanism that also builds around K-Means to preserve LDP, is called the LDPK mechanism \citep{yuan_privacypreserving_2021}.
As K-Means works only with numerical data, they use K-prototypes for supporting mixed data types.
The LDPK mechanism perturbs the user data first locally and interactively exchanges information with the server to complete the clustering process.
The mechanism they use for perturbation is the Harmony algorithm, which was proposed earlier by \citep{nguyen_collecting_2016}.
To also support categorical data the S-Hist method is used, which was also introduced by Nguyen et al.
But the author replaces this algorithm with OUE \citep{wang_locally_nodate} to improve accuracy.
Due to the correlation between the cluster centroids and the real data, the server could still infer the correct information.
Therefore, the authors also disturb the user’s cluster information with an extra extension to the LDPK method, called ELDPK.
To this end, they perturb the clusters with the GRR (Generalized Random Response) algorithm.
Their evaluation focuses on the privacy budget and the amount of data points.
They show that if the amount of data points increases the clustering quality does as well. \newline

Most existing work focuses on (L)DP in combination with K-Means.
Finally, two interesting studies focus on differential privacy for \gls{ap} or \gls{dbscan}.
A study conducted by Cai et al. focuses on \gls{ap} \citep{cai_dp-ap_2020}.
Their method involves adding Laplace noise to the responsibility matrix.
For each sample data, a neighborhood is specified using a radius around the data point.
This area is called the neighborhood density, and each sample point’s preference value is adjusted according to its density value.
Higher density yields a higher chance of belonging to a cluster center and then being ranked based on size.
The perturbed responsibility matrix and densities are combined and used to run AP.
They evaluated their method using the  \gls{ari}, Fowlkes-Mallows Index (FMI), and \gls{ami}.

Another recent study focuses on differential privacy for \gls{dbscan} \citep{bozdemir_privacy-preserving_nodate}.
The proposed solution involves clustering data between two or more parties using two servers.
Secure two-party computation (S2PC) is used to achieve this.
Using S2PC, both servers receive a random-looking secret share.
To recover the original data, both servers would need to combine their shares using S2PC, which combines the data without the servers having access to the full value.
The proposed protocol is named privacy-preserving \gls{dbscan} (ppDBSCAN).
The calculations in this study are based on squared Euclidean distance (SED) and are evaluated using different methods.
To evaluate the performance of ppDBSCAN, the study compares its Adjusted Rand Index (ARI) to that of K-means.

%\subsection{Summary}
%\todo[inline]{Short summary}
\begin{landscape}
  \begin{table}[ht]
    \centering
    \begin{adjustbox}{width=1.6\textwidth}
      \begin{tabular}{rlllllllll}
        \toprule
        year                                            & Name                                               & Data type                         & Dataset                                            & Code implementations                               & Preserving               & Type                & Interactive     & Methods                          \\
        \midrule
        2022 \citep{sun_privbv_2022}                    & PrivBV: Distance-aware encoding for distributed... & -                                 & Synthetic dataset                                  & -                                                  & ($\epsilon, \delta$)-LDP & K-Means             & Non interactive & -                                \\
        2021 \citep{9679364}                            & Private distributed K-means clustering on inter... & -                                 & -                                                  & -                                                  & LDP                      & K-Means             & Interactive     & -                                \\
        2021 \citep{stemmer_locally_2021}               & Locally Private k-Means Clustering                 & numerical                         & -                                                  & -                                                  & LDP                      & K-Means             & Interactive     & -                                \\
        2021 \citep{yuan_privacypreserving_2021}        & Privacy‐preserving mechanism for mixed data clu... & \shortstack{n-dimensional numeric                                                                                                                                                                                                                 \\ \& categorical} & Adult dataset, US Census dataset                   & -                                                  & LDP                      & K-Prototypes        & Interactive     & LDPK and ELDPK                            \\
        2021 \citep{bozdemir_privacy-preserving_nodate} & Privacy-preserving Density-based Clustering        & -                                 & Deer dataset, Lsun dataset, S1                     & -                                                  & DP                       & DBSCAN              & -               & ppDBSCAN                         \\
        2020 \citep{cai_dp-ap_2020}                     & DP-AP: Differential Privacy-Preserving Affinity... & -                                 & Iris dataset, Seeds dataset                        & -                                                  & DP                       & AffinityPropagation & -               & DP-AP                            \\
        2020 \citep{xia_distributed_2020-1}             & Distributed K-Means clustering guaranteeing loc... & n-dimensional numerical data      & 3D Road Network, CarGPS                            & -                                                  & LDP                      & K-Means             & Interactive     & LDPKmeans                        \\
        2019 \citep{sun_distributed_2019}               & Distributed Clustering in the Anonymized Space...  & n-dimensional numerical data      & Aggregation dataset, Digit dataset, Pathbased d... & -                                                  & LDP                      & DBSCAN, K-Means     & Non interactive & Distance Aware Bit Vector (DPBV) \\
        2018 \citep{nissim_clustering_2018}             & Clustering algorithms for the centralized and l... & n-dimensional numerical data      & -                                                  & -                                                  & ($\epsilon, \delta$)-LDP & K-Means             & Interactive     & LDP-GOODCenter                   \\
        2018 \citep{nissim_clustering_2018}             & Differentially private K-means with constant mu... & -                                 & -                                                  & -                                                  & -                        & K-Means             & Interactive     & LSH-Procedure \& Private-Centers \\
        2015 \citep{su_differentially_2015-1}           & Differentially Private k-Means Clustering          & 2 - 10-dimensional numerical data & Adult dataset, Gowalla dataset, Image dataset, ... & \footnote{https://github.com/DongSuIBM/PrivKmeans} & DP                       & K-Means             & Both            & EUGkM and hybrid EUGkM + DPLloyd \\
        %2011              & Differential privacy for location pattern mining                                                              & 2-dimensional geographical data      & Synthetic dataset with GPS trajectories            & -                                       & Differential privacy       & DBSCAN              & -               & DPQuadTree                                & -                                                                                                             \\
        2007 \citep{nissim_smooth_2007}                 & Smooth sensitivity and sampling in private data... & n-dimensional numeric             & -                                                  & -                                                  & ($\epsilon, \delta$)-LDP & K-Means             & Non interactive & Smooth sensitivity               \\
        \bottomrule
      \end{tabular}
    \end{adjustbox}
    \caption{Summary table of the literature review for (L)DP clustering algorithms.}
    \label{tab:summary_table_kmeans}
  \end{table}


  \begin{table}[ht]
    \centering
    \begin{adjustbox}{width=1.6\textwidth}

      \begin{tabular}{rllllllll}
        \toprule
        year                                & Name                                               & Data type                                          & Dataset & Code implementations                               & Preserving     & Interactive                 & Methods                                \\
        \midrule
        %2022                    & 3D Geo-Indistinguishability for Indoor Location... & 3-dimensional geographical data                    & -                                                  & -                                                  & Geo-indistinguishability   & Differential privacy method & -               & 3-dimensional Laplace mechanism & -                               \\
        %2019                    & Generalised Differential Privacy for Text Docum... & n-dimensional (?? data)                            & -                                                  & -                                                  & Differential privacy       & Differential privacy method & -               & n-dimensional Laplace mechanism & -                               \\
        2019 \citep{wang_collecting_2019}   & Collecting and Analyzing Multidimensional Data ... & n-dimensional (PM), but HM is 1-dimensional and... & BR, MR  & https://github.com/forestneo/sunPytools/blob/m...  & LDP            & -                           & \shortstack{- Piecewise Mechanism (PM) \\- Hybrid Mechanism (HM)}                         \\
        2017 \citep{duchi_minimax_2017}     & Minimax optimal procedures for locally private ... & 1-dimensional numerical data                       & -       & https://github.com/forestneo/sunPytools/blob/ma... & LDP            & -                           & -                                      \\
        2016 \citep{nguyen_collecting_2016} & Collecting and analyzing data from smart device... & numerical, binary and categorical data. Domain ... & BR      & -                                                  & $\epsilon$-LDP &                             & Harmony                                \\
        2015 \citep{geng_staircase_2015}    & The staircase mechanism in differential privacy    & n-dimensional numerical data                       & -       & https://github.com/IBM/differential-privacy-lib... & DP             & Differential privacy method & Staircase mechanism (SM)               \\
        2013 \citep{geng_optimal_2013}      & Optimal data-independent noise for differential... & n-dimensional                                      & -       & -                                                  & $\epsilon$-DP  & Non interactive             & -                                      \\
        %2012                    & Geo-indistinguishability: Differential privacy ... & 2-dimensional geographical data                    & -                                                  & -                                                  & Geo-indistinguishability   & Differential privacy method & -               & 2-dimensional Laplace mechanism & -                               \\
        \bottomrule
      \end{tabular}
    \end{adjustbox}
    \caption{Summary table of the literature review for (L)DP algorithms.}
    \label{tab:summary_table_dp}
  \end{table}
\end{landscape}

\begin{table}
  \centering
  \begin{adjustbox}{width=1\textwidth}

    \begin{tabular}{rllllll}
      \toprule
      number & name            & samples    & features                            & target                & Source                                          & Realworld data? \\
      \midrule
      1      & Adult           & 48,842     & 14 numerical/categorical/boolean    & income (>50k, <= 50k) & UCI                                             & Yes             \\
      2      & Seeds           & 210        & 7 numerical                         & type                  & UCI                                             & Yes             \\
      3      & Iris            & 150        & 4 numerical                         & class (type of iris)  & UCI                                             & Yes             \\
      4      & CarGPS          & 17,785,500 & 3 geographical data                 & -                     & -                                               & Yes             \\
      5      & 3D Road Network & 434,874    & 3 geographical data                 & -                     & -                                               & Yes             \\
      6      & Pathbased       & 300        & 2 numerical                         & ground truth clusters & PapersWithCode                                  & No              \\
      7      & Aggregation     & 788        & 2 numerical                         & -                     & -                                               & Unknown         \\
      8      & Digit           & 1797       & 8x8 numerical                       & number                & Scikit-learn                                    & Yes             \\
      9      & Lsun            & 400        & 2 numerical                         & ground truth clusters & -                                               & No              \\
      10     & S1              & 1500       & 2 numerical                         & ground truth clusters & -                                               & No              \\
      11     & Deer            & 20,033     & 2 numerical                         & -                     & -                                               & Yes             \\
      13     & Gowalla         & 6,442,890  & 5 (geographical data, ids and time) & -                     & https://snap.stanford.edu/data/loc-gowalla.html & Yes             \\
      \bottomrule
    \end{tabular}
  \end{adjustbox}
  \caption{The different datasets used in the related literature.}
  \label{tab:datasets}
\end{table}