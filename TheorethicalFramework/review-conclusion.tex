\subsection{Evaluation}
It is important to compare our kD-Laplace method with other studies for this research.
Studies that are similar to ours mainly utilize \gls{ldp} for clustering and add noise to cluster centroids \citep{xia_distributed_2020, yuan_privacypreserving_2021, 9679364}.
Or, require modifications of the K-Means algorithm \citep{sun_distributed_2019}.

As explained earlier, we aim to create a general-purpose \gls{ldp} mechanism that can be used with multiple clustering algorithms \ref{theory:literature-review:dp-clustering}.
\todo[inline]{a better clarification is needed,
  something like "Our methodology remains independent of the specific clustering algorithm chosen."}
Based on the literature study, two LDP mechanisms fall into this category: Harmony and Piecewise \citep{nguyen_collecting_2016, wang_collecting_2019}.
Published open-source code is available for Piecewise but, unfortunately, not for Harmony.
Therefore, we will only focus on the Piecewise mechanism as means of comparison material.
The following sections focus on investigating the Piecewise mechanism.
\todo[inline]{Last part, is not a good reason}

\subsubsection{Duchi et al.'s mechanism}
The Piecewise mechanism is based on Duchi et al.'s mechanism for one-dimensional data.
Therefore, we start by explaining this mechanism first.
Duchi et al.'s mechanism is a relatively simple method based on the Bernoulli distribution \citep{duchi_minimax_2017}.
This distribution yields either a 0 (negative) or a 1 (false) based on specified probabilities \footnote{https://mathworld.wolfram.com/BernoulliDistribution.html}.
The mechanism works on a domain tuple [-1, 1] and returns -1 or 1.
Hence, the \gls{pdf} of this function is as follows \footnote{https://mathworld.wolfram.com/BernoulliDistribution.html}:
\begin{equation}
  P(n) =
  \begin{cases}
    1 - p & \text{if } n = 0 \\
    p     & \text{if } n = 1
  \end{cases}
\end{equation}
The probabilities are calculated based on the input value and can then be used to estimate a mean value.
Compared to Laplace, Duchi et al. solution performs better in variance for epsilons smaller than 2 \citep{wang_collecting_2019}.
However, it performs worse when the epsilon value is higher because the algorithm does not consider the privacy budget for values that are 0.
The multidimensional variant looks like the one-dimensional version but samples each data point's noise independently.

\subsubsection*{Piecewise mechanism} \label{theory:piecewise}
The authors aim to create a method that combines the advantages of the Laplace mechanism and Duchi et al.'s methods \citep{wang_collecting_2019}.
The goal is to reduce the variance for a broader range of privacy budgets.
Like the mechanism above, the Piecewise mechanism only accepts data from -1 to 1.
We first explain the one-dimensional variant and then the multidimensional variant.

The mechanism for one-dimensional has an output of $c \in [-C, C]$.
Which is defined based on the privacy budget:
\begin{equation}
  C = \frac{exp(\epsilon/2)+1}{exp(\epsilon/2) - 1} \\
  \label{fig:piecewise-C}
\end{equation}
The noise is sampled from this distribution by conditionally executing one of two algorithms (see for reference Wang et al.'s paper) \citep{wang_collecting_2019}.
Due to the symmetric nature of their mechanism's \gls{pdf}, the authors can handle the value of 0.
Imagine it as a histogram with the distribution centered around 0. \todo[inline]{mathematical formula?}
The histogram consists of three "parts" on the left, right, and center (0).
This approach allows for determining the probability of 0 based on a certain likelihood, unlike Duchi et al.'s solution.

The authors generate a randomly sampled set of values $k$ for the multidimensional approach.
Next, for each value from $k$, the value is sampled using the one-dimensional Piecewise mechanism.
A critical factor in the overall calculation is the scale factor $C_d$, which, in addition to $C$ (referring to Equation \ref{fig:piecewise-C}), also considers the number of dimensions $d$.
Finally, the authors also provide an extension to support categorical data.


