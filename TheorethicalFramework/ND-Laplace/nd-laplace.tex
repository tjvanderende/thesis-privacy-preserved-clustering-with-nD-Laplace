\chapter{nD-Laplace}
In this chapter, we delve deeper into geo-indistinguishability and the various mechanisms that work with it, and aim to provide the theoretical foundation for research questions 1, 2 and 3.
We also explain the theory behind the nD-Laplace mechanism and how we modify it and apply it for clustering.
%This explanation is build-up out of several sections, each dedicated to 2, 3, and n-dimensional data.
Because we frequently discuss 2, 3, and dimensional data in our thesis, we decided to prefix the respective Laplace method with this information.
Therefore, for the rest of the thesis, we use the following names:
\begin{enumerate}
  \item 2D-Laplace: This refers to the planar Laplace mechanism \citep{DBLP:journals/corr/abs-1212-1984}.
  \item 3D-Laplace: This refers to the spherical Laplace mechanism \citep{9646489}.
  \item nD-Laplace: Also named like this, in the original paper \citep{fernandes_generalised_2019}.
  \item grid-nD-Laplace: This is a grid-remapping approach that is generalised for nD-Laplace.
  \item density-nD-Laplace: This is a density-remapping approach to provide an alternative to grid-nD-Laplace.
\end{enumerate}
The first three points are focused on the theory for our first research question. Here, we delve into the implementation of 2D-Laplace, 3D-Laplace and nD-Laplace. Subsequently, point 4 is centered on the theory for the second research question, which focuses on grid-nD-Laplace. Finally, we address the theory related to research question 3 for the density-nD-Laplace variant. Once all the theory has been covered, a summary will be provided along with an overview of the privacy framework.

\input{TheorethicalFramework/ND-Laplace/2d-laplace.tex}
\input{TheorethicalFramework/ND-Laplace/3d-laplace.tex}
\newpage
\section{nD-Laplace}
As mentioned in the previous chapter, the paper introduced by Min et al. can handle 3-dimensional data.
A small recap: a point $(r, \theta, \psi)$ gives us the three coordinates of a location on the 3-dimensional sphere.
An important property is that these coordinates can be generated separately \citep{DBLP:journals/corr/abs-1212-1984, 9646489}.
The $r$ gives us the distance from $(\theta, \psi)$ to the center of the sphere \footnote{https://mathworld.wolfram.com/SphericalCoordinates.html}.
So, instead of having just these two coordinates, we can extend this to n-dimensions by considering a hypersphere \citep{fernandes_generalised_2019, 9646489}.
The theorems for \gls{gi} are extended by Fernandes et al. to support n-dimensional data:
%To this end, in addition to points $\theta$ and $\psi$, we consider $\theta \in S^n$, where $S$ is a unit hypersphere.
\begin{theorem}
  Let $d_x$ be a pseudo-metric on $X$ and let $K: X \rightarrow Z$ be a mechanism satisfying $\epsilon-d_x-privacy$. \\
  $K(x)(Z) \leq e^{\epsilon \cdot d_x (x, x')} \cdot K(x')(Z) \ for \ all \ x, x' \in X, Z \subseteq X$.
  \label{theorem:nd-laplace}
\end{theorem}
Where $Z$ is a set of perturbed points generated from the original dataset $X$. 
For any two original datapoints $x$ and $x'$ the distance between them is limited at most $e^{-\epsilon \cdot d(x_0, x_0')}$. 
This theorem extends $\epsilon$-geo-indistinguishability to $\epsilon-d_x$-privacy as a more general notion of distinguishability \citep{fernandes_generalised_2019}:
Here, $d_x$ is a pseudo metric which was provided by Chatzikokalakis et al. as elastic privacy definition for location privacy \citep{chatzikokolakis_constructing_2015}. For the use with the Euclidean distance, the privacy definition is defined as $d_{euc}$. Due to the flexibility of $d_x$ the theorem \ref{theorem:nd-laplace} also holds for $d_{euc}$.  Furthermore, $\epsilon-d_{euc}$ provides the same privacy definition as geo-indistinguishability \citep{chatzikokolakis_constructing_2015}.
Therefore, $d_{euc}$ is adopted by this thesis from now on, to be used for applying it for non-geographical data to establish a more general notion of privacy. \newline

The 2D-Laplace mechanism is referenced as a plane, and the coordinates can be generated separately as $(r, \theta)$ \citep{fernandes_generalised_2019,DBLP:journals/corr/abs-1212-1984}.
Hence, generating the nD-variant can be seen as generating multiple $(r, \theta)$ pairs \citep{fernandes_generalised_2019}.
Where $r$ is the radial distance from the origin $x_0$ and $\theta$ is the angle randomly selected from a unit hypersphere.
The selection of $r$ is according to the Gamma distribution, with shape $n$ (dimensions) and scale $\delta > 0$ \citep{fernandes_generalised_2019}:
\begin{equation}
  Gam^n_\delta(r) := \frac{r^{n-1}\cdot e^{-\frac{r}{\delta}}}{\delta^n(n-1!)}
  \label{eq:generate_r_for_nd_laplace}
\end{equation}
Then, $\theta$ is drawn from an uniform distribution of a unit hypersphere $S$ \citep{fernandes_generalised_2019}:
\begin{equation}
  Uniform^n(\theta) := \frac{\gamma(\frac{n}{2})}{n \cdot \pi ^{\frac{n}{2}}}
  \label{eq:generate_theta_for_nd_laplace}
\end{equation}
Where $\gamma(a) = \int^\infty_0 x^{a-1} \cdot e^{-x} \ dx$ is the gamma function \citep{fernandes_generalised_2019}.
This approach is similar to the other variants of the Laplace mechanism.
Only now, we select points from an $n$-dimensional hypersphere  \footnote{https://mathworld.wolfram.com/SpherePointPicking.html} instead of a unit sphere \ref{eq:3d-laplace-2}. \newline

In the next step, the spherical coordinate representation is converted to Cartesian coordinates \citep{fernandes_generalised_2019}:
It is comparable to the way it was done in the previous chapters; however, as there are an $n$-amount of angles, the equation is repeated and slightly different.
The formula is provided by Fernandes et al. to convert $r$ to spherical coordinates \citep{fernandes_generalised_2019}:
\begin{align*}
  x_1 = r \cdot cos (\theta_1)                                          \\
  x_2 = r \cdot sin (\theta_1) \cdot cos (\theta_2)                         \\
  ... \\
  x_n = r \cdot sin(\theta_{n-1}) \cdot sin(\theta_{n-2}) \ ..., sin(\theta_{n-2} \cdot sin(\theta_{n-1})
  \label{eq:nd-laplace-cartesian}
\end{align*}
This formula is the same for the first two dimensions in comparison to 2D-Laplace and 3D-Laplace. After that, the conversion happens using the $sin$ for all $\theta$.

\subsubsection{Impact of dimensions} \label{theory:privacy-utility-nd}
When we specifically look at the \(uniform^n(\theta)\) function (see Equation: \ref{eq:generate_theta_for_nd_laplace}), the \(\theta\) can be generated \(n\)-times, but this has some limitation \citep{weisstein_hypersphere_nodate}.
The value of \(\theta\) decreases after the $\approx 7$ dimensions have been reached \citep{wells_penguin_1997}. Subsequently, the hyper-surface area reaches a maximum, so the value of $\theta$ decreases towards 0 \citep{weisstein_hypersphere_nodate}.
This behaviour is illustrated in the following figure:
\begin{figure}[H]
\centering
  \includesvg[width=0.8\textwidth]{TheorethicalFramework//ND-Laplace//Images/HypersphereArea_900.svg}
  \caption{Illustration of the decreasing hypersphere volume $S_n$ while increasing the number of dimensions \citep{weisstein_hypersphere_nodate}.}
  \label{fig:curse-of-dimensionality}
\end{figure}
As can be seen in the image, the amount of volume starts to decrease after the 7 dimensions . From this, it can be inferred that the value of  $\theta$ will also decrease. 
The consequence of this behavior is that the final noise decreases for higher dimensions. This will result in the possibility that utility increases in higher dimensions, but privacy decreases.
\newpage
\subsection{nD-Laplace truncation \label{section-grid-remapping}}
In the previous sections, we introduced the 2D-Laplace, 3D-Laplace, and nD-Laplace mechanisms and introduced truncation for 2D-Laplace and 3D-Laplace.
The current section will be used to formalize nD-Laplace with truncation, and also provide the theoretical groundwork for research question 2 (grid-remapping).

\subsubsection{Discretization and truncation} \label{theory:nd-laplace-truncation}
As mentioned from the previous sections. The discretized 2D version operates on a plane and approximates on a grid $G$, while the 3D version works in a sphere and approximates the data using a cuboid grid  $G_C$.

Given a set of non-private points $X$ and perturbed points $Z$ we can truncate the points that are outside the domain by remapping them to points such that $Z = X \cap G$ \citep{DBLP:journals/corr/abs-1212-1984}.
The following part aims at extending the theorems for 2D-Laplace and 3D-Laplace for truncation to n-dimensions.

The theorems for 2D (See Theorem \ref{theorem:discretization}) and 3D-Laplace (See Theorem \ref{theorem:3d-discretization}) include a device precision. 
This variable is the hardware precision of a GPS provided by the user's device (e.g. a mobile phone). 
For the purpose of clustering, we omit this for the formulation of truncation with n-dimensions. \newline

We build upon Min et al.'s rationale for the expansion from 2D-Laplace to 3D-Laplace, highlighting its relevance to nD-Laplace. 
Additionally, we reference the concept of the n-cube, an extension of the 3D cuboid, which is discussed further in detail in this source \footnote{https://mathworld.wolfram.com/Hypercube.html}.
This expansion allows us to define the n-cube as $G_n$, characterized by an $n$ number of sides. In contrast to the cuboid $G_c$, we maintain equal side lengths for the sake of simplicity.

The probability associated with a point $z$ belonging to $G_h$ can be expressed as follows, similar to how we previously did for 2D-Laplace and 3D-Laplace, as demonstrated in Equations \ref{eq:grid-probability} and \ref{eq:3d-grid-probability}:
\begin{equation}
R_h(x) = { y \in \mathbb{R}^+ \ | \ \forall x' \in G_h \cdot d_{euc}(y, x') \leq d_{euc}(y, x') }
\end{equation}
This can be interpreted as a region, denoted as $R_h$ around $x \in X$, in which we aim to preserve $\epsilon$-geo-indistinguishability \citep{9646489}.
Using this variant of nD-Laplace, the region $R_h$ can be expressed as a collection of acceptable report points $A$, where nD-Laplace uses $A_h$ \citep{DBLP:journals/corr/abs-1212-1984}.
The truncated nD-Laplace mechanism remaps points outside the diameter $diam(A)$ to the closest point $A_h \cap G_h$. 
Where the $diam(A_h) = r_{max}$ as the maximum allowed radial distance from $x_0$. \newline
Based on this, we define the theorem:
\begin{theorem}
Assume  $r_{max} = v$, where $v \in G_h$. Let $\epsilon \in R^+$ and $\epsilon' = \frac{\epsilon}{|G_h|}$ such that: \\
  $\epsilon' \leq \epsilon$ and $\epsilon = \sum_i{\epsilon'_i}$ \\
  Then $K_{\epsilon'}$ satisfies $\epsilon'-d_{euc}$-privacy in any area of diameter $r_{max}$, namely: \\ 
  $K_{\epsilon'}(x)(Z) \leq e^{\epsilon \cdot d_{euc} (x, x')} \cdot K_{\epsilon'}(x')(Z) \ for \ all \ x, x' \in X, Z \subseteq X$.  \\
  Whenever $d_{euc}(x, z)$ and $d_{euc}(x', z) \leq r_{max}$.
  \label{theorem:nd-laplace-truncation}
\end{theorem}
Given the above theorem, the privacy of a perturbed point $z$ outside an area $A \cap G_h$, can be remapped as:
\begin{equation}
z' = 
\begin{cases}
        z & \text{if} \ z \in A_h \cap G_h \\ 
        min (z, A_h \cap G_h)  & \text{if} \ z \notin A_h \cap G_h
    \end{cases}    
\end{equation}
The $min(z, A_h \cap G_h)$ indicates that we remap to the closest point in $A_h$ from the perturbed point $z$. Such that $d(x_0, z) \leq r_{max}$.  \newline
%\added{The truncated variant reduces the privacy of the mechanism, so we recalculate the $\epsilon$ based on the length of the grid unit, where $\epsilon' = \frac{1}{v}$ \citep{DBLP:journals/corr/abs-1212-1984}. } \newline
Now, let's present the proof, starting with a redefinition of the fundamentals of \gls{gi}, followed by a detailed explanation of the theorem. \newline

In the fundamentals of \gls{gi}, it is essential to ensure that the likelihood of reporting a point within a specific region around $z$ when the true locations are $x_0$ and $x_0'$ should only differ at most $e^{\epsilon \cdot d(x_0, x_0')}$ \citep{DBLP:journals/corr/abs-1212-1984}. This behaviour occurs when the noise function causes the probability of generating a point near $z$ to drop significantly as you move further from the true location $x_0$.
The area around $x_0$ is defined as the radius $r$, so according to \gls{gi} any point that is generated within this area preserves $\epsilon$-geo-indistinguishability. The probability of this, was expressed using an integral to represent the area between $\theta$ and $r$ \citep{DBLP:journals/corr/abs-1212-1984}:
\begin{equation}
    C_\epsilon(r) = \int^r_0 D_{\epsilon, R(p)dp}
\end{equation}
Where the integral represents the area of $r$, and $p$ is a random value between the original point $x_0$ and $r$. The $p$ is generated according to the earlier description we gave for 2D-Laplace (See Algorithm \ref{alg:2d-laplace}).

The proof of 2D-Laplace for \gls{gi} was provided by Andres et al., and was extended to 3D-Laplace and nD-Laplace by Min et al. and Fernandes et al., respectively. 
The latter, extended the proof for nD-Laplace by showing that nD-Laplace can be represented by selecting multiple spherical coordinates $(r, \theta)$ independently. Hence, the proof they provided is an extension of that of 2D-Laplace. In addition to considering the area of $r$ for a planar, they also consider the area for the angular coordinates over the hyper sphere \citep{fernandes_generalised_2019}. This is expressed as the product of two integrals.\newline

In light of this, we can demonstrate that the privacy assurance holds for $(r, \theta_v)$ across all sides (areas) $v \in G_h$. 
To establish this, we make the assumption that $r_{max} \leq v_n$ for every $v_n \in G_h$. 
Given the uniform grid-unit sizes of $G_h$, it suffices to state that $r_{max} \leq v$. 
The significance of the upper bound on $r_{max}$ is essential as it determines the region where $\epsilon$-geo-indistinguishability can be ensured \citep{DBLP:journals/corr/abs-1212-1984}. Consequently, the proof illustrates the existence of a suitable $\epsilon'$ based on $\epsilon$ and the step-unit $v$ that guarantees privacy for the region $r_{max}$.

Let us begin by revisiting the proof offered by Andres et al. for two-dimensional data, 
where the probability $S = R(z)$ in a two-dimensional space, and $r = d(x_0, z)$ \citep{DBLP:journals/corr/abs-1212-1984}:
\begin{equation}
     \int_{S} D_\epsilon(x_0)(z)ds \leq e^{\epsilon \cdot d(x_0, x_0')} \leq \int_{S} D_\epsilon(x_0')(z)ds
\end{equation}
The integral is employed to demonstrate that the condition holds within the plane or region $S$.

For $G_h$, we define the available locations as $A_h = R_n(z)$ within the n-dimensional space. As nD-Laplace extends the concepts of 2D-Laplace by allowing separate $(r, \theta_n)$ selections for each $n$ plane (area/side), the same principle can be extended to encompass every side of the region $A_h$:
\begin{equation}
    \int ... \int_{A_h} D_{\epsilon}(x)(z)d_{euc}A_h \leq e^{\epsilon \cdot d(x, x')} \leq \int ... \int_{A_h} D_{\epsilon}(x')(z)d_{euc}A_h
\end{equation}
Where we define the product of multiple integrals for each side of $A_h$.
To uphold the aforementioned conditions, three crucial steps are required:
\begin{enumerate}
\item \textbf{Selecting $r_{max}$:} We select $r_{max}$ as the diameter of $A_h$.
\item \textbf{Determining a new $r'$ for $z$:} We choose $r'$ such that $r' = d(x', z) \leq r_{max}$ to ensure that the coordinates fall within the region.
\item \textbf{Adapting $\epsilon$ for Closest Point Mapping: }To guarantee that the point $z$ is remapped to the closest point within $A_h$, we modify the value of $\epsilon$ to be the maximum value within the grid unit $v$. To achieve this, we apply theorem 3.2 by Andres et al., where they establish that multiple sampling also satisfies $\epsilon$-geo-indistinguishability when $\epsilon$ is the sum of individual $\epsilon_i$ values \citep{DBLP:journals/corr/abs-1212-1984}. As a result, the new epsilon value $\epsilon'$ based on the grid unit and original $\epsilon$, such that $\epsilon' = \frac{\epsilon}{|G_h|}$.
\end{enumerate}
Finally, based on this, we are be-able to preserve $\epsilon$-$d_{euc}$-privacy for the truncated variant $K = K^T$ using the modified privacy budget $\epsilon'$ within region $A_h$ \citep{9646489, DBLP:journals/corr/abs-1212-1984}.
Here $K = K^T$, where $K^T$ is the truncated variant of the probability $K$:
\begin{theorem}
    If $r_{max} \geq diam(A_h)$, \\
    then $K^T$ provides $\epsilon'-d_x$-privacy, namely \\
    $K^T(x)(Z) \leq e^{\epsilon' \cdot d_{euc} (x, x')} \cdot K^T(x')(Z)$  for all $x, x' \in A_h$. 
\end{theorem}
%\added{Let $R_h(x) = S_h$ be a region, which is a grid unit $v$ around $x_0$ of $G_h$ \citep{DBLP:journals/corr/abs-1212-1984}. The probability density of $S_h$ is differs at most by a factor $e^{\epsilon' \cdot v}$ \citep{9646489}.  Due to the way we select the spherical coordinates for each side separately, we define the probability density as a cumulative of each side: $n \cdot e^{\epsilon^ \cdot v}$, where $n$ is the amount of dimensions/sides of $G_h$.}
%\added{Given that $K$ is the probability of reporting the point $x$ when the actual point is $x_0$, it is defined on the region $R(x) = S$ as \citep{DBLP:journals/corr/abs-1212-1984}:
%\begin{equation}
%    K(x_0)(S) = \int_S D_\epsilon(x_0)(x)ds = K(x_0)(S) \leq e^{\epsilon \cdot d(x_0, x'_0} K(x'_0)(S)
%\end{equation}
%Notice that $S$ is in this instance a 2-dimensional region on a plane. If we extend this to n-dimensions, we define the product of multiple integrals for each side of $S_h$ \cite{9646489, DBLP:journals/corr/abs-1212-1984}:
%\begin{equation}
 %   \int ... \int_{S_h} D_{\epsilon'}(x_0)(x_1)d_{euc}s_h - P(r) \leq K(x_0)(x) \leq \int ... \int_{S_h} D_{\epsilon'}(x_0)(x_1)d_{euc}s_h + P(r)
%\end{equation}
%Where $r = d_{euc}(x_0, x)$ and the probability  $P(r) = n \cdot e^{\epsilon' \cdot v}$.  For the rest of the proof, we inherent the papers from 2D-Laplace and 3D-Laplace \citep{DBLP:journals/corr/abs-1212-1984, 9646489}.
%We do not consider the case where $x$ can be projected outside $G_h$ due to the finite precision. Therefore, the %proof for truncation is inherent by the proof provided above. }

%\added{Also, $r_{max}$ and $\epsilon'$ are selected based on theorem \ref{theorem:nd-laplace-truncation}.}
%Where $A$ are acceptable locations from the region $R(x)$, and where $(r, \theta)$ is remapped to the closest point $x$ on $A \cap G_h$}. 
%The truncated variant of $K$ is then defined as $K^T_{\epsilon'} \rightarrow A \cap G_h $ for the $n$-dimensional variant
Finally, we omit the proof for clustering since it is considered a post-processing step. Data generated using the mechanism proven to provide $d_x$-privacy also provides it for post-processing \citep{feyisetan_leveraging_2019}. 
%While increasing the number of grid cells might enhance utility, it also leads to a notable rise in space complexity. 
%Moreover, as the number of dimensions grows, the count of grid cells increases quadratically.
\newpage
\subsubsection{Putting it together: nD-Laplace}
Now that we have defined everything, we can write the algorithm in a step-by-step manner:
\input{TheorethicalFramework/ND-Laplace/algorithms/nd-laplace.tex}
This algorithm is utilized in this research in two ways:
\begin{enumerate}
    \item We use nD-Laplace without truncation, as part of research question 1.
    \item We use the truncation with nD-Laplace, which we call grid-nD-Laplace for research question 2.
\end{enumerate}

The utility of grid-nD-Laplace depends on the number of grid cells in $G_n$ since a smaller distance will result in more frequent mapping to the surface of the grid.
When $\epsilon$ is very low (resulting in $z$ being much farther away from $x_0$), data points have a higher likelihood of mapping to map to the grid surface 
(as seen in \ref{fig:3d-laplace-noise}, \ref{fig:3d-laplace-example}). 
An alternative approach is therefore density remapping, which will be explained in the next section.
\newpage
\subsection{Density remapping} \label{theory:optimal-remapping}
As discussed, the remapping will be performance intensive to provide good utility, so we adopt the optimal remapping \citep{chatzikokolakis_efficient_2017}.
This thesis will refer to this as density remapping because this better explains the application \added{for clustering}.

According to the grid-remapping methodology, a private point $z$ is mapped to the center of the grid cell.
The utility is improved by reducing the distance between $z$ and $x$, as this is closer to the original data point.
But, to consider the privacy of the data, this can only be done if there is enough indistinguishability between $z$ and $x$.
To this end, we adopt the remapping approach of Chatzikokolakis et al. to remap based on the data density \citep{chatzikokolakis_efficient_2017}.
The remapping algorithm works on the idea of crowded places, with the intuition that a crowded place leverages indistinguishability by crowdedness (density) \citep{chatzikokolakis_efficient_2017}.  \newline

The approach is visualized using the following figure:
\begin{figure}[H]
  \includesvg{TheorethicalFramework/ND-Laplace/Images/master-thesis-Page-12.svg}
  \label{fig:optimal-remapping}
  \caption{Representation of density remapping \citep{chatzikokolakis_efficient_2017}}
\end{figure}
The first step is calculating $B_r(z)$, which refers to all the data points within the radius $r$ around the data point $z_i$ \citep{chatzikokolakis_efficient_2017}.
Then, the algorithm collects the data points around $x_i$, again using $r$, to determine the density of $x_i$.
This is the convex hull (collection) of all the original data points within the radius $r$ around $x_i$ and is denoted as $Q_r (x)$.
Finally, we obtain $Q_r$ which is a union of $Q_r (x)$ and $B_r(z)$.
Now that we have the sets of points around $x_i$ and $z_i$, we can calculate the density \citep{chatzikokolakis_efficient_2017}:
\begin{equation}
  \forall x' \in Q_r \quad \sigma(x) = \frac{w(x')e^{-\epsilon d(x'_i, z_i)}}{\sum{_{q\in Q_r} w(q)e^{-\epsilon d(q, z)}}}
  \label{eq:optimal-remapping-formula-1}
\end{equation}
$w(q)$ is the weight of a point $q \in Q_r$, and $w(x_i)$ the weight of a point $x_i \in X$.
Here, the weight can be a point of interest \citep{chatzikokolakis_efficient_2017}.
But, in the context of our study, we consider the points within $r$ of $q$ or $x_i$ to be the weight.

In equation \ref{eq:optimal-remapping-formula-1}, the $w(x)$ and $w(q)$ are normalization factors for estimating the likelihood of a point $x'$ being close to $z_i$ and $q$ being close to $z$.
So, this remapping is according to the original definition of the 2D Laplace \gls{pdf} definition \ref{eq:polar-laplace-pdf}.
The outcome of the formula is a collection of values that indicate the degree of density $\sigma(x)$.
The new value $z'$ is calculated by taking the mean of the $\sigma(x)$ \citep{chatzikokolakis_efficient_2017}:
\begin{equation}
  z' = \sum_{x' \in Q_r} \sigma(x') * x'
  \label{eq:optimal-remapping-formula-2}
\end{equation}
By applying this formula, the new $z'$ is closer to $x$ to minimize the expected loss of utility \citep{chatzikokolakis_efficient_2017}.
Much like the 2D and 3D Laplace methods, which use the likelihood of a point $z$ being close to $x$ \citep{DBLP:journals/corr/abs-1212-1984, 9646489}.

%The first step is to calculate the coefficients for each point $x \in X$ by multiplying the density $\sigma(x)$ with the original point $x$.

%The probability that $z'$ will be closer to $x$ is higher, and this probability is calculated based on the original value $x \in X$ to first determine the coefficient.
%Finally, the new $z'$ is calculated by taking the mean value of $\sigma(x)$ \citep{chatzikokolakis_efficient_2017}.
%As described by chatzikokolakis et al., the 
%Chatzikokolakis et al's work considers a prior set of data point $Q \in R^n$.
%Which are other data points that belong to the user.
%We are interested in the data points that are within the radius $r$ around $z$.
%This is denoted as $B_r(z)$, which is the vector of all points within radius $r$ around $z$.
%In addition to this, there is also a $Q_r$ that is a convex hull of all nearby points.
%Hence, this is described as $Q_r = B_r \cap Q$.
%The final intuition here is that $r$ is automatically generated based on crowdedness (see circle inside figure \ref{fig:optimal-remapping}).
%The last step is to take the mean value of $\sigma(x)$.
%Unfortunately, optimal remapping is not possible for users that do not have sufficient data (e.g. new users).
%The remapping is not applied for these users and is also not applied for $z$ if it is within the domain of $X$.
\input{TheorethicalFramework/ND-Laplace/algorithms/optimal-remapping.tex}

It is important to note that with the introduction of this algorithm, it is no longer a non-interactive method, as the data points now interact with each other.
Due to the extra interaction rounds, we expect the introduction of density grid remapping with kd-tree will bring more utility \citep{wang_comprehensive_2020, xiongComprehensiveSurveyLocal2020}.
If this proofs to be true, it might out-weights the privacy implications for clustering.  \newline

While density remapping can improve utility, the task of searching for points within spatial data is inherently complex. Density remapping requires numerous queries to find nearby points, which can lead to significant computational costs. In the next section, we introduce an optimization method to address this challenge.

\subsubsection{Optimization}
To make optimal-remapping practically possible with n-dimensions, the data structure has to be more efficient to search spatial data. For this purpose, we adopt the idea proposed by Chatzikokolakis et al. of using a kd-tree to search the grid efficiently \citep{chatzikokolakis_efficient_2017}.
Their research describes the theoretical utilization of a kd-tree for searching nearby points for a given point.
For this reason:
\begin{enumerate}
    \item     We use the kd-tree to find nearby points $x$ to remap within $X \cap G_h$.
    \item We aim to apply this practically by using a kd-tree for finding nearby points for $x \in X$ and $z \in Z$ (Section: \ref{theory:optimal-remapping}). 
\end{enumerate}
The usage of kd-tree does not impact any privacy guarantee provided in the previous section. It is just a more efficient way of searching in n-dimensional spatial structures. Also, for visualization purposes, this section will primarily focus on 2D data. \newline
The next section explains the concept and underlying idea of kd-trees.
Then, we delve into its application for grid remapping.
Finally, we expand this to a practical application with nD-Laplace.

\subsubsection*{Kd-trees} \label{theory:kd-trees}
A kd-tree algorithm can search a grid for nearby points \citep{bentley_multidimensional_1975}.
It can do so by recursively splitting the grid into a binary tree to search for grid coordinates \citep{washington_k-d_2002}.
In addition, it preserves spatial information of the data so it can be utilized to find nearby points using Euclidean distance (nearest neighbor search).
The following example provides an idea of how this works (Figure \ref{fig:kd-tree-theory}):
\begin{figure}[H]
  \includegraphics[width=0.8\textwidth]{TheorethicalFramework/ND-Laplace/Images/kd-tree-part1.png}
  \caption{Representation of constructing a kd-tree with 2 dimensions \citep{washington_k-d_2002}.}
  \label{fig:kd-tree-theory}
\end{figure}
Take, for example, the 2D Laplace algorithm that utilizes a plane (left side).
The data points can be divided based on their x and y coordinates.
Each coordinate becomes a node in the binary tree, and the grid is divided based on these splits.
The binary tree allows us to search the grid efficiently.
An example of this is provided in the following image (Figure \ref{fig:kd-tree-searching-theory}):
\begin{figure}[H]
  \includegraphics[width=0.8\textwidth]{TheorethicalFramework/ND-Laplace/Images/kd-tree-part2.png}
  \caption{Representation of searching a kd-tree with 2 dimensions \citep{washington_k-d_2002}.}
  \label{fig:kd-tree-searching-theory}
\end{figure}
In the example, we are searching for all points that fall within the radius of a random query point.
The most significant advantage is that this dramatically reduces the complexity of searching.
Constructing the kd-tree costs equal to grid-remapping $O(kn)$, where $k$ is the number of dimensions and $n$ is the dataset size.
But, searching for the nearest neighbor is a logarithmic function with time complexity of $O(\log n)$ \citep{washington_k-d_2002}.
This approach is a significant improvement over searching manually, which would have the same complexity as constructing the tree.

\todo[inline]{What to do with this section?}
\subsubsection{Grid-remapping with kd-tree} \label{theory:grid-remapping}
The kd-tree search method is beneficial for the optimizations we are striving for.
This optimization extends grid-remapping for 2D \citep{DBLP:journals/corr/abs-1212-1984} and 3D data \citep{9646489} to n-dimensions. \newline
We have illustrated the three steps required for this below:
\begin{figure}[H]
  \includegraphics[width=1\textwidth]{TheorethicalFramework/ND-Laplace/Images/KD-tree.png}
  \caption{Representation utilizing a kd-tree for applying grid-remapping \citep{DBLP:journals/corr/abs-1212-1984}}
  \label{fig:kd-tree}
\end{figure}
%When using a kd-tree to search for a data point $z_i$, the algorithm begins with an unbalanced binary tree.
%The root is split by the x-axis, and since 4.5 is greater than 3.5, we go to the right.
%This means that we no longer need to consider the left (greyed out) part of the grid.
%We continue traversing the tree until we find the nearest point based on Euclidean distance.
For easy visualization, the process shown above is with 2-dimensional data.
However, this can be extended to n-dimensional using the kd-tree optimization.
The goal is to remap a perturbed point $z \in Z$, outside the original domain $X$, to the closest point in $X$ or $G$ \citep{DBLP:journals/corr/abs-1212-1984}.

Firstly, a grid is generated, where each (blue) point represents the center of a grid cell.
Together, these centroids form the grid dataset, denoted as $G$.
The yellow points and $x_i$ are part of the original collection, denoted as $X$.
Here, $r$ represents the radius used to generate a private version of the data point $x_i$, named $z_i$, based on 2D-Laplace.
In the illustration, you can observe that $z_i$ falls outside the original domain of $X$, so it needs to be remapped.
We accomplish this by utilizing the nearest-neighbor search from the kd-tree algorithm, allowing us to search in $X \cup G$.
Using this algorithm, we can effectively remap point $z \in Z$ to either $X$ or $G$ based on the closest Euclidean distance (Algorithm \ref{alg:grid-remapping-laplace} and Algorithm \ref{alg:find-outside-domain-laplace}).

A dataset with little dispersion in the data is remapped to the grid regardless of the data shape. 
Generating a grid with sufficiently small grid units to account for this would still result in too much complexity. 
Therefore, in the next chapter, we will look at a variant that addresses this issue.

\todo[inline]{Clarify the algorithms (see others)}
\input{TheorethicalFramework/ND-Laplace/algorithms/outside-domain.tex}
\input{TheorethicalFramework/ND-Laplace/algorithms/generating-meshgrid-and-remap.tex}
%\todo[inline]{Also refactor this}

%\subsection{Extending to $d_x$-privacy}
%\todo[inline]{Find if this is possible}

%Constructing elastic distinguishability metrics for location privacy

\input{TheorethicalFramework/ND-Laplace/mechanism-design.tex}
