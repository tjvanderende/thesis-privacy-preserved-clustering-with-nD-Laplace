\chapter{Conclusion}
This thesis has explored the answer on the question: "How can the nD-Laplace mechanism be applied in training privacy-preserving clustering algorithms on distributed n-dimensional data?".
To answer this question, we conducted multiple experiments based on the research questions.
For practical relevance and to gauge our mechanism's performance, we compared our experiments with the Piecewise mechanism, another approach to differential privacy.
The research questions have been addressed as follows: \newline
\textbf{RQ1: How can the 2D-Laplace, 3D-Laplace, and nD-Laplace approaches be adapted to train privacy-preserving clustering algorithms?} \newline
We compared three clustering algorithms: K-Means, \gls{ami}, and \gls{optics}, and analyzed the impact of nD-Laplace and Piecewise.
We evaluated internal and external validity and compared these results with the Piecewise mechanism
From this, it can be concluded that the nD-Laplace mechanism scores the highest for the lower privacy budgets (< 9). 
When weighing privacy and utility against each other, the nD-Laplace mechanism performs better than Piecewise. 
The K-Means algorithm scores the highest utility, followed by \gls{ag}. This is consistent for all experiments, but Piecewise scores better for \gls{optics} in comparison to nD-Laplace.
\newline

\textbf{RQ2: How can the noise generated by nD-Laplace outside the data boundary be remapped to inside the data domain?} \newline
For lower privacy budgets, remapping to a grid has been found to minimize the potential leakage of data information to attackers.
In addition, grid-nD-Laplace performs comparably to nD-Laplace, and the extension provides a more stable result.
\textbf{RQ3: How do dataset characteristics impact the nD-Laplace mechanism for utility and privacy?} \newline
This research question is addressed through three hypotheses: \newline
\begin{itemize}
	\item H1: The shape of the data negatively impacts the nd-Laplace mechanism in terms of privacy and utility:
	The shape of the data strongly influences the nD-Laplace mechanism.
        As a result, the mechanism shows better utility on datasets that have a uniform distribution, such as the heart, skewed, and seed-dataset, compared to a dataset that follows a fixed shape, like the Circle and Line datasets.
        This same result is also reflected in the comparison of the clustering algorithms and the performance between nD-Laplace and the Piecewise mechanism.
	\item H2: The privacy leakage (membership advantage) and utility increases for more dimensions:
	      For the seeds-dataset and heart-dataset, a slightly higher utility is measurable for the highest two dimensions of the two datasets. 
       This has no impact on the \gls{tpr}.
            For the other experiments, there isn't a clear influence of the number of dimensions. However, privacy distance increases as the number of dimensions also increases.
	\item H3: Adding remapping based on density improves utility without sacrificing privacy:
	      As previously explained, datasets with a distinct shape have a negative impact on the utility of the nD-Laplace mechanism.
            The density-nD-Laplace mechanism does not offer any improvement and scores similarly to the nD-Laplace mechanism. 
            Therefore, it can be concluded that this variant does not deliver the hoped-for utility improvements.
\end{itemize}

Ultimately, this research has shown that the nD-Laplace mechanism can be used for privacy-preserved training of algorithms on n-dimensional data.
In this context, the mechanism outperforms the comparable Piecewise mechanism on datasets with a uniform distribution of data, by providing much more utility for lower privacy budgets.
Furthermore, the grid-nD-Laplace extension for the nD-Laplace mechanism offers the necessary protection for lower privacy budgets. As a result, the mechanism displays more stable results compared to the Piecewise mechanism. \newline

The findings of this research have significant implications for the field of privacy-preserving data analysis.
This thesis presents a new take on evaluating privacy mechanisms using real-world data and attacks.
In conclusion, our findings provide a solid foundation for future research and have the potential to drive advancements in the field of privacy-preserving data analysis.


