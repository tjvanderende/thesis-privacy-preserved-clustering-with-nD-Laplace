\chapter{Discussion}
For each result, we have included an interpretation and discussion. This section summarizes these findings and suggests future research directions.
Our study involved a series of experiments to assess the utility and privacy attributes of the nD-Laplace mechanism in comparison to the Piecewise mechanism. We employed five datasets in our analysis, two of which are real-world datasets: seeds-dataset and heart-dataset. The remaining three, Circle, Line, and Skewed, are synthetic datasets crafted to evaluate the performance of nD-Laplace.

Our initial focus was on the utility of three clustering algorithms: K-Means, \gls{ag}, and \gls{optics}. We then delved deeper to discern the disparities between the Piecewise mechanism and nD-Laplace, examining both in terms of utility—using internal (\gls{sc}) and external (\gls{ami}) validation—and privacy, with an emphasis on metrics like membership advantage and \gls{tpr}. A subsequent experiment incorporated the variants of nD-Laplace, using the same evaluation metrics.

To ensure reproducibility, our research was conducted using Jupyter notebook. We also employed a version control system (git) to store all datasets, safeguarding against any external alterations that might skew the results. For robustness, each experiment was repeated 10 times, and the average result was considered. 

Our findings underline the significant influence of the privacy budget on the utility and privacy of nD-Laplace. As the privacy budget increases, utility improves, but at the cost of reduced privacy. This observation is consistent with existing literature \citep{sun_distributed_2019, xia_distributed_2020, 9679364}. \newline

In comparing nD-Laplace with the Piecewise mechanism, it was clear that nD-Laplace excelled with the heart-dataset, seeds-dataset, and skewed dataset, particularly when evaluated using K-Means and \gls{ag} clustering \gls{ami} scores. However, its performance was subpar for the line-dataset and circle dataset. Also, the \gls{optics} yielded a notably low \gls{ami} score.

Dimensionality had a marginal effect on the utility and privacy for the seeds and heart-dataset. The most significant outcome was observed for the top two dimensions, which demonstrated a minor increase in \gls{ami}, suggesting enhanced utility with increased dimensions.  This might be due to our observation for the hypersphere volume (See Section: \ref{theory:privacy-utility-nd}), where we stated the possibility of a increased utility for 7 > dimensions. This would need further investigation to tell for sure.
Also, the enhancement in utility did not translate to a corresponding increase in privacy. \newpage

In our concluding experiments, we delved into the details of the nD-Laplace mechanism by examining its variants: grid-nD-Laplace and density-nD-Laplace. The primary objective of these variants is to ensure that data processed by nD-Laplace remains confined within its original domain.

Drawing from existing literature, we recognized the criticality of employing a remapping or truncation method. Without such a method, data with a low epsilon value risks being plotted outside its original domain. This deviation can potentially provide attackers with an advantage, enabling them to infer whether the data is part (member) of the original dataset.

Our empirical findings agreed on these findings. Specifically, when operating with a constrained privacy budget, we observed a clear drop in membership advantage, plummeting to values even lower than -50. While this decline was anticipated, its magnitude was surprising. A deeper dive revealed that this steep decline could be attributed to the membership advantage metric itself, which, as highlighted in our literature review, has certain inherent limitations. Contrary to the pattern suggested by the membership advantage, the underlying \gls{tpr} was considerably high, especially unexpected for a lower privacy budget. This anomaly was notably absent, or at least less pronounced, in the nD-Laplace variants. 

The high \gls{tpr} for lower privacy budgets can be attributed to the fact that, for an epsilon value of 0.5, data points were plotted significantly outside the original domain. Our empirical findings thus emphasize the necessity, also echoed in the literature, of addressing this issue. Both nD-Laplace and Piecewise mechanisms would likely exhibit these shortcomings in practical settings.

The two variants, grid-nD-Laplace and density-nD-Laplace, have demonstrated their capability to mitigate this issue in practice. Grid-nD-Laplace, in particular, showcased more stable results, with its privacy and utility metrics aligning closely with those of nD-Laplace. We introduced density-nD-Laplace to address the nD-Laplace mechanism's sensitivity to data shapes. However, it fell short in practice, particularly with the Line and Circle datasets.

\section{Constraints}
We encountered challenges with \gls{optics} clustering algorithm.
Our analysis revealed a higher number of clusters for \gls{optics} compared to K-Means and \gls{ag}. Additionally, a significant portion of data points were labeled as noise. This suggests potential issues with the configuration of \gls{optics}, particularly the $minPts$ parameter. Despite these configuration issues, the Piecewise mechanism still outperformed nD-Laplace in certain scenarios, likely due to its ability to handle dense data shapes.
% \todo[inline]{Selection of features for 2d/3d heart-dataset \& seedsdataset might have impact}
\section{Future work}
The nD-Laplace mechanism, based on our findings, holds promise for clustering applications. While it showcases distinct advantages and disadvantages compared to the Piecewise mechanism, there's room for improvement, especially in handling diverse data forms. To further its practical applicability, we propose the following research directions:

\begin{enumerate}
\item \textbf{Examine diverse data shapes}: nD-Laplace's practicality hinges on its adaptability to various data shapes. Given its current limitations with certain datasets, directed noise introduction, as opposed to uniform noise distribution, might offer a solution.
\item \textbf{Dimensionality in synthetic datasets}: Our current study limits dimensionality to 7 and 9 for certain datasets. Expanding this to higher dimensions, especially for synthetic datasets, could provide deeper insights.
\item \textbf{Explore higher dimensions}: With observed improvements in utility beyond 7 dimensions, it's worth investigating data with 20+ dimensions .
\item \textbf{Incorporate categorical and binary data}: Enhancing nD-Laplace to support these data types, similar to the Piecewise mechanism, can broaden its practical applicability. 
\end{enumerate}

