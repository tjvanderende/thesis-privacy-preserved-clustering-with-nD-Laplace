@article{9646489,
  title = {{{3D}} Geo-Indistinguishability for Indoor Location-Based Services},
  author = {Min, Minghui and Xiao, Liang and Ding, Jiahao and Zhang, Hongliang and Li, Shiyin and Pan, Miao and Han, Zhu},
  year = {2022},
  journal = {IEEE Transactions on Wireless Communications},
  volume = {21},
  number = {7},
  pages = {4682--4694},
  doi = {10.1109/TWC.2021.3132464},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\QPJZTQGX\\Min e.a. - 2022 - 3D geo-indistinguishability for indoor location-ba.pdf}
}

@inproceedings{9679364,
  title = {Private Distributed {{K-means}} Clustering on Interval Data},
  booktitle = {2021 {{IEEE}} International Performance, Computing, and Communications Conference ({{IPCCC}})},
  author = {Huang, D. and Yao, X. and An, S. and Ren, S.},
  year = {2021},
  month = oct,
  pages = {1--9},
  publisher = {{IEEE Computer Society}},
  address = {{Los Alamitos, CA, USA}},
  doi = {10.1109/IPCCC51483.2021.9679364},
  abstract = {K-means clustering has been heavily employed to mine valuable insights from interval data. Nevertheless, serious privacy leakage concerns are stumbling blocks impeding its widespread application. To quantify the privacy of small and large-scale interval data, we introduce two notions of \&amp;\#x03B1;-Condensed Local Differential Privacy and \&amp;\#x03F5;-Local Differential Privacy, and propose two distance-aware perturbation mechanisms of \&amp;\#x03B1;-exponential and square wave mechanisms. Rigorous theoretical analysis proves that our proposed mechanisms satisfy these two privacy notions. The experimental results built on multiple synthesized and real datasets show that our proposed mechanisms can provide more accurate clustering results than prior work, such as Randomized Response, Generalized Randomized Response, and Optimized Local Hash.},
  keywords = {conferences,correlation,differential privacy,distributed databases,perturbation methods,privacy},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\6F8LBU8D\\Huang e.a. - 2021 - Private distributed K-means clustering on interval.pdf}
}

@misc{alvim_metric-based_2018,
  title = {Metric-Based Local Differential Privacy for Statistical Applications},
  author = {Alvim, M{\'a}rio S. and Chatzikokolakis, Konstantinos and Palamidessi, Catuscia and Pazii, Anna},
  year = {2018},
  month = may,
  number = {arXiv:1805.01456},
  eprint = {arXiv:1805.01456},
  publisher = {{arXiv}},
  abstract = {Local differential privacy (LPD) is a distributed variant of differential privacy (DP) in which the obfuscation of the sensitive information is done at the level of the individual records, and in general it is used to sanitize data that are collected for statistical purposes. LPD has the advantage it does not need to assume a trusted third party. On the other hand LDP in general requires more noise than DP to achieve the same level of protection, with negative consequences on the utility. In practice, utility becomes acceptable only on very large collections of data, and this is the reason why LDP is especially successful among big companies such as Apple and Google, which can count on a huge number of users. In this paper, we propose a variant of LDP suitable for metric spaces, such as location data or energy consumption data, and we show that it provides a much better utility for the same level of privacy.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Cryptography and Security},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\ZP2CTPQW\\Alvim e.a. - 2018 - Metric-based local differential privacy for statis.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\FDNJ3E7E\\1805.html}
}

@inproceedings{bozdemir_privacy-preserving_2021-2,
  title = {Privacy-Preserving {{Density-based Clustering}}},
  booktitle = {Proceedings of the 2021 {{ACM Asia Conference}} on {{Computer}} and {{Communications Security}}},
  author = {Bozdemir, Beyza and Canard, S{\'e}bastien and Ermis, Orhan and M{\"o}llering, Helen and {\"O}nen, Melek and Schneider, Thomas},
  year = {2021},
  month = may,
  pages = {658--671},
  publisher = {{ACM}},
  address = {{Virtual Event Hong Kong}},
  doi = {10.1145/3433210.3453104},
  abstract = {Clustering is an unsupervised machine learning technique that outputs clusters containing similar data items. In this work, we investigate privacy-preserving density-based clustering which is, for example, used in financial analytics and medical diagnosis. When (multiple) data owners collaborate or outsource the computation, privacy concerns arise. To address this problem, we design, implement, and evaluate the first practical and fully private density-based clustering scheme based on secure two-party computation. Our protocol privately executes the DBSCAN algorithm without disclosing any information (including the number and size of clusters). It can be used for private clustering between two parties as well as for private outsourcing of an arbitrary number of data owners to two non-colluding servers. Our implementation of the DBSCAN algorithm privately clusters data sets with 400 elements in 7 minutes on commodity hardware. Thereby, it flexibly determines the number of required clusters and is insensitive to outliers, while being only factor 19x slower than today's fastest private K-means protocol (Mohassel et al., PETS'20) which can only be used for specific data sets. We then show how to transfer our newly designed protocol to related clustering algorithms by introducing a private approximation of the TRACLUS algorithm for trajectory clustering which has interesting real-world applications like financial time series forecasts and the investigation of the spread of a disease like COVID-19.},
  isbn = {978-1-4503-8287-8},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\QADFI8Z5\\Bozdemir e.a. - 2021 - Privacy-preserving Density-based Clustering.pdf}
}

@inproceedings{cai_dp-ap_2020,
  title = {{{DP-AP}}: {{Differential Privacy-Preserving Affinity Propagation Clustering}}},
  shorttitle = {{{DP-AP}}},
  booktitle = {2020 {{IEEE}} 14th {{International Conference}} on {{Big Data Science}} and {{Engineering}} ({{BigDataSE}})},
  author = {Cai, Hanbo and Wang, Jinyan and Liu, Xiaohong and Li, Xianxian},
  year = {2020},
  month = dec,
  pages = {73--79},
  publisher = {{IEEE}},
  address = {{Guangzhou, China}},
  doi = {10.1109/BigDataSE50710.2020.00018},
  isbn = {978-1-66540-396-2},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\LH7Y4ZSA\\Cai e.a. - 2020 - DP-AP Differential Privacy-Preserving Affinity Pr.pdf}
}

@article{calinski_dendrite_1974,
  title = {A {{Dendrite Method}} for {{Cluster Analysis}}},
  author = {Cali{\'n}ski, Tadeusz and JA, Harabasz},
  year = {1974},
  month = jan,
  journal = {Communications in Statistics - Theory and Methods},
  volume = {3},
  pages = {1--27},
  doi = {10.1080/03610927408827101}
}

@article{chen_new_2023,
  title = {A {{New Density Peak Clustering Algorithm With Adaptive Clustering Center Based}} on {{Differential Privacy}}},
  author = {Chen, Hua and Zhou, Yuan and Mei, Kehui and Wang, Nan and Cai, Guangxing},
  year = {2023},
  journal = {IEEE Access},
  volume = {11},
  pages = {1418--1431},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2022.3233196},
  abstract = {A new density peak clustering (DPC) algorithm with adaptive clustering center based on differential privacy was proposed to solve the problems of poor adaptability of high-dimensional data, inability to automatically determine clustering centers, and privacy problems in clustering analysis. First, to solve the problem of poor adaptability of high-dimensional data, cosine distance was used to measure the similarity between high-dimensional datasets. Then, aiming at the subjective problem of clustering center selection, from the perspective of ranking graph, the weight \$(i-1)/i\$ was introduced creatively, the slope trend of ranking graph was redefined to realize the adaptive clustering center. Finally, aiming at the privacy problem, the Laplacian noise of appropriate privacy budget was added to the core statistic (local density) of the algorithm to achieve the balance between privacy protection and algorithm effectiveness. Experimental results on both the synthetic and UCI datasets show that this algorithm can not only realize the automatic selection of clustering center, but also solve the privacy problem in clustering analysis, and improve the clustering evaluation index greatly, which proves the effectiveness of the algorithm.},
  keywords = {Clustering algorithms,Cosine distance,differential privacy,Differential privacy,DPC algorithm,Laplace equations,Laplacian noise,Noise measurement,Partitioning algorithms,Privacy,Statistical analysis,trend of slope change},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\4ZCXBXQI\\Chen e.a. - 2023 - A New Density Peak Clustering Algorithm With Adapt.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\IVJ96UNU\\stamp.html}
}

@inproceedings{chen_private_2016,
  title = {Private Spatial Data Aggregation in the Local Setting},
  booktitle = {2016 {{IEEE}} 32nd {{International Conference}} on {{Data Engineering}} ({{ICDE}})},
  author = {Chen, Rui and Li, Haoran and Qin, A. K. and Kasiviswanathan, Shiva Prasad and Jin, Hongxia},
  year = {2016},
  month = may,
  pages = {289--300},
  publisher = {{IEEE}},
  address = {{Helsinki, Finland}},
  doi = {10.1109/ICDE.2016.7498248},
  abstract = {With the deep penetration of the Internet and mobile devices, privacy preservation in the local setting has been an increasing demand in many real-life applications. The local setting refers to the scenario where a user trusts nobody else and is willing to share his/her information only if it has been properly sanitized before leaving his/her own device. Moreover, a user may hold only a single data element to share, instead of a database. Despite its ubiquitousness, the above facts make the local setting substantially more challenging than the traditional centralized or distributed settings.},
  isbn = {978-1-5090-2020-1},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\U4JU224L\\Chen e.a. - 2016 - Private spatial data aggregation in the local sett.pdf}
}

@inproceedings{cormode_privacy_2018,
  title = {Privacy at {{Scale}}: {{Local Differential Privacy}} in {{Practice}}},
  shorttitle = {Privacy at {{Scale}}},
  booktitle = {Proceedings of the 2018 {{International Conference}} on {{Management}} of {{Data}}},
  author = {Cormode, Graham and Jha, Somesh and Kulkarni, Tejas and Li, Ninghui and Srivastava, Divesh and Wang, Tianhao},
  year = {2018},
  month = may,
  pages = {1655--1658},
  publisher = {{ACM}},
  address = {{Houston TX USA}},
  doi = {10.1145/3183713.3197390},
  abstract = {Local differential privacy (LDP), where users randomly perturb their inputs to provide plausible deniability of their data without the need for a trusted party, has been adopted recently by several major technology organizations, including Google, Apple and Microsoft. This tutorial aims to introduce the key technical underpinnings of these deployed systems, to survey current research that addresses related problems within the LDP model, and to identify relevant open problems and research directions for the community.},
  isbn = {978-1-4503-4703-7},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\JMVXWKRW\\Cormode e.a. - 2018 - Privacy at Scale Local Differential Privacy in Pr.pdf}
}

@article{DBLP:journals/corr/abs-1212-1984,
  title = {Geo-Indistinguishability: {{Differential}} Privacy for Location-Based Systems},
  author = {Andr{\'e}s, Miguel E. and Bordenabe, Nicol{\'a}s Emilio and Chatzikokolakis, Konstantinos and Palamidessi, Catuscia},
  year = {2012},
  journal = {CoRR},
  volume = {abs/1212.1984},
  eprint = {1212.1984},
  archiveprefix = {arxiv},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/journals/corr/abs-1212-1984.bib},
  timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\HVVT4GUR\\Andrés e.a. - 2012 - Geo-indistinguishability Differential privacy for.pdf}
}

@misc{de_cristofaro_overview_2020,
  title = {An {{Overview}} of {{Privacy}} in {{Machine Learning}}},
  author = {De Cristofaro, Emiliano},
  year = {2020},
  month = may,
  number = {arXiv:2005.08679},
  eprint = {arXiv:2005.08679},
  publisher = {{arXiv}},
  abstract = {Over the past few years, providers such as Google, Microsoft, and Amazon have started to provide customers with access to software interfaces allowing them to easily embed machine learning tasks into their applications. Overall, organizations can now use Machine Learning as a Service (MLaaS) engines to outsource complex tasks, e.g., training classifiers, performing predictions, clustering, etc. They can also let others query models trained on their data. Naturally, this approach can also be used (and is often advocated) in other contexts, including government collaborations, citizen science projects, and business-to-business partnerships. However, if malicious users were able to recover data used to train these models, the resulting information leakage would create serious issues. Likewise, if the inner parameters of the model are considered proprietary information, then access to the model should not allow an adversary to learn such parameters. In this document, we set to review privacy challenges in this space, providing a systematic review of the relevant research literature, also exploring possible countermeasures. More specifically, we provide ample background information on relevant concepts around machine learning and privacy. Then, we discuss possible adversarial models and settings, cover a wide range of attacks that relate to private and/or sensitive information leakage, and review recent results attempting to defend against such attacks. Finally, we conclude with a list of open problems that require more work, including the need for better evaluations, more targeted defenses, and the study of the relation to policy and data protection efforts.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Computers and Society,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\TWI5HZGS\\De Cristofaro - 2020 - An Overview of Privacy in Machine Learning.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\K66U9F5M\\2005.html}
}

@article{del_rey_comprehensive_2020,
  title = {A {{Comprehensive Survey}} on {{Local Differential Privacy}}},
  author = {Xiong, Xingxing and Liu, Shubo and Li, Dan and Cai, Zhaohui and Niu, Xiaoguang},
  editor = {Del Rey, Angel M.},
  year = {2020},
  month = oct,
  journal = {Security and Communication Networks},
  volume = {2020},
  pages = {8829523},
  publisher = {{Hindawi}},
  issn = {1939-0114},
  doi = {10.1155/2020/8829523},
  abstract = {With the advent of the era of big data, privacy issues have been becoming a hot topic in public. Local differential privacy (LDP) is a state-of-the-art privacy preservation technique that allows to perform big data analysis (e.g., statistical estimation, statistical learning, and data mining) while guaranteeing each individual participant\&\#x2019;s privacy. In this paper, we present a comprehensive survey of LDP. We first give an overview on the fundamental knowledge of LDP and its frameworks. We then introduce the mainstream privatization mechanisms and methods in detail from the perspective of frequency oracle and give insights into recent studied on private basic statistical estimation (e.g., frequency estimation and mean estimation) and complex statistical estimation (e.g., multivariate distribution estimation and private estimation over complex data) under LDP. Furthermore, we present current research circumstances on LDP including the private statistical learning/inferencing, private statistical data analysis, privacy amplification techniques for LDP, and some application fields under LDP. Finally, we identify future research directions and open challenges for LDP. This survey can serve as a good reference source for the research of LDP to deal with various privacy-related scenarios to be encountered in practice.}
}

@book{dridi_unsupervised_2021,
  title = {Unsupervised {{Learning}} - {{A Systematic Literature Review}}},
  author = {Dridi, Salim},
  year = {2021},
  month = dec,
  doi = {10.13140/RG.2.2.16963.12323}
}

@misc{duchi_local_2014,
  title = {Local {{Privacy}}, {{Data Processing Inequalities}}, and {{Statistical Minimax Rates}}},
  author = {Duchi, John C. and Jordan, Michael I. and Wainwright, Martin J.},
  year = {2014},
  month = aug,
  number = {arXiv:1302.3203},
  eprint = {arXiv:1302.3203},
  publisher = {{arXiv}},
  abstract = {Working under a model of privacy in which data remains private even from the statistician, we study the tradeoff between privacy guarantees and the utility of the resulting statistical estimators. We prove bounds on information-theoretic quantities, including mutual information and Kullback-Leibler divergence, that depend on the privacy guarantees. When combined with standard minimax techniques, including the Le Cam, Fano, and Assouad methods, these inequalities allow for a precise characterization of statistical rates under local privacy constraints. We provide a treatment of several canonical families of problems: mean estimation, parameter estimation in fixed-design regression, multinomial probability estimation, and nonparametric density estimation. For all of these families, we provide lower and upper bounds that match up to constant factors, and exhibit new (optimal) privacy-preserving mechanisms and computationally efficient estimators that achieve the bounds.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Information Theory,Mathematics - Statistics Theory},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\QYKGI68J\\Duchi e.a. - 2014 - Local Privacy, Data Processing Inequalities, and S.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\IW73UGSV\\1302.html}
}

@article{dwork_calibrating_nodate,
  title = {Calibrating {{Noise}} to {{Sensitivity}} in {{Private Data Analysis}}},
  author = {Dwork, Cynthia and McSherry, Frank and Nissim, Kobbi and Smith, Adam},
  abstract = {We continue a line of research initiated in [10, 11] on privacypreserving statistical databases. Consider a trusted server that holds a database of sensitive information. Given a query function f mapping databases to reals, the so-called true answer is the result of applying f to the database. To protect privacy, the true answer is perturbed by the addition of random noise generated according to a carefully chosen distribution, and this response, the true answer plus noise, is returned to the user.},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\C63GKYIP\\Dwork e.a. - Calibrating Noise to Sensitivity in Private Data A.pdf}
}

@article{dwork_our_2006,
  title = {Our {{Data}}, {{Ourselves}}: {{Privacy Via Distributed Noise Generation}}},
  author = {Dwork, Cynthia and Kenthapadi, Krishnaram and McSherry, Frank and Mironov, Ilya and Naor, Moni},
  year = {2006},
  journal = {Advances in Cryptology - EUROCRYPT 2006},
  pages = {486--503},
  publisher = {{Springer Berlin Heidelberg}},
  issn = {0302-9743},
  doi = {10.1007/11761679_29}
}

@inproceedings{erlingsson_rappor_2014-1,
  title = {{{RAPPOR}}: {{Randomized Aggregatable Privacy-Preserving Ordinal Response}}},
  shorttitle = {{{RAPPOR}}},
  booktitle = {Proceedings of the 2014 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  author = {Erlingsson, {\'U}lfar and Pihur, Vasyl and Korolova, Aleksandra},
  year = {2014},
  month = nov,
  pages = {1054--1067},
  publisher = {{ACM}},
  address = {{Scottsdale Arizona USA}},
  doi = {10.1145/2660267.2660348},
  abstract = {Randomized Aggregatable Privacy-Preserving Ordinal Response, or RAPPOR, is a technology for crowdsourcing statistics from end-user client software, anonymously, with strong privacy guarantees. In short, RAPPORs allow the forest of client data to be studied, without permitting the possibility of looking at individual trees. By applying randomized response in a novel manner, RAPPOR provides the mechanisms for such collection as well as for efficient, high-utility analysis of the collected data. In particular, RAPPOR permits statistics to be collected on the population of client-side strings with strong privacy guarantees for each client, and without linkability of their reports.},
  isbn = {978-1-4503-2957-6},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\YYTD4TLN\\Erlingsson e.a. - 2014 - RAPPOR Randomized Aggregatable Privacy-Preserving.pdf}
}

@article{ester_density-based_nodate,
  title = {A {{Density-Based Algorithm}} for {{Discovering Clusters}} in {{Large Spatial Databases}} with {{Noise}}},
  author = {Ester, Martin and Kriegel, Hans-Peter and Xu, Xiaowei},
  abstract = {Clusteringalgorithmasreattractivefor the taskof classidentification in spatial databases.Howevetrh, e applicationto large spatial databasesrises the followingrequirementfsor clustering algorithms: minimalrequirementsof domain knowledgteo determinethe input parameters,discoveryof clusters witharbitraryshapeandgoodefficiencyonlarge databases. Thewell-knowcnlusteringalgorithmsoffer nosolution to the combinatioonf theserequirementsI.n this paper, wepresent the newclustering algorithmDBSCAreNlying on a density-basednotionof clusters whichis designedto discoverclusters of arbitrary shape.DBSCrAeNquiresonly one input parameterandsupportsthe user in determiningan appropriatevaluefor it. Weperformeadn experimentaelvaluation of the effectiveness and efficiency of DBSCAusNing synthetic data and real data of the SEQUO2IA000benchmark.Theresults of our experimentsdemonstratethat (1) DBSCiAsNsignificantlymoreeffective in discoveringclusters of arbitrary shapethan the well-knowanlgorithmCLARANS,and that (2) DBSCAoNutperforms CLARANbyS factorof morethan100in termsof efficiency.},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\D68L5F4R\\Ester e.a. - A Density-Based Algorithm for Discovering Clusters.pdf}
}

@article{fahad_survey_2014,
  title = {A {{Survey}} of {{Clustering Algorithms}} for {{Big Data}}: {{Taxonomy}} and {{Empirical Analysis}}},
  shorttitle = {A {{Survey}} of {{Clustering Algorithms}} for {{Big Data}}},
  author = {Fahad, Adil and Alshatri, Najlaa and Tari, Zahir and Alamri, Abdullah and Khalil, Ibrahim and Zomaya, Albert Y. and Foufou, Sebti and Bouras, Abdelaziz},
  year = {2014},
  month = sep,
  journal = {IEEE Transactions on Emerging Topics in Computing},
  volume = {2},
  number = {3},
  pages = {267--279},
  issn = {2168-6750},
  doi = {10.1109/TETC.2014.2330519},
  abstract = {Clustering algorithms have emerged as an alternative powerful meta-learning tool to accurately analyze the massive volume of data generated by modern applications. In particular, their main goal is to categorize data into clusters such that objects are grouped in the same cluster when they are similar according to specific metrics. There is a vast body of knowledge in the area of clustering and there has been attempts to analyze and categorize them for a larger number of applications. However, one of the major issues in using clustering algorithms for big data that causes confusion amongst practitioners is the lack of consensus in the definition of their properties as well as a lack of formal categorization. With the intention of alleviating these problems, this paper introduces concepts and algorithms related to clustering, a concise survey of existing (clustering) algorithms as well as providing a comparison, both from a theoretical and an empirical perspective. From a theoretical perspective, we developed a categorizing framework based on the main properties pointed out in previous studies. Empirically, we conducted extensive experiments where we compared the most representative algorithm from each of the categories using a large number of real (big) data sets. The effectiveness of the candidate clustering algorithms is measured through a number of internal and external validity metrics, stability, runtime, and scalability tests. In addition, we highlighted the set of clustering algorithms that are the best performing for big data.},
  keywords = {Algorithm design and analysis,big data,Big data,Clustering algorithms,Clustering methods,Neural networks,Partitioning algorithms,Taxonomies,unsupervised learning},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\BJSQU8PU\\Fahad e.a. - 2014 - A Survey of Clustering Algorithms for Big Data Ta.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\8AUACR48\\stamp.html}
}

@techreport{gates_impact_2017,
  type = {Preprint},
  title = {The {{Impact}} of {{Random Models}} on {{Clustering Similarity}}},
  author = {Gates, Alexander J. and Ahn, Yong-Yeol},
  year = {2017},
  month = oct,
  institution = {{Bioinformatics}},
  doi = {10.1101/196840},
  abstract = {Clustering is a central approach for unsupervised learning. After clustering is applied, the most fundamental analysis is to quantitatively compare clusterings. Such comparisons are crucial for the evaluation of clustering methods as well as other tasks such as consensus clustering. It is often argued that, in order to establish a baseline, clustering similarity should be assessed in the context of a random ensemble of clusterings. The prevailing assumption for the random clustering ensemble is the permutation model in which the number and sizes of clusters are fixed. However, this assumption does not necessarily hold in practice; for example, multiple runs of K-means clustering returns clusterings with a fixed number of clusters, while the cluster size distribution varies greatly. Here, we derive corrected variants of two clustering similarity measures (the Rand index and Mutual Information) in the context of two random clustering ensembles in which the number and sizes of clusters vary. In addition, we study the impact of one-sided comparisons in the scenario with a reference clustering. The consequences of different random models are illustrated using synthetic examples, handwriting recognition, and gene expression data. We demonstrate that the choice of random model can have a drastic impact on the ranking of similar clustering pairs, and the evaluation of a clustering method with respect to a random baseline; thus, the choice of random clustering model should be carefully justified.},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\WAATUPMF\\17-039.pdf}
}

@inproceedings{ho_differential_2011,
  title = {Differential Privacy for Location Pattern Mining},
  booktitle = {Proceedings of the 4th {{ACM SIGSPATIAL International Workshop}} on {{Security}} and {{Privacy}} in {{GIS}} and {{LBS}} - {{SPRINGL}} '11},
  author = {Ho, Shen-Shyang and Ruan, Shuhua},
  year = {2011},
  pages = {17},
  publisher = {{ACM Press}},
  address = {{Chicago, Illinois}},
  doi = {10.1145/2071880.2071884},
  abstract = {One main concern for individuals to participate in the data collection of personal location history records is the disclosure of their location and related information when a user queries for statistical or pattern mining results derived from these records. In this paper, we investigate how the privacy goal that the inclusion of one's location history in a statistical database with location pattern mining capabilities does not substantially increase one's privacy risk. In particular, we propose a differentially private pattern mining algorithm for interesting geographic location discovery using a region quadtree spatial decomposition to preprocess the location points followed by applying a density-based clustering algorithm. A differentially private region quadtree is used for both de-noising the spatial domain and identifying the likely geographic regions containing the interesting locations. Then, a differential privacy mechanism is applied to the algorithm outputs, namely: the interesting regions and their corresponding stay point counts. The quadtree spatial decomposition enables one to obtain a localized reduced sensitivity to achieve the differential privacy goal and accurate outputs. Experimental results on synthetic datasets are used to show the feasibility of the proposed privacy preserving location pattern mining algorithm.},
  isbn = {978-1-4503-1032-1},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\TF8DSXWE\\Ho en Ruan - 2011 - Differential privacy for location pattern mining.pdf}
}

@article{hubert_comparing_1985,
  title = {Comparing Partitions},
  author = {Hubert, Lawrence and Arabie, Phipps},
  year = {1985},
  month = dec,
  journal = {Journal of Classification},
  volume = {2},
  number = {1},
  pages = {193--218},
  issn = {1432-1343},
  doi = {10.1007/BF01908075},
  abstract = {The problem of comparing two different partitions of a finite set of objects reappears continually in the clustering literature. We begin by reviewing a well-known measure of partition correspondence often attributed to Rand (1971), discuss the issue of correcting this index for chance, and note that a recent normalization strategy developed by Morey and Agresti (1984) and adopted by others (e.g., Miligan and Cooper 1985) is based on an incorrect assumption. Then, the general problem of comparing partitions is approached indirectly by assessing the congruence of two proximity matrices using a simple cross-product measure. They are generated from corresponding partitions using various scoring rules. Special cases derivable include traditionally familiar statistics and/or ones tailored to weight certain object pairs differentially. Finally, we propose a measure based on the comparison of object triples having the advantage of a probabilistic interpretation in addition to being corrected for chance (i.e., assuming a constant value under a reasonable null hypothesis) and bounded between {$\pm$}1.},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\WLYYQR86\\Hubert en Arabie - 1985 - Comparing partitions.pdf}
}

@inproceedings{Hung2014MapR,
  title = {Map / Reduce Affinity Propagation Clustering Algorithm},
  author = {Hung, Wei-Chih and Chu, Chu and Wu, Yi-Leh and Tang, Cheng-Yuan},
  year = {2014}
}

@inproceedings{jagannathan_privacy-preserving_2005,
  title = {Privacy-Preserving Distributed k-Means Clustering over Arbitrarily Partitioned Data},
  booktitle = {Proceeding of the Eleventh {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery in Data Mining  - {{KDD}} '05},
  author = {Jagannathan, Geetha and Wright, Rebecca N.},
  year = {2005},
  pages = {593},
  publisher = {{ACM Press}},
  address = {{Chicago, Illinois, USA}},
  doi = {10.1145/1081870.1081942},
  abstract = {Advances in computer networking and database technologies have enabled the collection and storage of vast quantities of data. Data mining can extract valuable knowledge from this data, and organizations have realized that they can often obtain better results by pooling their data together. However, the collected data may contain sensitive or private information about the organizations or their customers, and privacy concerns are exacerbated if data is shared between multiple organizations.},
  isbn = {978-1-59593-135-1},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\A64MLK72\\Jagannathan en Wright - 2005 - Privacy-preserving distributed k-means clustering .pdf}
}

@inproceedings{jagannathan_privacy-preserving_2005-1,
  title = {Privacy-{{Preserving Distributed}} k-{{Means Clustering}} over {{Arbitrarily Partitioned Data}}},
  booktitle = {Proceedings of the {{Eleventh ACM SIGKDD International Conference}} on {{Knowledge Discovery}} in {{Data Mining}}},
  author = {Jagannathan, Geetha and Wright, Rebecca N.},
  year = {2005},
  series = {{{KDD}} '05},
  pages = {593--599},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1081870.1081942},
  abstract = {Advances in computer networking and database technologies have enabled the collection and storage of vast quantities of data. Data mining can extract valuable knowledge from this data, and organizations have realized that they can often obtain better results by pooling their data together. However, the collected data may contain sensitive or private information about the organizations or their customers, and privacy concerns are exacerbated if data is shared between multiple organizations.Distributed data mining is concerned with the computation of models from data that is distributed among multiple participants. Privacy-preserving distributed data mining seeks to allow for the cooperative computation of such models without the cooperating parties revealing any of their individual data items. Our paper makes two contributions in privacy-preserving data mining. First, we introduce the concept of arbitrarily partitioned data, which is a generalization of both horizontally and vertically partitioned data. Second, we provide an efficient privacy-preserving protocol for k-means clustering in the setting of arbitrarily partitioned data.},
  isbn = {1-59593-135-X}
}

@misc{kairouz_discrete_2016,
  title = {Discrete {{Distribution Estimation}} under {{Local Privacy}}},
  author = {Kairouz, Peter and Bonawitz, Keith and Ramage, Daniel},
  year = {2016},
  month = jun,
  number = {arXiv:1602.07387},
  eprint = {arXiv:1602.07387},
  publisher = {{arXiv}},
  abstract = {The collection and analysis of user data drives improvements in the app and web ecosystems, but comes with risks to privacy. This paper examines discrete distribution estimation under local privacy, a setting wherein service providers can learn the distribution of a categorical statistic of interest without collecting the underlying data. We present new mechanisms, including hashed K-ary Randomized Response (KRR), that empirically meet or exceed the utility of existing mechanisms at all privacy levels. New theoretical results demonstrate the order-optimality of KRR and the existing RAPPOR mechanism at different privacy regimes.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\PBZBTBFP\\Kairouz e.a. - 2016 - Discrete Distribution Estimation under Local Priva.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\L2QAECMV\\1602.html}
}

@misc{kasiviswanathan_what_2010-1,
  title = {What {{Can We Learn Privately}}?},
  author = {Kasiviswanathan, Shiva Prasad and Lee, Homin K. and Nissim, Kobbi and Raskhodnikova, Sofya and Smith, Adam},
  year = {2010},
  month = feb,
  number = {arXiv:0803.0924},
  eprint = {arXiv:0803.0924},
  publisher = {{arXiv}},
  abstract = {Learning problems form an important category of computational tasks that generalizes many of the computations researchers apply to large real-life data sets. We ask: what concept classes can be learned privately, namely, by an algorithm whose output does not depend too heavily on any one input or specific training example? More precisely, we investigate learning algorithms that satisfy differential privacy, a notion that provides strong confidentiality guarantees in contexts where aggregate information is released about a database containing sensitive information about individuals. We demonstrate that, ignoring computational constraints, it is possible to privately agnostically learn any concept class using a sample size approximately logarithmic in the cardinality of the concept class. Therefore, almost anything learnable is learnable privately: specifically, if a concept class is learnable by a (non-private) algorithm with polynomial sample complexity and output size, then it can be learned privately using a polynomial number of samples. We also present a computationally efficient private PAC learner for the class of parity functions. Local (or randomized response) algorithms are a practical class of private algorithms that have received extensive investigation. We provide a precise characterization of local private learning algorithms. We show that a concept class is learnable by a local algorithm if and only if it is learnable in the statistical query (SQ) model. Finally, we present a separation between the power of interactive and noninteractive local learning algorithms.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Computational Complexity,Computer Science - Cryptography and Security,Computer Science - Databases,Computer Science - Machine Learning},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\F5SAVJU9\\Kasiviswanathan e.a. - 2010 - What Can We Learn Privately.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\6NB4M2QB\\0803.html}
}

@inproceedings{keller_balancing_2021,
  title = {Balancing {{Quality}} and {{Efficiency}} in {{Private Clustering}} with {{Affinity Propagation}}:},
  shorttitle = {Balancing {{Quality}} and {{Efficiency}} in {{Private Clustering}} with {{Affinity Propagation}}},
  booktitle = {Proceedings of the 18th {{International Conference}} on {{Security}} and {{Cryptography}}},
  author = {Keller, Hannah and M{\"o}llering, Helen and Schneider, Thomas and Yalame, Hossein},
  year = {2021},
  pages = {173--184},
  publisher = {{SCITEPRESS - Science and Technology Publications}},
  address = {{Online Streaming, --- Select a Country ---}},
  doi = {10.5220/0010547801730184},
  abstract = {In many machine learning applications, training data consists of sensitive information from multiple sources.},
  isbn = {978-989-758-524-1},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\ITIR5ZT3\\Keller e.a. - 2021 - Balancing Quality and Efficiency in Private Cluste.pdf}
}

@inproceedings{kolluri_private_2021,
  title = {Private {{Hierarchical Clustering}} in {{Federated Networks}}},
  booktitle = {Proceedings of the 2021 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  author = {Kolluri, Aashish and Baluta, Teodora and Saxena, Prateek},
  year = {2021},
  month = nov,
  pages = {2342--2360},
  publisher = {{ACM}},
  address = {{Virtual Event Republic of Korea}},
  doi = {10.1145/3460120.3484822},
  isbn = {978-1-4503-8454-4},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\UL7WF2U2\\Kolluri e.a. - 2021 - Private Hierarchical Clustering in Federated Netwo.pdf}
}

@inproceedings{kwatra_k-anonymised_2022,
  title = {A K-{{Anonymised Federated Learning Framework}} with {{Decision Trees}}},
  booktitle = {Data {{Privacy Management}}, {{Cryptocurrencies}} and {{Blockchain Technology}}},
  author = {Kwatra, Saloni and Torra, Vicen{\c c}},
  editor = {{Garcia-Alfaro}, Joaquin and {Mu{\~n}oz-Tapia}, Jose Luis and {Navarro-Arribas}, Guillermo and Soriano, Miguel},
  year = {2022},
  pages = {106--120},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  abstract = {We propose a privacy-preserving framework using Mondrian k-anonymity with decision trees in a Federated Learning (FL) setting for the horizontally partitioned data. Data heterogeneity in FL makes the data non-IID (Non-Independent and Identically Distributed). We use a novel approach to create non-IID partitions of data by solving an optimization problem. In this work, each device trains a decision tree classifier. Devices share the root node of their trees with the aggregator. The aggregator merges the trees by choosing the most common split attribute and grows the branches based on the split values of the chosen split attribute. This recursive process stops when all the nodes to be merged are leaf nodes. After the merging operation, the aggregator sends the merged decision tree to the distributed devices. Therefore, we aim to build a joint machine learning model based on the data from multiple devices while offering k-anonymity to the participants.},
  isbn = {978-3-030-93944-1}
}

@article{liu_privacy_2012,
  title = {Privacy Preserving Distributed {{DBSCAN}} Clustering},
  author = {Liu, Jinfei and Huang, Joshua and Luo, Jun and Xiong, Li},
  year = {2012},
  month = mar,
  journal = {Transactions on Data Privacy},
  volume = {6},
  doi = {10.1145/2320765.2320819},
  abstract = {DBSCAN is a well-known density-based clustering algorithm which offers advantages for finding clusters of arbitrary shapes compared to partitioning and hierarchical clustering methods. However, there are few papers studying the DBSCAN algorithm under the privacy preserving distributed data mining model, in which the data is distributed between two or more parties, and the parties cooperate to obtain the clustering results without revealing the data at the individual parties. In this paper, we address the problem of two-party privacy preserving DBSCAN clustering. We first propose two protocols for privacy preserving DBSCAN clustering over horizontally and vertically partitioned data respectively and then extend them to arbitrarily partitioned data. We also provide analysis of the performance and proof of privacy of our solution.},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\2AH2MBGH\\Liu e.a. - 2012 - Privacy preserving distributed DBSCAN clustering.pdf}
}

@article{liu_when_2022,
  title = {When {{Machine Learning Meets Privacy}}: {{A Survey}} and {{Outlook}}},
  shorttitle = {When {{Machine Learning Meets Privacy}}},
  author = {Liu, Bo and Ding, Ming and Shaham, Sina and Rahayu, Wenny and Farokhi, Farhad and Lin, Zihuai},
  year = {2022},
  month = mar,
  journal = {ACM Computing Surveys},
  volume = {54},
  number = {2},
  pages = {1--36},
  issn = {0360-0300, 1557-7341},
  doi = {10.1145/3436755},
  abstract = {The newly emerged machine learning (e.g., deep learning) methods have become a strong driving force to revolutionize a wide range of industries, such as smart healthcare, financial technology, and surveillance systems. Meanwhile, privacy has emerged as a big concern in this machine learning-based artificial intelligence era. It is important to note that the problem of privacy preservation in the context of machine learning is quite different from that in traditional data privacy protection, as machine learning can act as both friend and foe. Currently, the work on the preservation of privacy and machine learning are still in an infancy stage, as most existing solutions only focus on privacy problems during the machine learning process. Therefore, a comprehensive study on the privacy preservation problems and machine learning is required. This article surveys the state of the art in privacy issues and solutions for machine learning. The survey covers three categories of interactions between privacy and machine learning: (i) private machine learning, (ii) machine learning-aided privacy protection, and (iii) machine learning-based privacy attack and corresponding protection schemes. The current research progress in each category is reviewed and the key challenges are identified. Finally, based on our in-depth analysis of the area of privacy and machine learning, we point out future research directions in this field.},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\EAN39LTI\\Liu e.a. - 2022 - When Machine Learning Meets Privacy A Survey and .pdf}
}

@inproceedings{meng_private_2021,
  title = {Private {{Hierarchical Clustering}} and {{Efficient Approximation}}},
  booktitle = {Proceedings of the 2021 on {{Cloud Computing Security Workshop}}},
  author = {Meng, Xianrui and Papadopoulos, Dimitrios and Oprea, Alina and Triandopoulos, Nikos},
  year = {2021},
  month = nov,
  eprint = {1904.04475},
  primaryclass = {cs},
  pages = {3--20},
  doi = {10.1145/3474123.3486760},
  abstract = {In collaborative learning, multiple parties contribute their datasets to jointly deduce global machine learning models for numerous predictive tasks. Despite its efficacy, this learning paradigm fails to encompass critical application domains that involve highly sensitive data, such as healthcare and security analytics, where privacy risks limit entities to individually train models using only their own datasets. In this work, we target privacy-preserving collaborative hierarchical clustering. We introduce a formal security definition that aims to achieve the balance between utility and privacy and present a two-party protocol that provably satisfies it. We then extend our protocol with: (i) an optimized version for the single-linkage clustering, and (ii) scalable approximation variants. We implement all our schemes and experimentally evaluate their performance and accuracy on synthetic and real datasets, obtaining very encouraging results. For example, end-to-end execution of our secure approximate protocol for over 1M 10-dimensional data samples requires 35sec of computation and achieves 97.09\% accuracy.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security,Computer Science - Data Structures and Algorithms,Computer Science - Databases},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\T52RI559\\Meng e.a. - 2021 - Private Hierarchical Clustering and Efficient Appr.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\HIH7PC72\\1904.html}
}

@inproceedings{mo_differential_2019,
  title = {A {{Differential Privacy-Based Protecting Data Preprocessing Method}} for {{Big Data Mining}}},
  booktitle = {2019 18th {{IEEE International Conference On Trust}}, {{Security And Privacy In Computing And Communications}}/13th {{IEEE International Conference On Big Data Science And Engineering}} ({{TrustCom}}/{{BigDataSE}})},
  author = {Mo, Ran and Liu, Jianfeng and Yu, Wentao and Jiang, Fu and Gu, Xin and Zhao, Xiaoshuai and Liu, Weirong and Peng, Jun},
  year = {2019},
  month = aug,
  pages = {693--699},
  publisher = {{IEEE}},
  address = {{Rotorua, New Zealand}},
  doi = {10.1109/TrustCom/BigDataSE.2019.00098},
  isbn = {978-1-72812-777-4}
}

@inproceedings{navidan_hide_2022,
  title = {Hide Me {{Behind}} the {{Noise}}: {{Local Differential Privacy}} for {{Indoor Location Privacy}}},
  shorttitle = {Hide Me {{Behind}} the {{Noise}}},
  booktitle = {2022 {{IEEE European Symposium}} on {{Security}} and {{Privacy Workshops}} ({{EuroS}}\&{{PW}})},
  author = {Navidan, Hojjat and Moghtadaiee, Vahideh and Nazaran, Niki and Alishahi, Mina},
  year = {2022},
  month = jun,
  eprint = {2207.00633},
  primaryclass = {cs},
  pages = {514--523},
  doi = {10.1109/EuroSPW55150.2022.00061},
  abstract = {The advent of numerous indoor location-based services (LBSs) and the widespread use of many types of mobile devices in indoor environments have resulted in generating a massive amount of people's location data. While geo-spatial data contains sensitive information about personal activities, collecting it in its raw form may lead to the leak of personal information relating to the people, violating their privacy. This paper proposes a novel privacy-aware framework for aggregating the indoor location data employing the Local Differential Privacy (LDP) technique, in which the user location data is changed locally in the user's device and is sent to the aggregator afterward. Therefore, the users' locations are kept hidden from a server or any attackers. The practical feasibility of applying the proposed framework is verified by two real-world datasets. The impact of dataset properties, the privacy mechanisms, and the privacy level on our framework are also investigated. The experimental results indicate that the presented framework can protect the location information of users, and the accuracy of the population frequency of different zones in the indoor area is close to that of the original population frequency with no knowledge about the location of people indoors.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Cryptography and Security},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\BR9UPM87\\Navidan e.a. - 2022 - Hide me Behind the Noise Local Differential Priva.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\L95BWU7X\\2207.html}
}

@misc{neera_private_2021,
  title = {Private and {{Utility Enhanced Recommendations}} with {{Local Differential Privacy}} and {{Gaussian Mixture Model}}},
  author = {Neera, Jeyamohan and Chen, Xiaomin and Aslam, Nauman and Wang, Kezhi and Shu, Zhan},
  year = {2021},
  month = mar,
  number = {arXiv:2102.13453},
  eprint = {arXiv:2102.13453},
  publisher = {{arXiv}},
  abstract = {Recommendation systems rely heavily on users behavioural and preferential data (e.g. ratings, likes) to produce accurate recommendations. However, users experience privacy concerns due to unethical data aggregation and analytical practices carried out by the Service Providers (SP). Local differential privacy (LDP) based perturbation mechanisms add noise to users data at user side before sending it to the SP. The SP then uses the perturbed data to perform recommendations. Although LDP protects the privacy of users from SP, it causes a substantial decline in predictive accuracy. To address this issue, we propose an LDP-based Matrix Factorization (MF) with a Gaussian Mixture Model (MoG). The LDP perturbation mechanism, Bounded Laplace (BLP), regulates the effect of noise by confining the perturbed ratings to a predetermined domain. We derive a sufficient condition of the scale parameter for BLP to satisfy \$\textbackslash epsilon\$ LDP. At the SP, The MoG model estimates the noise added to perturbed ratings and the MF algorithm predicts missing ratings. Our proposed LDP based recommendation system improves the recommendation accuracy without violating LDP principles. The empirical evaluations carried out on three real world datasets, i.e., Movielens, Libimseti and Jester, demonstrate that our method offers a substantial increase in predictive accuracy under strong privacy guarantee.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\V7A4IS7T\\Neera e.a. - 2021 - Private and Utility Enhanced Recommendations with .pdf;C\:\\Users\\tjvan\\Zotero\\storage\\5ERLZYHX\\2102.html}
}

@misc{noauthor_art_2018,
  title = {Art. 34 {{GDPR}} \textendash{} {{Communication}} of a Personal Data Breach to the Data Subject},
  year = {2018},
  month = may,
  journal = {General Data Protection Regulation (GDPR)},
  abstract = {When the personal data breach is likely to result in a high risk to the rights and freedoms of natural persons, the controller shall communicate the personal data breach to the data subject without undue delay. The communication to the data subject referred to in paragraph 1 of this Article shall describe in clear and \ldots{} Continue reading Art. 34 GDPR \textendash{} Communication of a personal data breach to the data subject},
  langid = {american},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\LLUBRNU7\\art-34-gdpr.html}
}

@misc{noauthor_data_nodate-3,
  title = {Data Breach of 500m {{Yahoo}} Accounts},
  abstract = {CERT-UK made aware of reports of an attack on the technology firm Yahoo in which up to 500 million user accounts were breached.},
  howpublished = {https://www.ncsc.gov.uk/news/data-breach-500m-yahoo-accounts},
  langid = {english}
}

@misc{noauthor_data_nodate-4,
  title = {Data Breach of 500m {{Yahoo}} Accounts},
  abstract = {CERT-UK made aware of reports of an attack on the technology firm Yahoo in which up to 500 million user accounts were breached.},
  howpublished = {https://www.ncsc.gov.uk/news/data-breach-500m-yahoo-accounts},
  langid = {english}
}

@misc{noauthor_global_2023,
  title = {Global Big Data Industry Market Size 2011-2027},
  year = {2023},
  month = feb,
  journal = {Statista},
  abstract = {The global big data market is forecasted to grow to 103 billion U.S.},
  howpublished = {https://www.statista.com/statistics/254266/global-big-data-market-forecast/},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\4DYXBNAX\\global-big-data-market-forecast.html}
}

@misc{noauthor_office_2014,
  title = {Office of {{Privacy}} and {{Civil Liberties}} | {{Privacy Act}} of 1974},
  year = {2014},
  month = jun,
  howpublished = {https://www.justice.gov/opcl/privacy-act-1974},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\34N4QHSJ\\privacy-act-1974.html}
}

@article{noauthor_personal_2017,
  title = {Personal Details of Nearly 200 Million {{US}} Citizens Exposed},
  year = {2017},
  month = jun,
  journal = {BBC News},
  abstract = {Sensitive personal details were available on a cloud server to anyone with the correct link.},
  chapter = {Technology},
  langid = {british}
}

@misc{noauthor_regulation_2018,
  title = {Regulation ({{EU}}) 2018/1725 of the {{European Parliament}} and of the {{Council}} of 23 {{October}} 2018 on the Protection of Natural Persons with Regard to the Processing of Personal Data by the {{Union}} Institutions, Bodies, Offices and Agencies and on the Free Movement of Such Data, and Repealing {{Regulation}} ({{EC}}) {{No}} 45/2001 and {{Decision No}} 1247/2002/{{EC}} ({{Text}} with {{EEA}} Relevance.)},
  year = {2018},
  month = oct,
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\3REY82E8\\2018 - Regulation (EU) 20181725 of the European Parliame.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\WVZ24GTW\\HTML.html}
}

@article{noauthor_security_2022,
  title = {Security Warning after Sale of Stolen {{Chinese}} Data},
  year = {2022},
  month = jul,
  journal = {BBC News},
  abstract = {Public bodies are told to be on guard after hacker tries to sell data of one billion Chinese citizens.},
  chapter = {Technology},
  langid = {british}
}

@misc{noauthor_wise19_ldppdf_nodate,
  title = {Wise19\_ldp.Pdf},
  journal = {Google Docs},
  howpublished = {https://drive.google.com/file/d/1C4buKvjM6Xf4QxzQfsHScrLtI5hGh830/view?usp=embed\_facebook}
}

@misc{papernot_towards_2016,
  title = {Towards the {{Science}} of {{Security}} and {{Privacy}} in {{Machine Learning}}},
  author = {Papernot, Nicolas and McDaniel, Patrick and Sinha, Arunesh and Wellman, Michael},
  year = {2016},
  month = nov,
  number = {arXiv:1611.03814},
  eprint = {arXiv:1611.03814},
  publisher = {{arXiv}},
  abstract = {Advances in machine learning (ML) in recent years have enabled a dizzying array of applications such as data analytics, autonomous systems, and security diagnostics. ML is now pervasive---new systems and models are being deployed in every domain imaginable, leading to rapid and widespread deployment of software based inference and decision making. There is growing recognition that ML exposes new vulnerabilities in software systems, yet the technical community's understanding of the nature and extent of these vulnerabilities remains limited. We systematize recent findings on ML security and privacy, focusing on attacks identified on these systems and defenses crafted to date. We articulate a comprehensive threat model for ML, and categorize attacks and defenses within an adversarial framework. Key insights resulting from works both in the ML and security communities are identified and the effectiveness of approaches are related to structural elements of ML algorithms and the data used to train them. We conclude by formally exploring the opposing relationship between model accuracy and resilience to adversarial manipulation. Through these explorations, we show that there are (possibly unavoidable) tensions between model complexity, accuracy, and resilience that must be calibrated for the environments in which they will be used.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\6AAN39YK\\Papernot e.a. - 2016 - Towards the Science of Security and Privacy in Mac.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\F8CUBLZT\\1611.html}
}

@article{primault_differentially_nodate,
  title = {Differentially {{Private Location Privacy}} in {{Practice}}},
  author = {Primault, Vincent and Mokhtar, Sonia Ben and Lauradoux, C{\'e}dric and Brunie, Lionel and {de Lyon}, Universit{\'e}},
  abstract = {With the wide adoption of handheld devices (e.g., smartphones, tablets), a large number of location-based services (also called LBSs) have flourished providing mobile users with real-time and contextual information on the move. Accounting for the amount of location information they are given by users, these services are able to track users wherever they go and to learn sensitive information about them (e.g., their points of interest including home, work, religious or political places regularly visited). A number of solutions have been proposed in the past few years to protect users location information while still allowing them to enjoy geo-located services. Among the most robust solutions are those that apply the popular notion of differential privacy to location privacy (e.g., Geo-Indistinguishability), promising strong theoretical privacy guarantees with a bounded accuracy loss. While these theoretical guarantees are attracting, it might be difficult for end users or practitioners to assess their effectiveness in the wild. In this paper, we carry on a practical study using real mobility traces coming from two different datasets, to assess the ability of Geo-Indistinguishability to protect users' points of interest (POIs). We show that a curious LBS collecting obfuscated location information sent by mobile users is still able to infer most of the users POIs with a reasonable both geographic and semantic precision. This precision depends on the degree of obfuscation applied by Geo-Indistinguishability. Nevertheless, the latter also has an impact on the overhead incurred on mobile devices resulting in a privacy versus overhead trade-off. Finally, we show in our study that POIs constitute a quasi-identifier for mobile users and that obfuscating them using Geo-Indistinguishability is not sufficient as an attacker is able to re-identify at least 63 \% of them despite a high degree of obfuscation.},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\97UJR6SU\\Primault e.a. - Differentially Private Location Privacy in Practic.pdf}
}

@article{rodriguez_clustering_2014,
  title = {Clustering by Fast Search and Find of Density Peaks},
  author = {Rodriguez, Alex and Laio, Alessandro},
  year = {2014},
  journal = {science},
  volume = {344},
  number = {6191},
  pages = {1492--1496},
  publisher = {{American Association for the Advancement of Science}},
  issn = {0036-8075},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\K6MCAY4N\\rodriguez2014.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\SHWA8K9H\\Rodriguez en Laio - 2014 - Clustering by fast search and find of density peak.pdf}
}

@article{rodriguez-barroso_survey_2023,
  title = {Survey on {{Federated Learning Threats}}: Concepts, Taxonomy on Attacks and Defences, Experimental Study and Challenges},
  shorttitle = {Survey on {{Federated Learning Threats}}},
  author = {{Rodr{\'i}guez-Barroso}, Nuria and L{\'o}pez, Daniel Jim{\'e}nez and Luz{\'o}n, M. Victoria and Herrera, Francisco and {Mart{\'i}nez-C{\'a}mara}, Eugenio},
  year = {2023},
  month = feb,
  journal = {Information Fusion},
  volume = {90},
  eprint = {2201.08135},
  primaryclass = {cs},
  pages = {148--173},
  issn = {15662535},
  doi = {10.1016/j.inffus.2022.09.011},
  abstract = {Federated learning is a machine learning paradigm that emerges as a solution to the privacy-preservation demands in artificial intelligence. As machine learning, federated learning is threatened by adversarial attacks against the integrity of the learning model and the privacy of data via a distributed approach to tackle local and global learning. This weak point is exacerbated by the inaccessibility of data in federated learning, which makes harder the protection against adversarial attacks and evidences the need to furtherance the research on defence methods to make federated learning a real solution for safeguarding data privacy. In this paper, we present an extensive review of the threats of federated learning, as well as as their corresponding countermeasures, attacks versus defences. This survey provides a taxonomy of adversarial attacks and a taxonomy of defence methods that depict a general picture of this vulnerability of federated learning and how to overcome it. Likewise, we expound guidelines for selecting the most adequate defence method according to the category of the adversarial attack. Besides, we carry out an extensive experimental study from which we draw further conclusions about the behaviour of attacks and defences and the guidelines for selecting the most adequate defence method according to the category of the adversarial attack. This study is finished leading to meditated learned lessons and challenges.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security,Computer Science - Machine Learning},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\WTV9LE2T\\Rodríguez-Barroso e.a. - 2023 - Survey on Federated Learning Threats concepts, ta.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\8R9W2SNA\\2201.html}
}

@article{romano_adjusting_nodate,
  title = {Adjusting for {{Chance Clustering Comparison Measures}}},
  author = {Romano, Simone and Vinh, Nguyen Xuan and Bailey, James and Verspoor, Karin},
  abstract = {Adjusted for chance measures are widely used to compare partitions/clusterings of the same data set. In particular, the Adjusted Rand Index (ARI) based on pair-counting, and the Adjusted Mutual Information (AMI) based on Shannon information theory are very popular in the clustering community. Nonetheless it is an open problem as to what are the best application scenarios for each measure and guidelines in the literature for their usage are sparse, with the result that users often resort to using both. Generalized Information Theoretic (IT) measures based on the Tsallis entropy have been shown to link pair-counting and Shannon IT measures. In this paper, we aim to bridge the gap between adjustment of measures based on pair-counting and measures based on information theory. We solve the key technical challenge of analytically computing the expected value and variance of generalized IT measures. This allows us to propose adjustments of generalized IT measures, which reduce to well known adjusted clustering comparison measures as special cases. Using the theory of generalized IT measures, we are able to propose the following guidelines for using ARI and AMI as external validation indices: ARI should be used when the reference clustering has large equal sized clusters; AMI should be used when the reference clustering is unbalanced and there exist small clusters.},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\F8DI8R6Z\\Romano e.a. - Adjusting for Chance Clustering Comparison Measure.pdf}
}

@article{rosenberg_how_2018,
  title = {How {{Trump Consultants Exploited}} the {{Facebook Data}} of {{Millions}}},
  author = {Rosenberg, Matthew and Confessore, Nicholas and Cadwalladr, Carole},
  year = {2018},
  month = mar,
  journal = {The New York Times},
  issn = {0362-4331},
  abstract = {Cambridge Analytica harvested personal information from a huge swath of the electorate to develop techniques that were later used in the Trump campaign.},
  chapter = {U.S.},
  langid = {american},
  keywords = {Bannon; Stephen K,Cambridge Analytica,Data-Mining and Database Marketing,Facebook Inc,Kogan; Aleksandr,Mercer; Robert (1946- ),Nix; Alexander,Online Advertising,Political Advertising,Presidential Election of 2016,Russian Interference in 2016 US Elections and Ties to Trump Associates,Trump; Donald J,United States Politics and Government,Wylie; Christopher}
}

@article{sun_differential_2019,
  title = {Differential {{Privacy-Preserving Density Peaks Clustering Based}} on {{Shared Near Neighbors Similarity}}},
  author = {Sun, Liping and Bao, Shuting and Ci, Shang and Zheng, Xiaoyao and Guo, Liangmin and Luo, Yonglong},
  year = {2019},
  journal = {IEEE Access},
  volume = {7},
  pages = {89427--89440},
  issn = {2169-3536},
  doi = {10.1109/ACCESS.2019.2927308},
  abstract = {Density peaks clustering is a novel and efficient density-based clustering algorithm. However, the problem of the sensitive information leakage and the associated security risk with the applications of clustering methods is rarely considered. To address the problem, we proposed differential privacy-preserving density peaks' clustering based on the shared near neighbors similarity method in this paper. First, the Euclidean distance and the shared near neighbors similarity were combined to define the local density of a sample, and the Laplace noise was added to the local density and the shortest distance to protect privacy. Second, the process of cluster center selection was optimized to select the initial cluster centers based on the neighborhood information. Finally, each sample was assigned to the cluster as its nearest neighbor with higher local density. The experimental results on both the UCI and synthetic datasets show that compared with other algorithms, our method more effectively protects the data privacy and improves the quality of the clustering results.},
  keywords = {Clustering algorithms,density peaks clustering algorithm,differential privacy,Differential privacy,Euclidean distance,Heuristic algorithms,Privacy,Privacy preservation,shared near neighbors similarity},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\MKTV4TFF\\Sun e.a. - 2019 - Differential Privacy-Preserving Density Peaks Clus.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\TPIARW7R\\8756224.html}
}

@misc{sun_distributed_2019,
  title = {Distributed {{Clustering}} in the {{Anonymized Space}} with {{Local Differential Privacy}}},
  author = {Sun, Lin and Zhao, Jun and Ye, Xiaojun},
  year = {2019},
  month = jun,
  number = {arXiv:1906.11441},
  eprint = {arXiv:1906.11441},
  publisher = {{arXiv}},
  abstract = {Clustering and analyzing on collected data can improve user experiences and quality of services in big data, IoT applications. However, directly releasing original data brings potential privacy concerns, which raises challenges and opportunities for privacy-preserving clustering. In this paper, we study the problem of non-interactive clustering in distributed setting under the framework of local differential privacy. We first extend the Bit Vector, a novel anonymization mechanism to be functionality-capable and privacy-preserving. Based on the modified encoding mechanism, we propose kCluster algorithm that can be used for clustering in the anonymized space. We show the modified encoding mechanism can be easily implemented in existing clustering algorithms that only rely on distance information, such as DBSCAN. Theoretical analysis and experimental results validate the effectiveness of the proposed schemes.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Databases},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\8VTXE9HS\\Sun e.a. - 2019 - Distributed Clustering in the Anonymized Space wit.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\IRX6PFZC\\1906.html}
}

@article{sun_privbv_2022,
  title = {{{PrivBV}}: {{Distance-aware}} Encoding for Distributed Data with Local Differential Privacy},
  shorttitle = {{{PrivBV}}},
  author = {Sun, Lin and Ping, Guolou and Ye, Xiaojun},
  year = {2022},
  month = apr,
  journal = {Tsinghua Science and Technology},
  volume = {27},
  number = {2},
  pages = {412--421},
  issn = {1007-0214},
  doi = {10.26599/TST.2021.9010027},
  abstract = {Recently, local differential privacy (LDP) has been used as the de facto standard for data sharing and analyzing with high-level privacy guarantees. Existing LDP-based mechanisms mainly focus on learning statistical information about the entire population from sensitive data. For the first time in the literature, we use LDP for distance estimation between distributed datato support more complicated data analysis. Specifically, we propose PrivBV\textemdash a locally differentially private bit vector mechanism with a distance-aware property in the anonymized space. We also present an optimization strategy for reducing privacy leakage in the high-dimensional space. The distance-aware property of PrivBV brings new insights into complicated data analysis in distributed environments. As study cases, we show the feasibility of applying PrivBV to privacy-preserving record linkage and non-interactive clustering. Theoretical analysis and experimental results demonstrate the effectiveness of the proposed scheme.},
  keywords = {Data analysis,Differential privacy,Distributed databases,Encoding,Estimation,local differential privacy,non-interactive clustering,Privacy,privacy-preserving data publishing,Sun},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\B8WDVH5J\\Sun e.a. - 2022 - PrivBV Distance-aware encoding for distributed da.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\JPL3C98G\\9552667.html}
}

@article{sweeney_k-anonymity_2002,
  title = {K-{{ANONYMITY}}: {{A MODEL FOR PROTECTING PRIVACY}}},
  shorttitle = {K-{{ANONYMITY}}},
  author = {Sweeney, Latanya},
  year = {2002},
  month = oct,
  journal = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  volume = {10},
  number = {05},
  pages = {557--570},
  issn = {0218-4885, 1793-6411},
  doi = {10.1142/S0218488502001648},
  abstract = {Consider a data holder, such as a hospital or a bank, that has a privately held collection of person-specific, field structured data. Suppose the data holder wants to share a version of the data with researchers. How can a data holder release a version of its private data with scientific guarantees that the individuals who are the subjects of the data cannot be re-identified while the data remain practically useful? The solution provided in this paper includes a formal protection model named k-anonymity and a set of accompanying policies for deployment. A release provides k-anonymity protection if the information for each person contained in the release cannot be distinguished from at least k-1 individuals whose information also appears in the release. This paper also examines re-identification attacks that can be realized on releases that adhere to kanonymity unless accompanying policies are respected. The k-anonymity protection model is important because it forms the basis on which the real-world systems known as Datafly, \textmu -Argus and k-Similar provide guarantees of privacy protection.},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\X68B5J59\\Sweeney - 2002 - k-ANONYMITY A MODEL FOR PROTECTING PRIVACY.pdf}
}

@misc{truex_ldp-fed_2020,
  title = {{{LDP-Fed}}: {{Federated Learning}} with {{Local Differential Privacy}}},
  shorttitle = {{{LDP-Fed}}},
  author = {Truex, Stacey and Liu, Ling and Chow, Ka-Ho and Gursoy, Mehmet Emre and Wei, Wenqi},
  year = {2020},
  month = jun,
  number = {arXiv:2006.03637},
  eprint = {arXiv:2006.03637},
  publisher = {{arXiv}},
  abstract = {This paper presents LDP-Fed, a novel federated learning system with a formal privacy guarantee using local differential privacy (LDP). Existing LDP protocols are developed primarily to ensure data privacy in the collection of single numerical or categorical values, such as click count in Web access logs. However, in federated learning model parameter updates are collected iteratively from each participant and consist of high dimensional, continuous values with high precision (10s of digits after the decimal point), making existing LDP protocols inapplicable. To address this challenge in LDP-Fed, we design and develop two novel approaches. First, LDP-Fed's LDP Module provides a formal differential privacy guarantee for the repeated collection of model training parameters in the federated training of large-scale neural networks over multiple individual participants' private datasets. Second, LDP-Fed implements a suite of selection and filtering techniques for perturbing and sharing select parameter updates with the parameter server. We validate our system deployed with a condensed LDP protocol in training deep neural networks on public data. We compare this version of LDP-Fed, coined CLDP-Fed, with other state-of-the-art approaches with respect to model accuracy, privacy preservation, and system capabilities.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\YPUHCDTN\\Truex e.a. - 2020 - LDP-Fed Federated Learning with Local Differentia.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\7KYXQWVT\\2006.html}
}

@inproceedings{vinh_information_2009,
  title = {Information Theoretic Measures for Clusterings Comparison: Is a Correction for Chance Necessary?},
  booktitle = {Proceedings of the 26th Annual International Conference on Machine Learning},
  author = {Vinh, Nguyen Xuan and Epps, Julien and Bailey, James},
  year = {2009},
  pages = {1073--1080}
}

@article{vinh_information_nodate,
  title = {Information Theoretic Measures for Clusterings Comparison: Is a Correction for Chance Necessary?},
  author = {Vinh, Nguyen Xuan and Epps, Julien and Bailey, James},
  abstract = {Information theoretic based measures form a fundamental class of similarity measures for comparing clusterings, beside the class of pair-counting based and set-matching based measures. In this paper, we discuss the necessity of correction for chance for information theoretic based measures for clusterings comparison. We observe that the baseline for such measures, i.e. average value between random partitions of a data set, does not take on a constant value, and tends to have larger variation when the ratio between the number of data points and the number of clusters is small. This effect is similar in some other non-information theoretic based measures such as the well-known Rand Index. Assuming a hypergeometric model of randomness, we derive the analytical formula for the expected mutual information value between a pair of clusterings, and then propose the adjusted version for several popular information theoretic based measures. Some examples are given to demonstrate the need and usefulness of the adjusted measures.},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\3WKAB5EC\\Vinh e.a. - Information theoretic measures for clusterings com.pdf}
}

@article{wang_comprehensive_2020,
  title = {A {{Comprehensive Survey}} on {{Local Differential Privacy Toward Data Statistics}} and {{Analysis}} in {{Crowdsensing}}},
  author = {Wang, Teng and Zhang, Xuefeng and Feng, Jingyu and Yang, Xinyu},
  year = {2020},
  journal = {CoRR},
  volume = {abs/2010.05253},
  eprint = {2010.05253},
  archiveprefix = {arxiv}
}

@article{warner_randomized_1965,
  title = {Randomized {{Response}}: {{A Survey Technique}} for {{Eliminating Evasive Answer Bias}}},
  author = {Warner, Stanley L.},
  year = {1965},
  month = mar,
  journal = {Journal of the American Statistical Association},
  volume = {60},
  number = {309},
  pages = {63--69},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459},
  doi = {10.1080/01621459.1965.10480775}
}

@article{xia_distributed_2020,
  title = {Distributed {{K-Means}} Clustering Guaranteeing Local Differential Privacy},
  author = {Xia, Chang and Hua, Jingyu and Tong, Wei and Zhong, Sheng},
  year = {2020},
  month = mar,
  journal = {Computers \& Security},
  volume = {90},
  pages = {101699},
  issn = {0167-4048},
  doi = {10.1016/j.cose.2019.101699},
  abstract = {In many cases, a service provider might require to aggregate data from end-users to perform mining tasks such as K-means clustering. Nevertheless, since such data often contain sensitive information. In this paper, we propose the first locally differentially private K-means mechanism under this distributed scenario. Differing from standard differentially private clustering mechanisms, the proposed mechanism doesn't need any trusted third party to collect and preprocess users data. Our mechanism first perturbs users data locally to satisfy local differential privacy~(LDP). Then it revises the traditional K-means algorithm to allow the service provider to obtain high-quality clustering results by collaborating with users based on the highly perturbed data. We prove that our mechanism can enable high utility clustering while guaranteeing local differential privacy for each user. We also propose an extended mechanism to improve our basic model in terms of privacy and utility. In this mechanism, we perturb both users' sensitive data and the intermediate results of users' clusters in each iteration. Moreover, we consider a more general setting where the users may have different privacy requirements. Extensive experiments are conducted on two real-world datasets, and the results show that our proposal can well preserve the quality of clustering results.},
  keywords = {Differential privacy,Distributed clustering,K-Means;,Machine learning,Randomized response},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\N8H23NMU\\Xia e.a. - 2020 - Distributed K-Means clustering guaranteeing local .pdf}
}

@article{xu_comprehensive_2015,
  title = {A {{Comprehensive Survey}} of {{Clustering Algorithms}}},
  author = {Xu, Dongkuan and Tian, Yingjie},
  year = {2015},
  month = jun,
  journal = {Annals of Data Science},
  volume = {2},
  number = {2},
  pages = {165--193},
  issn = {2198-5812},
  doi = {10.1007/s40745-015-0040-1},
  abstract = {Data analysis is used as a common method in modern science research, which is across communication science, computer science and biology science. Clustering, as the basic composition of data analysis, plays a significant role. On one hand, many tools for cluster analysis have been created, along with the information increase and subject intersection. On the other hand, each clustering algorithm has its own strengths and weaknesses, due to the complexity of information. In this review paper, we begin at the definition of clustering, take the basic elements involved in the clustering process, such as the distance or similarity measurement and evaluation indicators, into consideration, and analyze the clustering algorithms from two perspectives, the traditional ones and the modern ones. All the discussed clustering algorithms will be compared in detail and comprehensively shown in Appendix Table~22.}
}

@article{yan_perturb_2022-1,
  title = {Perturb and Optimize Users' Location Privacy Using Geo-Indistinguishability and Location Semantics},
  author = {Yan, Yan and Xu, Fei and Mahmood, Adnan and Dong, Zhuoyue and Sheng, Quan Z.},
  year = {2022},
  month = nov,
  journal = {Scientific Reports},
  volume = {12},
  number = {1},
  pages = {20445},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-24893-0},
  abstract = {Location-based services (LBS) are capable of providing location-based information retrieval, traffic navigation, entertainment services, emergency rescues, and several similar services primarily on the premise of the geographic location of users or mobile devices. However, in the process of introducing a new user experience, it is also easy to expose users' specific location which can result in more private information leakage. Hence, the protection of location privacy remains one of the critical issues of the location-based services. Moreover, the areas where humans work and live have different location semantics and sensitivities according to their different social functions. Although the privacy protection of a user's real location can be achieved by the perturbation algorithm, the attackers may employ the semantics information of the perturbed location to infer a user's real location semantics in an attempt to spy on a user's privacy to certain extent. In order to mitigate the above semantics inference attack, and further improve the quality of the location-based services, this paper hereby proposes a user side location perturbation and optimization algorithm based on geo-indistinguishability and location semantics. The perturbation area satisfying geo-indistinguishability is thus generated according to the planar Laplace mechanism and optimized by combining the semantics information and time characteristics of the location. The optimum perturbed location that is able to satisfy the minimum loss of location-based service quality is selected via a linear programming method, and can be employed to replace the real location of the user so as to prevent the leakage of the privacy. Experimental comparison of the actual road network and location semantics dataset manifests that the proposed method reduces approximately 37\% perturbation distance in contrast to the other state-of-the-art methods, maintains considerably lower similarity of location semantics, and improves region counting query accuracy by a margin of around 40\%.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Energy science and technology,Mathematics and computing},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\IB8NW2MX\\Yan e.a. - 2022 - Perturb and optimize users’ location privacy using.pdf}
}

@misc{yang_local_2020,
  title = {Local {{Differential Privacy}} and {{Its Applications}}: {{A Comprehensive Survey}}},
  shorttitle = {Local {{Differential Privacy}} and {{Its Applications}}},
  author = {Yang, Mengmeng and Lyu, Lingjuan and Zhao, Jun and Zhu, Tianqing and Lam, Kwok-Yan},
  year = {2020},
  month = aug,
  number = {arXiv:2008.03686},
  eprint = {arXiv:2008.03686},
  publisher = {{arXiv}},
  abstract = {With the fast development of Information Technology, a tremendous amount of data have been generated and collected for research and analysis purposes. As an increasing number of users are growing concerned about their personal information, privacy preservation has become an urgent problem to be solved and has attracted significant attention. Local differential privacy (LDP), as a strong privacy tool, has been widely deployed in the real world in recent years. It breaks the shackles of the trusted third party, and allows users to perturb their data locally, thus providing much stronger privacy protection. This survey provides a comprehensive and structured overview of the local differential privacy technology. We summarise and analyze state-of-the-art research in LDP and compare a range of methods in the context of answering a variety of queries and training different machine learning models. We discuss the practical deployment of local differential privacy and explore its application in various domains. Furthermore, we point out several research gaps, and discuss promising future research directions.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Cryptography and Security},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\D49D6UZQ\\Yang e.a. - 2020 - Local Differential Privacy and Its Applications A.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\4SNPVQXE\\2008.html}
}

@article{zhang_birch_1996,
  title = {{{BIRCH}}: An Efficient Data Clustering Method for Very Large Databases},
  shorttitle = {{{BIRCH}}},
  author = {Zhang, Tian and Ramakrishnan, Raghu and Livny, Miron},
  year = {1996},
  month = jun,
  journal = {ACM SIGMOD Record},
  volume = {25},
  number = {2},
  pages = {103--114},
  issn = {0163-5808},
  doi = {10.1145/235968.233324},
  abstract = {Finding useful patterns in large datasets has attracted considerable interest recently, and one of the most widely studied problems in this area is the identification of clusters, or densely populated regions, in a multi-dimensional dataset. Prior work does not adequately address the problem of large datasets and minimization of I/O costs.This paper presents a data clustering method named BIRCH (Balanced Iterative Reducing and Clustering using Hierarchies), and demonstrates that it is especially suitable for very large databases. BIRCH incrementally and dynamically clusters incoming multi-dimensional metric data points to try to produce the best quality clustering with the available resources (i.e., available memory and time constraints). BIRCH can typically find a good clustering with a single scan of the data, and improve the quality further with a few additional scans. BIRCH is also the first clustering algorithm proposed in the database area to handle "noise" (data points that are not part of the underlying pattern) effectively.We evaluate BIRCH's time/space efficiency, data input order sensitivity, and clustering quality through several experiments. We also present a performance comparisons of BIRCH versus CLARANS, a clustering method proposed recently for large datasets, and show that BIRCH is consistently superior.},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\9PA6E78P\\Zhang e.a. - 1996 - BIRCH an efficient data clustering method for ver.pdf}
}

@inproceedings{zhang_privacy_2017,
  title = {Privacy {{Preserving BIRCH Algorithm}} under {{Differential Privacy}}},
  booktitle = {2017 10th {{International Conference}} on {{Intelligent Computation Technology}} and {{Automation}} ({{ICICTA}})},
  author = {Zhang, Yao and Li, Shuyu},
  year = {2017},
  month = oct,
  pages = {48--53},
  publisher = {{IEEE}},
  address = {{Changsha}},
  doi = {10.1109/ICICTA.2017.18},
  isbn = {978-1-5386-1230-9}
}
