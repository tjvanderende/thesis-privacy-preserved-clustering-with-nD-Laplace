@article{9646489,
  title = {{{3D}} Geo-Indistinguishability for Indoor Location-Based Services},
  author = {Min, Minghui and Xiao, Liang and Ding, Jiahao and Zhang, Hongliang and Li, Shiyin and Pan, Miao and Han, Zhu},
  year = {2022},
  journal = {IEEE Transactions on Wireless Communications},
  volume = {21},
  number = {7},
  pages = {4682--4694},
  doi = {10.1109/TWC.2021.3132464},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\QPJZTQGX\\Min e.a. - 2022 - 3D geo-indistinguishability for indoor location-ba.pdf}
}

@inproceedings{9679364,
  title = {Private Distributed {{K-means}} Clustering on Interval Data},
  booktitle = {2021 {{IEEE}} International Performance, Computing, and Communications Conference ({{IPCCC}})},
  author = {Huang, D. and Yao, X. and An, S. and Ren, S.},
  year = {2021},
  month = oct,
  pages = {1--9},
  publisher = {{IEEE Computer Society}},
  address = {{Los Alamitos, CA, USA}},
  doi = {10.1109/IPCCC51483.2021.9679364},
  abstract = {K-means clustering has been heavily employed to mine valuable insights from interval data. Nevertheless, serious privacy leakage concerns are stumbling blocks impeding its widespread application. To quantify the privacy of small and large-scale interval data, we introduce two notions of \&amp;\#x03B1;-Condensed Local Differential Privacy and \&amp;\#x03F5;-Local Differential Privacy, and propose two distance-aware perturbation mechanisms of \&amp;\#x03B1;-exponential and square wave mechanisms. Rigorous theoretical analysis proves that our proposed mechanisms satisfy these two privacy notions. The experimental results built on multiple synthesized and real datasets show that our proposed mechanisms can provide more accurate clustering results than prior work, such as Randomized Response, Generalized Randomized Response, and Optimized Local Hash.},
  keywords = {conferences,correlation,differential privacy,distributed databases,perturbation methods,privacy},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\6F8LBU8D\\Huang e.a. - 2021 - Private distributed K-means clustering on interval.pdf}
}

@misc{alvim_metric-based_2018,
  title = {Metric-Based Local Differential Privacy for Statistical Applications},
  author = {Alvim, M{\'a}rio S. and Chatzikokolakis, Konstantinos and Palamidessi, Catuscia and Pazii, Anna},
  year = {2018},
  month = may,
  number = {arXiv:1805.01456},
  eprint = {1805.01456},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  abstract = {Local differential privacy (LPD) is a distributed variant of differential privacy (DP) in which the obfuscation of the sensitive information is done at the level of the individual records, and in general it is used to sanitize data that are collected for statistical purposes. LPD has the advantage it does not need to assume a trusted third party. On the other hand LDP in general requires more noise than DP to achieve the same level of protection, with negative consequences on the utility. In practice, utility becomes acceptable only on very large collections of data, and this is the reason why LDP is especially successful among big companies such as Apple and Google, which can count on a huge number of users. In this paper, we propose a variant of LDP suitable for metric spaces, such as location data or energy consumption data, and we show that it provides a much better utility for the same level of privacy.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Cryptography and Security},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\ZP2CTPQW\\Alvim e.a. - 2018 - Metric-based local differential privacy for statis.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\FDNJ3E7E\\1805.html}
}

@inproceedings{bozdemir_privacy-preserving_2021,
  title = {Privacy-Preserving {{Density-based Clustering}}},
  booktitle = {Proceedings of the 2021 {{ACM Asia Conference}} on {{Computer}} and {{Communications Security}}},
  author = {Bozdemir, Beyza and Canard, S{\'e}bastien and Ermis, Orhan and M{\"o}llering, Helen and {\"O}nen, Melek and Schneider, Thomas},
  year = {2021},
  month = may,
  pages = {658--671},
  publisher = {{ACM}},
  address = {{Virtual Event Hong Kong}},
  doi = {10.1145/3433210.3453104},
  abstract = {Clustering is an unsupervised machine learning technique that outputs clusters containing similar data items. In this work, we investigate privacy-preserving density-based clustering which is, for example, used in financial analytics and medical diagnosis. When (multiple) data owners collaborate or outsource the computation, privacy concerns arise. To address this problem, we design, implement, and evaluate the first practical and fully private density-based clustering scheme based on secure two-party computation. Our protocol privately executes the DBSCAN algorithm without disclosing any information (including the number and size of clusters). It can be used for private clustering between two parties as well as for private outsourcing of an arbitrary number of data owners to two non-colluding servers. Our implementation of the DBSCAN algorithm privately clusters data sets with 400 elements in 7 minutes on commodity hardware. Thereby, it flexibly determines the number of required clusters and is insensitive to outliers, while being only factor 19x slower than today's fastest private K-means protocol (Mohassel et al., PETS'20) which can only be used for specific data sets. We then show how to transfer our newly designed protocol to related clustering algorithms by introducing a private approximation of the TRACLUS algorithm for trajectory clustering which has interesting real-world applications like financial time series forecasts and the investigation of the spread of a disease like COVID-19.},
  isbn = {978-1-4503-8287-8},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\VQSCH9H2\\Bozdemir e.a. - 2021 - Privacy-preserving Density-based Clustering.pdf}
}

@article{DBLP:journals/corr/abs-1212-1984,
  title = {Geo-Indistinguishability: {{Differential}} Privacy for Location-Based Systems},
  author = {Andr{\'e}s, Miguel E. and Bordenabe, Nicol{\'a}s Emilio and Chatzikokolakis, Konstantinos and Palamidessi, Catuscia},
  year = {2012},
  journal = {CoRR},
  volume = {abs/1212.1984},
  eprint = {1212.1984},
  eprinttype = {arxiv},
  archiveprefix = {arXiv},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/journals/corr/abs-1212-1984.bib},
  timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\HVVT4GUR\\Andr√©s e.a. - 2012 - Geo-indistinguishability Differential privacy for.pdf}
}

@article{del_rey_comprehensive_2020,
  title = {A {{Comprehensive Survey}} on {{Local Differential Privacy}}},
  author = {Xiong, Xingxing and Liu, Shubo and Li, Dan and Cai, Zhaohui and Niu, Xiaoguang},
  editor = {Del Rey, Angel M.},
  year = {2020},
  month = oct,
  journal = {Security and Communication Networks},
  volume = {2020},
  pages = {8829523},
  publisher = {{Hindawi}},
  issn = {1939-0114},
  doi = {10.1155/2020/8829523},
  abstract = {With the advent of the era of big data, privacy issues have been becoming a hot topic in public. Local differential privacy (LDP) is a state-of-the-art privacy preservation technique that allows to perform big data analysis (e.g., statistical estimation, statistical learning, and data mining) while guaranteeing each individual participant\&\#x2019;s privacy. In this paper, we present a comprehensive survey of LDP. We first give an overview on the fundamental knowledge of LDP and its frameworks. We then introduce the mainstream privatization mechanisms and methods in detail from the perspective of frequency oracle and give insights into recent studied on private basic statistical estimation (e.g., frequency estimation and mean estimation) and complex statistical estimation (e.g., multivariate distribution estimation and private estimation over complex data) under LDP. Furthermore, we present current research circumstances on LDP including the private statistical learning/inferencing, private statistical data analysis, privacy amplification techniques for LDP, and some application fields under LDP. Finally, we identify future research directions and open challenges for LDP. This survey can serve as a good reference source for the research of LDP to deal with various privacy-related scenarios to be encountered in practice.}
}

@inproceedings{erlingsson_rappor_2014,
  title = {{{RAPPOR}}: {{Randomized Aggregatable Privacy-Preserving Ordinal Response}}},
  shorttitle = {{{RAPPOR}}},
  booktitle = {Proceedings of the 2014 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  author = {Erlingsson, {\'U}lfar and Pihur, Vasyl and Korolova, Aleksandra},
  year = {2014},
  month = nov,
  pages = {1054--1067},
  publisher = {{ACM}},
  address = {{Scottsdale Arizona USA}},
  doi = {10.1145/2660267.2660348},
  abstract = {Randomized Aggregatable Privacy-Preserving Ordinal Response, or RAPPOR, is a technology for crowdsourcing statistics from end-user client software, anonymously, with strong privacy guarantees. In short, RAPPORs allow the forest of client data to be studied, without permitting the possibility of looking at individual trees. By applying randomized response in a novel manner, RAPPOR provides the mechanisms for such collection as well as for efficient, high-utility analysis of the collected data. In particular, RAPPOR permits statistics to be collected on the population of client-side strings with strong privacy guarantees for each client, and without linkability of their reports.},
  isbn = {978-1-4503-2957-6},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\GRMRMG69\\Erlingsson e.a. - 2014 - RAPPOR Randomized Aggregatable Privacy-Preserving.pdf}
}

@inproceedings{jagannathan_privacy-preserving_2005,
  title = {Privacy-Preserving Distributed k-Means Clustering over Arbitrarily Partitioned Data},
  booktitle = {Proceeding of the Eleventh {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery in Data Mining  - {{KDD}} '05},
  author = {Jagannathan, Geetha and Wright, Rebecca N.},
  year = {2005},
  pages = {593},
  publisher = {{ACM Press}},
  address = {{Chicago, Illinois, USA}},
  doi = {10.1145/1081870.1081942},
  abstract = {Advances in computer networking and database technologies have enabled the collection and storage of vast quantities of data. Data mining can extract valuable knowledge from this data, and organizations have realized that they can often obtain better results by pooling their data together. However, the collected data may contain sensitive or private information about the organizations or their customers, and privacy concerns are exacerbated if data is shared between multiple organizations.},
  isbn = {978-1-59593-135-1},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\A64MLK72\\Jagannathan en Wright - 2005 - Privacy-preserving distributed k-means clustering .pdf}
}

@inproceedings{jagannathan_privacy-preserving_2005-1,
  title = {Privacy-{{Preserving Distributed}} k-{{Means Clustering}} over {{Arbitrarily Partitioned Data}}},
  booktitle = {Proceedings of the {{Eleventh ACM SIGKDD International Conference}} on {{Knowledge Discovery}} in {{Data Mining}}},
  author = {Jagannathan, Geetha and Wright, Rebecca N.},
  year = {2005},
  series = {{{KDD}} '05},
  pages = {593--599},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1081870.1081942},
  abstract = {Advances in computer networking and database technologies have enabled the collection and storage of vast quantities of data. Data mining can extract valuable knowledge from this data, and organizations have realized that they can often obtain better results by pooling their data together. However, the collected data may contain sensitive or private information about the organizations or their customers, and privacy concerns are exacerbated if data is shared between multiple organizations.Distributed data mining is concerned with the computation of models from data that is distributed among multiple participants. Privacy-preserving distributed data mining seeks to allow for the cooperative computation of such models without the cooperating parties revealing any of their individual data items. Our paper makes two contributions in privacy-preserving data mining. First, we introduce the concept of arbitrarily partitioned data, which is a generalization of both horizontally and vertically partitioned data. Second, we provide an efficient privacy-preserving protocol for k-means clustering in the setting of arbitrarily partitioned data.},
  isbn = {1-59593-135-X}
}

@inproceedings{kolluri_private_2021,
  title = {Private {{Hierarchical Clustering}} in {{Federated Networks}}},
  booktitle = {Proceedings of the 2021 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  author = {Kolluri, Aashish and Baluta, Teodora and Saxena, Prateek},
  year = {2021},
  month = nov,
  pages = {2342--2360},
  publisher = {{ACM}},
  address = {{Virtual Event Republic of Korea}},
  doi = {10.1145/3460120.3484822},
  isbn = {978-1-4503-8454-4},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\UL7WF2U2\\Kolluri e.a. - 2021 - Private Hierarchical Clustering in Federated Netwo.pdf}
}

@inproceedings{kwatra_k-anonymised_2022,
  title = {A K-{{Anonymised Federated Learning Framework}} with {{Decision Trees}}},
  booktitle = {Data {{Privacy Management}}, {{Cryptocurrencies}} and {{Blockchain Technology}}},
  author = {Kwatra, Saloni and Torra, Vicen{\c c}},
  editor = {{Garcia-Alfaro}, Joaquin and {Mu{\~n}oz-Tapia}, Jose Luis and {Navarro-Arribas}, Guillermo and Soriano, Miguel},
  year = {2022},
  pages = {106--120},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  abstract = {We propose a privacy-preserving framework using Mondrian k-anonymity with decision trees in a Federated Learning (FL) setting for the horizontally partitioned data. Data heterogeneity in FL makes the data non-IID (Non-Independent and Identically Distributed). We use a novel approach to create non-IID partitions of data by solving an optimization problem. In this work, each device trains a decision tree classifier. Devices share the root node of their trees with the aggregator. The aggregator merges the trees by choosing the most common split attribute and grows the branches based on the split values of the chosen split attribute. This recursive process stops when all the nodes to be merged are leaf nodes. After the merging operation, the aggregator sends the merged decision tree to the distributed devices. Therefore, we aim to build a joint machine learning model based on the data from multiple devices while offering k-anonymity to the participants.},
  isbn = {978-3-030-93944-1}
}

@article{liu_privacy_2012,
  title = {Privacy Preserving Distributed {{DBSCAN}} Clustering},
  author = {Liu, Jinfei and Huang, Joshua and Luo, Jun and Xiong, Li},
  year = {2012},
  month = mar,
  journal = {Transactions on Data Privacy},
  volume = {6},
  doi = {10.1145/2320765.2320819},
  abstract = {DBSCAN is a well-known density-based clustering algorithm which offers advantages for finding clusters of arbitrary shapes compared to partitioning and hierarchical clustering methods. However, there are few papers studying the DBSCAN algorithm under the privacy preserving distributed data mining model, in which the data is distributed between two or more parties, and the parties cooperate to obtain the clustering results without revealing the data at the individual parties. In this paper, we address the problem of two-party privacy preserving DBSCAN clustering. We first propose two protocols for privacy preserving DBSCAN clustering over horizontally and vertically partitioned data respectively and then extend them to arbitrarily partitioned data. We also provide analysis of the performance and proof of privacy of our solution.},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\2AH2MBGH\\Liu e.a. - 2012 - Privacy preserving distributed DBSCAN clustering.pdf}
}

@inproceedings{meng_private_2021,
  title = {Private {{Hierarchical Clustering}} and {{Efficient Approximation}}},
  booktitle = {Proceedings of the 2021 on {{Cloud Computing Security Workshop}}},
  author = {Meng, Xianrui and Papadopoulos, Dimitrios and Oprea, Alina and Triandopoulos, Nikos},
  year = {2021},
  month = nov,
  eprint = {1904.04475},
  eprinttype = {arxiv},
  primaryclass = {cs},
  pages = {3--20},
  doi = {10.1145/3474123.3486760},
  abstract = {In collaborative learning, multiple parties contribute their datasets to jointly deduce global machine learning models for numerous predictive tasks. Despite its efficacy, this learning paradigm fails to encompass critical application domains that involve highly sensitive data, such as healthcare and security analytics, where privacy risks limit entities to individually train models using only their own datasets. In this work, we target privacy-preserving collaborative hierarchical clustering. We introduce a formal security definition that aims to achieve the balance between utility and privacy and present a two-party protocol that provably satisfies it. We then extend our protocol with: (i) an optimized version for the single-linkage clustering, and (ii) scalable approximation variants. We implement all our schemes and experimentally evaluate their performance and accuracy on synthetic and real datasets, obtaining very encouraging results. For example, end-to-end execution of our secure approximate protocol for over 1M 10-dimensional data samples requires 35sec of computation and achieves 97.09\% accuracy.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security,Computer Science - Data Structures and Algorithms,Computer Science - Databases},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\T52RI559\\Meng e.a. - 2021 - Private Hierarchical Clustering and Efficient Appr.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\HIH7PC72\\1904.html}
}

@inproceedings{navidan_hide_2022,
  title = {Hide Me {{Behind}} the {{Noise}}: {{Local Differential Privacy}} for {{Indoor Location Privacy}}},
  shorttitle = {Hide Me {{Behind}} the {{Noise}}},
  booktitle = {2022 {{IEEE European Symposium}} on {{Security}} and {{Privacy Workshops}} ({{EuroS}}\&{{PW}})},
  author = {Navidan, Hojjat and Moghtadaiee, Vahideh and Nazaran, Niki and Alishahi, Mina},
  year = {2022},
  month = jun,
  eprint = {2207.00633},
  eprinttype = {arxiv},
  primaryclass = {cs},
  pages = {514--523},
  doi = {10.1109/EuroSPW55150.2022.00061},
  abstract = {The advent of numerous indoor location-based services (LBSs) and the widespread use of many types of mobile devices in indoor environments have resulted in generating a massive amount of people's location data. While geo-spatial data contains sensitive information about personal activities, collecting it in its raw form may lead to the leak of personal information relating to the people, violating their privacy. This paper proposes a novel privacy-aware framework for aggregating the indoor location data employing the Local Differential Privacy (LDP) technique, in which the user location data is changed locally in the user's device and is sent to the aggregator afterward. Therefore, the users' locations are kept hidden from a server or any attackers. The practical feasibility of applying the proposed framework is verified by two real-world datasets. The impact of dataset properties, the privacy mechanisms, and the privacy level on our framework are also investigated. The experimental results indicate that the presented framework can protect the location information of users, and the accuracy of the population frequency of different zones in the indoor area is close to that of the original population frequency with no knowledge about the location of people indoors.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Cryptography and Security},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\BR9UPM87\\Navidan e.a. - 2022 - Hide me Behind the Noise Local Differential Priva.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\L95BWU7X\\2207.html}
}

@misc{neera_private_2021,
  title = {Private and {{Utility Enhanced Recommendations}} with {{Local Differential Privacy}} and {{Gaussian Mixture Model}}},
  author = {Neera, Jeyamohan and Chen, Xiaomin and Aslam, Nauman and Wang, Kezhi and Shu, Zhan},
  year = {2021},
  month = mar,
  number = {arXiv:2102.13453},
  eprint = {2102.13453},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  abstract = {Recommendation systems rely heavily on users behavioural and preferential data (e.g. ratings, likes) to produce accurate recommendations. However, users experience privacy concerns due to unethical data aggregation and analytical practices carried out by the Service Providers (SP). Local differential privacy (LDP) based perturbation mechanisms add noise to users data at user side before sending it to the SP. The SP then uses the perturbed data to perform recommendations. Although LDP protects the privacy of users from SP, it causes a substantial decline in predictive accuracy. To address this issue, we propose an LDP-based Matrix Factorization (MF) with a Gaussian Mixture Model (MoG). The LDP perturbation mechanism, Bounded Laplace (BLP), regulates the effect of noise by confining the perturbed ratings to a predetermined domain. We derive a sufficient condition of the scale parameter for BLP to satisfy \$\textbackslash epsilon\$ LDP. At the SP, The MoG model estimates the noise added to perturbed ratings and the MF algorithm predicts missing ratings. Our proposed LDP based recommendation system improves the recommendation accuracy without violating LDP principles. The empirical evaluations carried out on three real world datasets, i.e., Movielens, Libimseti and Jester, demonstrate that our method offers a substantial increase in predictive accuracy under strong privacy guarantee.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\V7A4IS7T\\Neera e.a. - 2021 - Private and Utility Enhanced Recommendations with .pdf;C\:\\Users\\tjvan\\Zotero\\storage\\5ERLZYHX\\2102.html}
}

@misc{noauthor_wise19_ldppdf_nodate,
  title = {Wise19\_ldp.Pdf},
  journal = {Google Docs},
  howpublished = {https://drive.google.com/file/d/1C4buKvjM6Xf4QxzQfsHScrLtI5hGh830/view?usp=embed\_facebook}
}

@article{rodriguez-barroso_survey_2023,
  title = {Survey on {{Federated Learning Threats}}: Concepts, Taxonomy on Attacks and Defences, Experimental Study and Challenges},
  shorttitle = {Survey on {{Federated Learning Threats}}},
  author = {{Rodr{\'i}guez-Barroso}, Nuria and L{\'o}pez, Daniel Jim{\'e}nez and Luz{\'o}n, M. Victoria and Herrera, Francisco and {Mart{\'i}nez-C{\'a}mara}, Eugenio},
  year = {2023},
  month = feb,
  journal = {Information Fusion},
  volume = {90},
  eprint = {2201.08135},
  eprinttype = {arxiv},
  primaryclass = {cs},
  pages = {148--173},
  issn = {15662535},
  doi = {10.1016/j.inffus.2022.09.011},
  abstract = {Federated learning is a machine learning paradigm that emerges as a solution to the privacy-preservation demands in artificial intelligence. As machine learning, federated learning is threatened by adversarial attacks against the integrity of the learning model and the privacy of data via a distributed approach to tackle local and global learning. This weak point is exacerbated by the inaccessibility of data in federated learning, which makes harder the protection against adversarial attacks and evidences the need to furtherance the research on defence methods to make federated learning a real solution for safeguarding data privacy. In this paper, we present an extensive review of the threats of federated learning, as well as as their corresponding countermeasures, attacks versus defences. This survey provides a taxonomy of adversarial attacks and a taxonomy of defence methods that depict a general picture of this vulnerability of federated learning and how to overcome it. Likewise, we expound guidelines for selecting the most adequate defence method according to the category of the adversarial attack. Besides, we carry out an extensive experimental study from which we draw further conclusions about the behaviour of attacks and defences and the guidelines for selecting the most adequate defence method according to the category of the adversarial attack. This study is finished leading to meditated learned lessons and challenges.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security,Computer Science - Machine Learning},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\WTV9LE2T\\Rodr√≠guez-Barroso e.a. - 2023 - Survey on Federated Learning Threats concepts, ta.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\8R9W2SNA\\2201.html}
}

@article{sun_privbv_2022,
  title = {{{PrivBV}}: {{Distance-aware}} Encoding for Distributed Data with Local Differential Privacy},
  shorttitle = {{{PrivBV}}},
  author = {Sun, Lin and Ping, Guolou and Ye, Xiaojun},
  year = {2022},
  month = apr,
  journal = {Tsinghua Science and Technology},
  volume = {27},
  number = {2},
  pages = {412--421},
  issn = {1007-0214},
  doi = {10.26599/TST.2021.9010027},
  abstract = {Recently, local differential privacy (LDP) has been used as the de facto standard for data sharing and analyzing with high-level privacy guarantees. Existing LDP-based mechanisms mainly focus on learning statistical information about the entire population from sensitive data. For the first time in the literature, we use LDP for distance estimation between distributed datato support more complicated data analysis. Specifically, we propose PrivBV\textemdash a locally differentially private bit vector mechanism with a distance-aware property in the anonymized space. We also present an optimization strategy for reducing privacy leakage in the high-dimensional space. The distance-aware property of PrivBV brings new insights into complicated data analysis in distributed environments. As study cases, we show the feasibility of applying PrivBV to privacy-preserving record linkage and non-interactive clustering. Theoretical analysis and experimental results demonstrate the effectiveness of the proposed scheme.},
  keywords = {Data analysis,Differential privacy,Distributed databases,Encoding,Estimation,local differential privacy,non-interactive clustering,Privacy,privacy-preserving data publishing,Sun},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\B8WDVH5J\\Sun e.a. - 2022 - PrivBV Distance-aware encoding for distributed da.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\JPL3C98G\\9552667.html}
}

@article{sweeney_k-anonymity_2002,
  title = {K-{{ANONYMITY}}: {{A MODEL FOR PROTECTING PRIVACY}}},
  shorttitle = {K-{{ANONYMITY}}},
  author = {Sweeney, Latanya},
  year = {2002},
  month = oct,
  journal = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
  volume = {10},
  number = {05},
  pages = {557--570},
  issn = {0218-4885, 1793-6411},
  doi = {10.1142/S0218488502001648},
  abstract = {Consider a data holder, such as a hospital or a bank, that has a privately held collection of person-specific, field structured data. Suppose the data holder wants to share a version of the data with researchers. How can a data holder release a version of its private data with scientific guarantees that the individuals who are the subjects of the data cannot be re-identified while the data remain practically useful? The solution provided in this paper includes a formal protection model named k-anonymity and a set of accompanying policies for deployment. A release provides k-anonymity protection if the information for each person contained in the release cannot be distinguished from at least k-1 individuals whose information also appears in the release. This paper also examines re-identification attacks that can be realized on releases that adhere to kanonymity unless accompanying policies are respected. The k-anonymity protection model is important because it forms the basis on which the real-world systems known as Datafly, \textmu -Argus and k-Similar provide guarantees of privacy protection.},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\X68B5J59\\Sweeney - 2002 - k-ANONYMITY A MODEL FOR PROTECTING PRIVACY.pdf}
}

@misc{truex_ldp-fed_2020,
  title = {{{LDP-Fed}}: {{Federated Learning}} with {{Local Differential Privacy}}},
  shorttitle = {{{LDP-Fed}}},
  author = {Truex, Stacey and Liu, Ling and Chow, Ka-Ho and Gursoy, Mehmet Emre and Wei, Wenqi},
  year = {2020},
  month = jun,
  number = {arXiv:2006.03637},
  eprint = {2006.03637},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  abstract = {This paper presents LDP-Fed, a novel federated learning system with a formal privacy guarantee using local differential privacy (LDP). Existing LDP protocols are developed primarily to ensure data privacy in the collection of single numerical or categorical values, such as click count in Web access logs. However, in federated learning model parameter updates are collected iteratively from each participant and consist of high dimensional, continuous values with high precision (10s of digits after the decimal point), making existing LDP protocols inapplicable. To address this challenge in LDP-Fed, we design and develop two novel approaches. First, LDP-Fed's LDP Module provides a formal differential privacy guarantee for the repeated collection of model training parameters in the federated training of large-scale neural networks over multiple individual participants' private datasets. Second, LDP-Fed implements a suite of selection and filtering techniques for perturbing and sharing select parameter updates with the parameter server. We validate our system deployed with a condensed LDP protocol in training deep neural networks on public data. We compare this version of LDP-Fed, coined CLDP-Fed, with other state-of-the-art approaches with respect to model accuracy, privacy preservation, and system capabilities.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\YPUHCDTN\\Truex e.a. - 2020 - LDP-Fed Federated Learning with Local Differentia.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\7KYXQWVT\\2006.html}
}

@article{wang_comprehensive_2020,
  title = {A {{Comprehensive Survey}} on {{Local Differential Privacy Toward Data Statistics}} and {{Analysis}} in {{Crowdsensing}}},
  author = {Wang, Teng and Zhang, Xuefeng and Feng, Jingyu and Yang, Xinyu},
  year = {2020},
  journal = {CoRR},
  volume = {abs/2010.05253},
  eprint = {2010.05253},
  eprinttype = {arxiv},
  archiveprefix = {arXiv}
}

@article{xia_distributed_2020,
  title = {Distributed {{K-Means}} Clustering Guaranteeing Local Differential Privacy},
  author = {Xia, Chang and Hua, Jingyu and Tong, Wei and Zhong, Sheng},
  year = {2020},
  month = mar,
  journal = {Computers \& Security},
  volume = {90},
  pages = {101699},
  issn = {0167-4048},
  doi = {10.1016/j.cose.2019.101699},
  abstract = {In many cases, a service provider might require to aggregate data from end-users to perform mining tasks such as K-means clustering. Nevertheless, since such data often contain sensitive information. In this paper, we propose the first locally differentially private K-means mechanism under this distributed scenario. Differing from standard differentially private clustering mechanisms, the proposed mechanism doesn't need any trusted third party to collect and preprocess users data. Our mechanism first perturbs users data locally to satisfy local differential privacy~(LDP). Then it revises the traditional K-means algorithm to allow the service provider to obtain high-quality clustering results by collaborating with users based on the highly perturbed data. We prove that our mechanism can enable high utility clustering while guaranteeing local differential privacy for each user. We also propose an extended mechanism to improve our basic model in terms of privacy and utility. In this mechanism, we perturb both users' sensitive data and the intermediate results of users' clusters in each iteration. Moreover, we consider a more general setting where the users may have different privacy requirements. Extensive experiments are conducted on two real-world datasets, and the results show that our proposal can well preserve the quality of clustering results.},
  keywords = {Differential privacy,Distributed clustering,K-Means;,Machine learning,Randomized response},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\N8H23NMU\\Xia e.a. - 2020 - Distributed K-Means clustering guaranteeing local .pdf}
}

@article{yan_perturb_2022,
  title = {Perturb and Optimize Users' Location Privacy Using Geo-Indistinguishability and Location Semantics},
  author = {Yan, Yan and Xu, Fei and Mahmood, Adnan and Dong, Zhuoyue and Sheng, Quan Z.},
  year = {2022},
  month = nov,
  journal = {Scientific Reports},
  volume = {12},
  number = {1},
  pages = {20445},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-24893-0},
  abstract = {Location-based services (LBS) are capable of providing location-based information retrieval, traffic navigation, entertainment services, emergency rescues, and several similar services primarily on the premise of the geographic location of users or mobile devices. However, in the process of introducing a new user experience, it is also easy to expose users' specific location which can result in more private information leakage. Hence, the protection of location privacy remains one of the critical issues of the location-based services. Moreover, the areas where humans work and live have different location semantics and sensitivities according to their different social functions. Although the privacy protection of a user's real location can be achieved by the perturbation algorithm, the attackers may employ the semantics information of the perturbed location to infer a user's real location semantics in an attempt to spy on a user's privacy to certain extent. In order to mitigate the above semantics inference attack, and further improve the quality of the location-based services, this paper hereby proposes a user side location perturbation and optimization algorithm based on geo-indistinguishability and location semantics. The perturbation area satisfying geo-indistinguishability is thus generated according to the planar Laplace mechanism and optimized by combining the semantics information and time characteristics of the location. The optimum perturbed location that is able to satisfy the minimum loss of location-based service quality is selected via a linear programming method, and can be employed to replace the real location of the user so as to prevent the leakage of the privacy. Experimental comparison of the actual road network and location semantics dataset manifests that the proposed method reduces approximately 37\% perturbation distance in contrast to the other state-of-the-art methods, maintains considerably lower similarity of location semantics, and improves region counting query accuracy by a margin of around 40\%.}
}

@article{yan_perturb_2022-1,
  title = {Perturb and Optimize Users' Location Privacy Using Geo-Indistinguishability and Location Semantics},
  author = {Yan, Yan and Xu, Fei and Mahmood, Adnan and Dong, Zhuoyue and Sheng, Quan Z.},
  year = {2022},
  month = nov,
  journal = {Scientific Reports},
  volume = {12},
  number = {1},
  pages = {20445},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-24893-0},
  abstract = {Location-based services (LBS) are capable of providing location-based information retrieval, traffic navigation, entertainment services, emergency rescues, and several similar services primarily on the premise of the geographic location of users or mobile devices. However, in the process of introducing a new user experience, it is also easy to expose users' specific location which can result in more private information leakage. Hence, the protection of location privacy remains one of the critical issues of the location-based services. Moreover, the areas where humans work and live have different location semantics and sensitivities according to their different social functions. Although the privacy protection of a user's real location can be achieved by the perturbation algorithm, the attackers may employ the semantics information of the perturbed location to infer a user's real location semantics in an attempt to spy on a user's privacy to certain extent. In order to mitigate the above semantics inference attack, and further improve the quality of the location-based services, this paper hereby proposes a user side location perturbation and optimization algorithm based on geo-indistinguishability and location semantics. The perturbation area satisfying geo-indistinguishability is thus generated according to the planar Laplace mechanism and optimized by combining the semantics information and time characteristics of the location. The optimum perturbed location that is able to satisfy the minimum loss of location-based service quality is selected via a linear programming method, and can be employed to replace the real location of the user so as to prevent the leakage of the privacy. Experimental comparison of the actual road network and location semantics dataset manifests that the proposed method reduces approximately 37\% perturbation distance in contrast to the other state-of-the-art methods, maintains considerably lower similarity of location semantics, and improves region counting query accuracy by a margin of around 40\%.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Energy science and technology,Mathematics and computing},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\IB8NW2MX\\Yan e.a. - 2022 - Perturb and optimize users‚Äô location privacy using.pdf}
}

@misc{yang_local_2020,
  title = {Local {{Differential Privacy}} and {{Its Applications}}: {{A Comprehensive Survey}}},
  shorttitle = {Local {{Differential Privacy}} and {{Its Applications}}},
  author = {Yang, Mengmeng and Lyu, Lingjuan and Zhao, Jun and Zhu, Tianqing and Lam, Kwok-Yan},
  year = {2020},
  month = aug,
  number = {arXiv:2008.03686},
  eprint = {2008.03686},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  abstract = {With the fast development of Information Technology, a tremendous amount of data have been generated and collected for research and analysis purposes. As an increasing number of users are growing concerned about their personal information, privacy preservation has become an urgent problem to be solved and has attracted significant attention. Local differential privacy (LDP), as a strong privacy tool, has been widely deployed in the real world in recent years. It breaks the shackles of the trusted third party, and allows users to perturb their data locally, thus providing much stronger privacy protection. This survey provides a comprehensive and structured overview of the local differential privacy technology. We summarise and analyze state-of-the-art research in LDP and compare a range of methods in the context of answering a variety of queries and training different machine learning models. We discuss the practical deployment of local differential privacy and explore its application in various domains. Furthermore, we point out several research gaps, and discuss promising future research directions.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Cryptography and Security},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\D49D6UZQ\\Yang e.a. - 2020 - Local Differential Privacy and Its Applications A.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\4SNPVQXE\\2008.html}
}
