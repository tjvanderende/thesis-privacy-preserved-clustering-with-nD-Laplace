@inproceedings{10.1145/1835804.1835848,
  title = {Unsupervised Feature Selection for Multi-Cluster Data},
  booktitle = {Proceedings of the 16th {{ACM SIGKDD}} International Conference on Knowledge Discovery and Data Mining},
  author = {Cai, Deng and Zhang, Chiyuan and He, Xiaofei},
  year = {2010},
  series = {{{KDD}} '10},
  pages = {333--342},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1835804.1835848},
  abstract = {In many data analysis tasks, one is often confronted with very high dimensional data. Feature selection techniques are designed to find the relevant feature subset of the original features which can facilitate clustering, classification and retrieval. In this paper, we consider the feature selection problem in unsupervised learning scenario, which is particularly difficult due to the absence of class labels that would guide the search for relevant information. The feature selection problem is essentially a combinatorial optimization problem which is computationally expensive. Traditional unsupervised feature selection methods address this issue by selecting the top ranked features based on certain scores computed independently for each feature. These approaches neglect the possible correlation between different features and thus can not produce an optimal feature subset. Inspired from the recent developments on manifold learning and L1-regularized models for subset selection, we propose in this paper a new approach, called Multi-Cluster Feature Selection (MCFS), for unsupervised feature selection. Specifically, we select those features such that the multi-cluster structure of the data can be best preserved. The corresponding optimization problem can be efficiently solved since it only involves a sparse eigen-problem and a L1-regularized least squares problem. Extensive experimental results over various real-life data sets have demonstrated the superiority of the proposed algorithm.},
  isbn = {978-1-4503-0055-1},
  keywords = {clustering,feature selection,unsupervised}
}

@article{9646489,
  title = {{{3D}} Geo-Indistinguishability for Indoor Location-Based Services},
  author = {Min, Minghui and Xiao, Liang and Ding, Jiahao and Zhang, Hongliang and Li, Shiyin and Pan, Miao and Han, Zhu},
  year = {2022},
  journal = {IEEE Transactions on Wireless Communications},
  volume = {21},
  number = {7},
  pages = {4682--4694},
  doi = {10.1109/TWC.2021.3132464},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\QPJZTQGX\\Min e.a. - 2022 - 3D geo-indistinguishability for indoor location-ba.pdf}
}

@inproceedings{9679364,
  title = {Private Distributed {{K-means}} Clustering on Interval Data},
  booktitle = {2021 {{IEEE}} International Performance, Computing, and Communications Conference ({{IPCCC}})},
  author = {Huang, D. and Yao, X. and An, S. and Ren, S.},
  year = {2021},
  month = oct,
  pages = {1--9},
  publisher = {{IEEE Computer Society}},
  address = {{Los Alamitos, CA, USA}},
  doi = {10.1109/IPCCC51483.2021.9679364},
  abstract = {K-means clustering has been heavily employed to mine valuable insights from interval data. Nevertheless, serious privacy leakage concerns are stumbling blocks impeding its widespread application. To quantify the privacy of small and large-scale interval data, we introduce two notions of \&amp;\#x03B1;-Condensed Local Differential Privacy and \&amp;\#x03F5;-Local Differential Privacy, and propose two distance-aware perturbation mechanisms of \&amp;\#x03B1;-exponential and square wave mechanisms. Rigorous theoretical analysis proves that our proposed mechanisms satisfy these two privacy notions. The experimental results built on multiple synthesized and real datasets show that our proposed mechanisms can provide more accurate clustering results than prior work, such as Randomized Response, Generalized Randomized Response, and Optimized Local Hash.},
  keywords = {conferences,correlation,differential privacy,distributed databases,perturbation methods,privacy},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\6F8LBU8D\\Huang e.a. - 2021 - Private distributed K-means clustering on interval.pdf}
}

@article{ahmed_k-means_2020-1,
  title = {The K-Means Algorithm: {{A}} Comprehensive Survey and Performance Evaluation},
  author = {Ahmed, Mohiuddin and Seraj, Raihan and Islam, Syed Mohammed Shamsul},
  year = {2020},
  journal = {Electronics},
  volume = {9},
  number = {8},
  pages = {1295},
  publisher = {{MDPI}},
  issn = {2079-9292}
}

@misc{ahuja_utility-preserving_2019,
  title = {A {{Utility-Preserving}} and {{Scalable Technique}} for {{Protecting Location Data}} with {{Geo-Indistinguishability}}},
  author = {Ahuja, Ritesh and Ghinita, Gabriel and Shahabi, Cyrus},
  year = {2019},
  publisher = {{OpenProceedings.org}},
  doi = {10.5441/002/EDBT.2019.20},
  urldate = {2023-02-26},
  abstract = {Location-based apps provide users with personalized services tailored to their geographical position. This is highly-beneficial for mobile users, who are able to find points of interest close to their location, or connect with nearby friends. However, sharing location data with service providers also introduces privacy concerns. An adversary with access to fine-grained user locations can infer private details about individuals. Geo-indistinguishability (GeoInd) adapts the popular differential privacy (DP) model to make it suitable for protecting users' location information. However, existing techniques that implement GeoInd have major drawbacks. Some solutions, such as the planar Laplace mechanism, significantly lower data utility by adding excessive noise. Other approaches, such as the optimal mechanism, achieve good utility, but only work for small sets of candidate locations due to the use of computationally-expensive linear programming. In most cases, locations are used to answer online queries, so a quick response time is essential. In this paper, we propose a technique that achieves GeoInd and scales to large datasets while preserving data utility. Our central idea is to use the composability property of GeoInd to create a multiple-step algorithm that can be used in conjunction with a spatial index. We preserve utility by applying accurate GeoInd mechanisms and we achieve scalability by pruning the solution search space with the help of the index when seeking high-utility outcomes. Our extensive performance evaluation on top of real location datasets from social media apps shows that the proposed technique outperforms significantly the benchmark in terms of utility and/or computational overhead.},
  langid = {english},
  keywords = {Database Technology},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\VN38ZL5N\\Ahuja et al. - 2019 - A Utility-Preserving and Scalable Technique for Pr.pdf}
}

@article{alvim_local_nodate,
  title = {Local {{Differential Privacy}} on {{Metric Spaces}}: Optimizing the Trade-off with Utility},
  author = {Alvim, Mario S and Chatzikokolakis, Konstantinos and Palamidessi, Catuscia and Pazii, Anna},
  abstract = {Local differential privacy (LPD) is a distributed variant of differential privacy (DP) in which the obfuscation of the sensitive information is done at the level of the individual records, and in general it is used to sanitize data that are collected for statistical purposes. LPD has the advantage it does not need to assume a trusted third party. On the other hand LDP in general requires more noise than DP to achieve the same level of protection, with negative consequences on the utility. In practice, utility becomes acceptable only on very large collections of data, and this is the reason why LDP is especially successful among big companies such as Apple and Google, which can count on a huge number of users. In this paper, we propose a variant of LDP suitable for metric spaces, such as location data or energy consumption data, and we show that it provides a much better utility for the same level of privacy.},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\VXCWK8LH\\Alvim et al. - Local Differential Privacy on Metric Spaces optim.pdf}
}

@incollection{bailey_privacy_2016,
  title = {Privacy {{Aware K-Means Clustering}} with {{High Utility}}},
  booktitle = {Advances in {{Knowledge Discovery}} and {{Data Mining}}},
  author = {Nguyen, Thanh Dai and Gupta, Sunil and Rana, Santu and Venkatesh, Svetha},
  editor = {Bailey, James and Khan, Latifur and Washio, Takashi and Dobbie, Gill and Huang, Joshua Zhexue and Wang, Ruili},
  year = {2016},
  volume = {9652},
  pages = {388--400},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-31750-2_31},
  urldate = {2023-03-15},
  isbn = {978-3-319-31749-6 978-3-319-31750-2},
  langid = {english}
}

@misc{bozdemir_privacy-preserving_nodate,
  title = {Privacy-Preserving {{Density-based Clustering}}},
  author = {Bozdemir, Beyza and Canard, S{\'e}bastien and Ermis, Orhan and M{\"o}llering, Helen and {\"O}nen, Melek and Schneider, Thomas},
  urldate = {2023-03-30},
  abstract = {Clustering is an unsupervised machine learning technique that outputs clusters containing similar data items. In this work, we investigate privacy-preserving density-based clustering which is, for example, used in financial analytics and medical diagnosis. When (multiple) data owners collaborate or outsource the computation, privacy concerns arise. To address this problem, we design, implement, and evaluate the first practical and fully private density-based clustering scheme based on secure two-party computation. Our protocol privately executes the DBSCAN algorithm without disclosing any information (including the number and size of clusters). It can be used for private clustering between two parties as well as for private outsourcing of an arbitrary number of data owners to two non-colluding servers. Our implementation of the DBSCAN algorithm privately clusters data sets with 400 elements in 7 minutes on commodity hardware. Thereby, it flexibly determines the number of required clusters and is insensitive to outliers, while being only factor 19x slower than today's fastest private K-means protocol (Mohassel et al., PETS'20) which can only be used for specific data sets. We then show how to transfer our newly designed protocol to related clustering algorithms by introducing a private approximation of the TRACLUS algorithm for trajectory clustering which has interesting real-world applications like financial time series forecasts and the investigation of the spread of a disease like COVID-19.},
  keywords = {Clustering,Private Machine Learning,Secure Computation}
}

@inproceedings{cai_dp-ap_2020,
  title = {{{DP-AP}}: {{Differential Privacy-Preserving Affinity Propagation Clustering}}},
  shorttitle = {{{DP-AP}}},
  booktitle = {2020 {{IEEE}} 14th {{International Conference}} on {{Big Data Science}} and {{Engineering}} ({{BigDataSE}})},
  author = {Cai, Hanbo and Wang, Jinyan and Liu, Xiaohong and Li, Xianxian},
  year = {2020},
  month = dec,
  pages = {73--79},
  publisher = {{IEEE}},
  address = {{Guangzhou, China}},
  doi = {10.1109/BigDataSE50710.2020.00018},
  urldate = {2022-12-22},
  isbn = {978-1-66540-396-2},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\LH7Y4ZSA\\Cai e.a. - 2020 - DP-AP Differential Privacy-Preserving Affinity Pr.pdf}
}

@article{calinski_dendrite_1974-1,
  title = {A Dendrite Method for Cluster Analysis},
  author = {Cali{\'n}ski, Tadeusz and Harabasz, Jerzy},
  year = {1974},
  journal = {Communications in Statistics-theory and Methods},
  volume = {3},
  number = {1},
  pages = {1--27},
  publisher = {{Taylor \& Francis}},
  issn = {0090-3272}
}

@article{chatzikokolakis_constructing_2015,
  title = {Constructing Elastic Distinguishability Metrics for Location Privacy},
  author = {Chatzikokolakis, Konstantinos and Palamidessi, Catuscia and Stronati, Marco},
  year = {2015},
  month = jun,
  journal = {Proceedings on Privacy Enhancing Technologies},
  volume = {2015},
  number = {2},
  eprint = {1503.00756},
  primaryclass = {cs},
  pages = {156--170},
  issn = {2299-0984},
  doi = {10.1515/popets-2015-0023},
  urldate = {2023-03-10},
  abstract = {With the increasing popularity of hand-held devices, location-based applications and services have access to accurate and real-time location information, raising serious privacy concerns for their users. The recently introduced notion of geo-indistinguishability tries to address this problem by adapting the well-known concept of differential privacy to the area of location-based systems. Although geo-indistinguishability presents various appealing aspects, it has the problem of treating space in a uniform way, imposing the addition of the same amount of noise everywhere on the map. In this paper we propose a novel elastic distinguishability metric that warps the geometrical distance, capturing the different degrees of density of each area. As a consequence, the obtained mechanism adapts the level of noise while achieving the same degree of privacy everywhere. We also show how such an elastic metric can easily incorporate the concept of a "geographic fence" that is commonly employed to protect the highly recurrent locations of a user, such as his home or work. We perform an extensive evaluation of our technique by building an elastic metric for Paris' wide metropolitan area, using semantic information from the OpenStreetMap database. We compare the resulting mechanism against the Planar Laplace mechanism satisfying standard geo-indistinguishability, using two real-world datasets from the Gowalla and Brightkite location-based social networks. The results show that the elastic mechanism adapts well to the semantics of each area, adjusting the noise as we move outside the city center, hence offering better overall privacy.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Cryptography and Security},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\BBGUL4GI\\Chatzikokolakis e.a. - 2015 - Constructing elastic distinguishability metrics fo.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\FI7V7IG2\\1503.html}
}

@article{chatzikokolakis_efficient_2017,
  title = {Efficient Utility Improvement for Location Privacy},
  author = {Chatzikokolakis, Konstantinos and Elsalamouny, Ehab and Palamidessi, Catuscia},
  year = {2017},
  journal = {Proceedings on Privacy Enhancing Technologies},
  volume = {2017},
  number = {4},
  pages = {308--328}
}

@article{chatzikokolakis_practical_nodate,
  title = {Practical {{Mechanisms}} for {{Location Privacy}}},
  author = {Chatzikokolakis, Konstantinos and ElSalamouny, Ehab and Palamidessi, Catuscia},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\355U7PAM\\Chatzikokolakis et al. - Practical Mechanisms for Location Privacy.pdf}
}

@article{craenendonck_using_nodate,
  title = {Using {{Internal Validity Measures}} to {{Compare Clustering Algorithms}}},
  author = {Craenendonck, Toon Van and Blockeel, Hendrik},
  abstract = {Recently, significant effort has been made to automate the machine learning process in the context of supervised learning. This automation includes, amongst other things, the selection of an appropriate learning algorithm and corresponding hyperparameters for a particular learning problem. In contrast, such problems are much less studied for unsupervised tasks such as clustering. Nevertheless, users who want to cluster a data set are confronted with similar problems: a clustering algorithm should be selected from the wide variety of available algorithms, and usually some hyperparameters have to be set. In a supervised setting, model search is guided by performance measures that rely on known class labels, such as accuracy. However, these measures are not applicable to clustering as labels are usually not available. Instead, one might use internal validity measures that only rely on properties intrinsic to the data set. Several such measures are defined, and in this paper we study the usefulness of four of them for model selection. We perform experiments with these measures in combination with six clustering algorithms. While some measures are suited to use in hyperparameter optimization for some specific algorithms, we conclude that none of them is suited to compare across very different clustering algorithms.},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\3DJL2JPQ\\Craenendonck en Blockeel - Using Internal Validity Measures to Compare Cluste.pdf}
}

@article{davies_cluster_1979,
  title = {A Cluster Separation Measure},
  author = {Davies, David L and Bouldin, Donald W},
  year = {1979},
  journal = {IEEE transactions on pattern analysis and machine intelligence},
  number = {2},
  pages = {224--227},
  publisher = {{IEEE}},
  issn = {0162-8828}
}

@article{DBLP:journals/corr/abs-1212-1984,
  title = {Geo-Indistinguishability: {{Differential}} Privacy for Location-Based Systems},
  author = {Andr{\'e}s, Miguel E. and Bordenabe, Nicol{\'a}s Emilio and Chatzikokolakis, Konstantinos and Palamidessi, Catuscia},
  year = {2012},
  journal = {CoRR},
  volume = {abs/1212.1984},
  eprint = {1212.1984},
  archiveprefix = {arxiv},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/journals/corr/abs-1212-1984.bib},
  timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\HVVT4GUR\\Andrés e.a. - 2012 - Geo-indistinguishability Differential privacy for.pdf}
}

@article{del_rey_comprehensive_2020-1,
  title = {A {{Comprehensive Survey}} on {{Local Differential Privacy}}},
  author = {Xiong, Xingxing and Liu, Shubo and Li, Dan and Cai, Zhaohui and Niu, Xiaoguang},
  editor = {Del Rey, Angel M.},
  year = {2020},
  month = oct,
  journal = {Security and Communication Networks},
  volume = {2020},
  pages = {8829523},
  publisher = {{Hindawi}},
  issn = {1939-0114},
  doi = {10.1155/2020/8829523},
  abstract = {With the advent of the era of big data, privacy issues have been becoming a hot topic in public. Local differential privacy (LDP) is a state-of-the-art privacy preservation technique that allows to perform big data analysis (e.g., statistical estimation, statistical learning, and data mining) while guaranteeing each individual participant\&\#x2019;s privacy. In this paper, we present a comprehensive survey of LDP. We first give an overview on the fundamental knowledge of LDP and its frameworks. We then introduce the mainstream privatization mechanisms and methods in detail from the perspective of frequency oracle and give insights into recent studied on private basic statistical estimation (e.g., frequency estimation and mean estimation) and complex statistical estimation (e.g., multivariate distribution estimation and private estimation over complex data) under LDP. Furthermore, we present current research circumstances on LDP including the private statistical learning/inferencing, private statistical data analysis, privacy amplification techniques for LDP, and some application fields under LDP. Finally, we identify future research directions and open challenges for LDP. This survey can serve as a good reference source for the research of LDP to deal with various privacy-related scenarios to be encountered in practice.}
}

@article{dong_limitations_2018,
  title = {On the Limitations of Existing Notions of Location Privacy},
  author = {Dong, Kai and Guo, Taolin and Ye, Haibo and Li, Xuansong and Ling, Zhen},
  year = {2018},
  month = sep,
  journal = {Future Generation Computer Systems},
  volume = {86},
  pages = {1513--1522},
  issn = {0167739X},
  doi = {10.1016/j.future.2017.05.045},
  urldate = {2023-03-16},
  abstract = {In the context of a single report of location information, existing researches define location privacy by adversary's uncertainty, inaccuracy, or incorrectness of the estimation, or by geo-indistinguishability which is a generalization of differential privacy. Each of these existing notions has problems in some specific scenarios. In this paper we illustrate the limitations of existing notions by constructing such scenarios, and introduce a formal definition on location privacy by quantifying the distance between the prior and posterior distribution over the possible locations. Further more, we show how to construct a near-optimal obfuscation mechanism by solving an optimization problem. We compare our proposed mechanism with the Laplace noise based geo-indistinguishable mechanism, and Shokri's optimal obfuscation mechanism, using both our proposed privacy metric and the traditional metric based on the estimated distance errors. The results show that our proposed metric better describes location privacy and our proposed mechanism makes a better tradeoff between privacy and utility.},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\C45AELKE\\Dong et al. - 2018 - On the limitations of existing notions of location.pdf}
}

@inproceedings{dwork_differential_2006,
  title = {Differential Privacy},
  booktitle = {Automata, {{Languages}} and {{Programming}}: 33rd {{International Colloquium}}, {{ICALP}} 2006, {{Venice}}, {{Italy}}, {{July}} 10-14, 2006, {{Proceedings}}, {{Part II}} 33},
  author = {Dwork, Cynthia},
  year = {2006},
  pages = {1--12},
  publisher = {{Springer}},
  isbn = {3-540-35907-9}
}

@article{franti_centroid_2014,
  title = {Centroid Index: {{Cluster}} Level Similarity Measure},
  shorttitle = {Centroid Index},
  author = {Fr{\"a}nti, Pasi and Rezaei, Mohammad and Zhao, Qinpei},
  year = {2014},
  month = sep,
  journal = {Pattern Recognition},
  volume = {47},
  number = {9},
  pages = {3034--3045},
  issn = {00313203},
  doi = {10.1016/j.patcog.2014.03.017},
  urldate = {2023-03-22},
  abstract = {In clustering algorithm, one of the main challenges is to solve the global allocation of the clusters instead of just local tuning of the partition borders. Despite this, all external cluster validity indexes calculate only point-level differences of two partitions without any direct information about how similar their cluster-level structures are. In this paper, we introduce a cluster level index called centroid index. The measure is intuitive, simple to implement, fast to compute and applicable in case of model mismatch as well. To a certain extent, we expect it to generalize other clustering models beyond the centroid-based k-means as well.},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\4IJJ6ZVN\\Fränti e.a. - 2014 - Centroid index Cluster level similarity measure.pdf}
}

@inproceedings{friedman_data_2010,
  title = {Data Mining with Differential Privacy},
  booktitle = {Proceedings of the 16th {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery and Data Mining},
  author = {Friedman, Arik and Schuster, Assaf},
  year = {2010},
  month = jul,
  pages = {493--502},
  publisher = {{ACM}},
  address = {{Washington DC USA}},
  doi = {10.1145/1835804.1835868},
  urldate = {2023-03-30},
  abstract = {We consider the problem of data mining with formal privacy guarantees, given a data access interface based on the differential privacy framework. Differential privacy requires that computations be insensitive to changes in any particular individual's record, thereby restricting data leaks through the results. The privacy preserving interface ensures unconditionally safe access to the data and does not require from the data miner any expertise in privacy. However, as we show in the paper, a naive utilization of the interface to construct privacy preserving data mining algorithms could lead to inferior data mining results. We address this problem by considering the privacy and the algorithmic requirements simultaneously, focusing on decision tree induction as a sample application. The privacy mechanism has a profound effect on the performance of the methods chosen by the data miner. We demonstrate that this choice could make the difference between an accurate classifier and a completely useless one. Moreover, an improved algorithm can achieve the same level of accuracy and privacy as the naive implementation but with an order of magnitude fewer learning samples.},
  isbn = {978-1-4503-0055-1},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\F635ZNB5\\Friedman en Schuster - 2010 - Data mining with differential privacy.pdf}
}

@article{hassani_using_2017,
  title = {Using Internal Evaluation Measures to Validate the Quality of Diverse Stream Clustering Algorithms},
  author = {Hassani, Marwan and Seidl, Thomas},
  year = {2017},
  month = aug,
  journal = {Vietnam Journal of Computer Science},
  volume = {4},
  number = {3},
  pages = {171--183},
  issn = {2196-8896},
  doi = {10.1007/s40595-016-0086-9},
  abstract = {Measuring the quality of a clustering algorithm has shown to be as important as the algorithm itself. It is a crucial part of choosing the clustering algorithm that performs best for an input data. Streaming input data have many features that make them much more challenging than static ones. They are endless, varying and emerging with high speeds. This raised new challenges for the clustering algorithms as well as for their evaluation measures. Up till now, external evaluation measures were exclusively used for validating stream clustering algorithms. While external validation requires a ground truth which is not provided in most applications, particularly in the streaming case, internal clustering validation is efficient and realistic. In this article, we analyze the properties and performances of eleven internal clustering measures. In particular, we apply these measures to carefully synthesized stream scenarios to reveal how they react to clusterings on evolving data streams using both k-means-based and density-based clustering algorithms. A series of experimental results show that different from the case with static data, the Calinski-Harabasz index performs the best in coping with common aspects and errors of stream clustering for k-means-based algorithms, while the revised validity index performs the best for density-based ones.}
}

@inproceedings{he_laplacian_2005,
  title = {Laplacian {{Score}} for {{Feature Selection}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {He, Xiaofei and Cai, Deng and Niyogi, Partha},
  year = {2005},
  volume = {18},
  publisher = {{MIT Press}},
  urldate = {2023-02-15},
  abstract = {In supervised learning scenarios, feature selection has been studied widely in the literature. Selecting features in unsupervised learning scenarios is a much harder problem, due to the absence of class labels that would guide the search for relevant information. And, almost all of previous unsupervised feature selection methods are "wrapper" techniques that require a learning algorithm to evaluate the candidate feature subsets. In this paper, we propose a "filter" method for feature selection which is independent of any learning algorithm. Our method can be performed in either supervised or unsupervised fashion. The proposed method is based on the observation that, in many real world classification problems, data from the same class are often close to each other. The importance of a feature is evaluated by its power of locality preserving, or, Laplacian Score. We compare our method with data variance (unsupervised) and Fisher score (supervised) on two data sets. Experimental results demonstrate the effectiveness and efficiency of our algorithm.},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\MEYJS6AX\\He e.a. - 2005 - Laplacian Score for Feature Selection.pdf}
}

@article{hubert_comparing_1985-1,
  title = {Comparing Partitions},
  author = {Hubert, Lawrence and Arabie, Phipps},
  year = {1985},
  journal = {Journal of classification},
  volume = {2},
  pages = {193--218},
  publisher = {{Springer}},
  issn = {0176-4268}
}

@article{jayaraman_evaluating_nodate,
  title = {Evaluating {{Differentially Private Machine Learning}} in {{Practice}}},
  author = {Jayaraman, Bargav and Evans, David},
  abstract = {Differential privacy is a strong notion for privacy that can be used to prove formal guarantees, in terms of a privacy budget, , about how much information is leaked by a mechanism. When used in privacy-preserving machine learning, the goal is typically to limit what can be inferred from the model about individual training records. However, the calibration of the privacy budget is not well understood. Implementations of privacy-preserving machine learning often select large values of in order to get acceptable utility of the model, with little understanding of the impact of such choices on meaningful privacy. Moreover, in scenarios where iterative learning procedures are used, relaxed definitions of differential privacy are often used which appear to reduce the needed privacy budget but present poorly understood trade-offs between privacy and utility. In this paper, we quantify the impact of these choices on privacy in experiments with logistic regression and neural network models. Our main finding is that there is no way to obtain privacy for free\textemdash relaxed definitions of differential privacy that reduce the amount of noise needed to improve utility also increase the measured privacy leakage. Current mechanisms for differentially private machine learning rarely offer acceptable utility-privacy trade-offs for complex learning tasks: settings that provide limited accuracy loss provide little effective privacy, and settings that provide strong privacy result in useless models.},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\SL2RLCCC\\Jayaraman en Evans - Evaluating Diﬀerentially Private Machine Learning .pdf}
}

@article{kodinariya_review_2013,
  title = {Review on Determining Number of {{Cluster}} in {{K-Means Clustering}}},
  author = {Kodinariya, Trupti M and Makwana, Prashant R},
  year = {2013},
  journal = {International Journal},
  volume = {1},
  number = {6},
  pages = {90--95}
}

@article{kohavi_wrappers_1997,
  title = {Wrappers for Feature Subset Selection},
  author = {Kohavi, Ron and John, George H.},
  year = {1997},
  month = dec,
  journal = {Artificial Intelligence},
  series = {Relevance},
  volume = {97},
  number = {1},
  pages = {273--324},
  issn = {0004-3702},
  doi = {10.1016/S0004-3702(97)00043-X},
  urldate = {2023-02-15},
  abstract = {In the feature subset selection problem, a learning algorithm is faced with the problem of selecting a relevant subset of features upon which to focus its attention, while ignoring the rest. To achieve the best possible performance with a particular learning algorithm on a particular training set, a feature subset selection method should consider how the algorithm and the training set interact. We explore the relation between optimal feature subset selection and relevance. Our wrapper method searches for an optimal feature subset tailored to a particular algorithm and a domain. We study the strengths and weaknesses of the wrapper approach and show a series of improved designs. We compare the wrapper approach to induction without feature subset selection and to Relief, a filter approach to feature subset selection. Significant improvement in accuracy is achieved for some datasets for the two families of induction algorithms used: decision trees and Naive-Bayes.},
  langid = {english},
  keywords = {Classification,Feature selection,Filter,Wrapper},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\5J9L28B4\\Kohavi en John - 1997 - Wrappers for feature subset selection.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\K2MHWNY7\\S000437029700043X.html}
}

@article{lehtonen_lambert_2016,
  title = {The {{Lambert W}} Function in Ecological and Evolutionary Models},
  author = {Lehtonen, Jussi},
  year = {2016},
  journal = {Methods in Ecology and Evolution},
  volume = {7},
  number = {9},
  pages = {1110--1118},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.12568},
  urldate = {2023-03-09},
  abstract = {The Lambert W function is a mathematical function with a long history, but which was named and rigorously defined relatively recently. It is closely related to the logarithmic function and arises from many models in the natural sciences, including a surprising number of problems in ecology and evolution. I describe the basic properties of the function and present examples of its application to models of ecological and evolutionary processes. The Lambert W function makes it possible to solve explicitly several models where this is not possible with elementary functions. I present examples of such models from existing literature, as well as novel models. Solving models explicitly with the Lambert W function can provide deeper insight and a new point of view on a biological problem. Explicit solutions with the Lambert W function are easily amenable to further mathematical operations, such as differentiation and integration. These advantages apply to a wide range of models, from the marginal value theorem to population growth rates and disease epidemics.},
  langid = {english},
  keywords = {calculus,explicit solution,fertilization kinetics,Lambert W function,Lotka–Volterra model,marginal value theorem,mate search,modelling,population growth rate,SIR model},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\S77QF2U8\\Lehtonen - 2016 - The Lambert W function in ecological and evolution.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\QYQTRQAH\\2041-210X.html}
}

@inproceedings{m_alvim_invited_2018,
  title = {Invited {{Paper}}: {{Local Differential Privacy}} on {{Metric Spaces}}: {{Optimizing}} the {{Trade-Off}} with {{Utility}}},
  booktitle = {2018 {{IEEE}} 31st {{Computer Security Foundations Symposium}} ({{CSF}})},
  author = {{M. Alvim} and {K. Chatzikokolakis} and {C. Palamidessi} and {A. Pazii}},
  year = {2018},
  month = jul,
  pages = {262--267},
  doi = {10.1109/CSF.2018.00026},
  isbn = {2374-8303}
}

@article{mitra_unsupervised_2002,
  title = {Unsupervised Feature Selection Using Feature Similarity},
  author = {Mitra, P. and Murthy, C.A. and Pal, S.K.},
  year = {2002},
  month = mar,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {24},
  number = {3},
  pages = {301--312},
  issn = {01628828},
  doi = {10.1109/34.990133},
  urldate = {2023-02-15},
  abstract = {\DH In this article, we describe an unsupervised feature selection algorithm suitable for data sets, large in both dimension and size. The method is based on measuring similarity between features whereby redundancy therein is removed. This does not need any search and, therefore, is fast. A new feature similarity measure, called maximum information compression index, is introduced. The algorithm is generic in nature and has the capability of multiscale representation of data sets. The superiority of the algorithm, in terms of speed and performance, is established extensively over various real-life data sets of different sizes and dimensions. It is also demonstrated how redundancy and information loss in feature selection can be quantified with an entropy measure.},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\E9SIXSRR\\Mitra e.a. - 2002 - Unsupervised feature selection using feature simil.pdf}
}

@misc{noauthor_wayback_2020,
  title = {Wayback {{Machine}}},
  year = {2020},
  month = sep,
  urldate = {2023-03-16},
  howpublished = {https://web.archive.org/web/20200913222203/https://arxiv.org/ftp/arxiv/papers/1410/1410.7744.pdf},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\M56L7GUH\\2020 - Wayback Machine.pdf}
}

@inproceedings{oya_is_2017,
  title = {Is {{Geo-Indistinguishability What You Are Looking}} For?},
  booktitle = {Proceedings of the 2017 on {{Workshop}} on {{Privacy}} in the {{Electronic Society}}},
  author = {Oya, Simon and Troncoso, Carmela and {P{\'e}rez-Gonz{\'a}lez}, Fernando},
  year = {2017},
  month = oct,
  pages = {137--140},
  publisher = {{ACM}},
  address = {{Dallas Texas USA}},
  doi = {10.1145/3139550.3139555},
  urldate = {2023-02-28},
  abstract = {Since its proposal in 2013, geo-indistinguishability has been consolidated as a formal notion of location privacy, generating a rich body of literature building on this idea. A problem with most of these follow-up works is that they blindly rely on geo-indistinguishability to provide location privacy, ignoring the numerical interpretation of this privacy guarantee. In this paper we provide an alternative formulation of geo-indistinguishability as an adversary error, and use it to show that the privacy vs. utility trade-off that can be obtained is not as appealing as implied by the literature. We also show that although geo-indistinguishability guarantees a lower bound on the adversary's error, this comes at the cost of achieving poorer performance than other noise generation mechanisms in terms of average error, and enabling the possibility of exposing obfuscated locations that are useless from the quality of service point of view.},
  isbn = {978-1-4503-5175-1},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\YFSMMX5M\\Oya et al. - 2017 - Is Geo-Indistinguishability What You Are Looking f.pdf}
}

@article{rand_objective_1971,
  title = {Objective Criteria for the Evaluation of Clustering Methods},
  author = {Rand, William M},
  year = {1971},
  journal = {Journal of the American Statistical association},
  volume = {66},
  number = {336},
  pages = {846--850},
  publisher = {{Taylor \& Francis}},
  issn = {0162-1459}
}

@article{rousseeuw_silhouettes_1987,
  title = {Silhouettes: A Graphical Aid to the Interpretation and Validation of Cluster Analysis},
  author = {Rousseeuw, Peter J},
  year = {1987},
  journal = {Journal of computational and applied mathematics},
  volume = {20},
  pages = {53--65},
  publisher = {{Elsevier}},
  issn = {0377-0427}
}

@inproceedings{shejwalkar_revisiting_2019,
  title = {Revisiting Utility Metrics for Location Privacy-Preserving Mechanisms},
  booktitle = {Proceedings of the 35th {{Annual Computer Security Applications Conference}}},
  author = {Shejwalkar, Virat and Houmansadr, Amir and {Pishro-Nik}, Hossein and Goeckel, Dennis},
  year = {2019},
  month = dec,
  pages = {313--327},
  publisher = {{ACM}},
  address = {{San Juan Puerto Rico USA}},
  doi = {10.1145/3359789.3359829},
  urldate = {2023-03-17},
  abstract = {The literature has extensively studied various location privacypreserving mechanisms (LPPMs) in order to improve the location privacy of the users of location-based services (LBSes). Such privacy, however, comes at the cost of degrading the utility of the underlying LBSes. The main body of previous work has used a generic distance-only based metric to quantify the quality loss incurred while employing LPPMs. In this paper, we argue that using such generic utility metrics misleads the design and evaluation of LPPMs, since generic utility metrics do not capture the actual utility perceived by the users. We demonstrate this for ride-hailing services, a popular class of LBS with complex utility behavior. Specifically, we design a privacy-preserving ride-hailing service, called PRide, and demonstrate the significant distinction between its generic and tailored metrics. Through various experiments we show the significant implications of using generic utility metrics in the design and evaluation of LPPMs. Our work concludes that LPPM design and evaluation should use utility metrics that are tailored to the individual LBSes.},
  isbn = {978-1-4503-7628-0},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\NS6QKNSZ\\Shejwalkar et al. - 2019 - Revisiting utility metrics for location privacy-pr.pdf}
}

@article{solorio-fernandez_review_2020,
  title = {A Review of Unsupervised Feature Selection Methods},
  author = {{Solorio-Fern{\'a}ndez}, Sa{\'u}l and {Carrasco-Ochoa}, J. Ariel and {Mart{\'i}nez-Trinidad}, Jos{\'e} Fco.},
  year = {2020},
  month = feb,
  journal = {Artificial Intelligence Review},
  volume = {53},
  number = {2},
  pages = {907--948},
  issn = {1573-7462},
  doi = {10.1007/s10462-019-09682-y},
  abstract = {In recent years, unsupervised feature selection methods have raised considerable interest in many research areas; this is mainly due to their ability to identify and select relevant features without needing class label information. In this paper, we provide a comprehensive and structured review of the most relevant and recent unsupervised feature selection methods reported in the literature. We present a taxonomy of these methods and describe the main characteristics and the fundamental ideas they are based on. Additionally, we summarized the advantages and disadvantages of the general lines in which we have categorized the methods analyzed in this review. Moreover, an experimental comparison among the most representative methods of each approach is also presented. Finally, we discuss some important open challenges in this research area.}
}

@article{strehl_cluster_2002,
  title = {Cluster Ensembles---a Knowledge Reuse Framework for Combining Multiple Partitions},
  author = {Strehl, Alexander and Ghosh, Joydeep},
  year = {2002},
  journal = {Journal of machine learning research},
  volume = {3},
  number = {Dec},
  pages = {583--617},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\CTQ3ZAYE\\Strehl en Ghosh - Cluster Ensembles – A Knowledge Reuse Framework fo.pdf}
}

@misc{sun_distributed_2019,
  title = {Distributed {{Clustering}} in the {{Anonymized Space}} with {{Local Differential Privacy}}},
  author = {Sun, Lin and Zhao, Jun and Ye, Xiaojun},
  year = {2019},
  month = jun,
  number = {arXiv:1906.11441},
  eprint = {arXiv:1906.11441},
  publisher = {{arXiv}},
  urldate = {2022-12-22},
  abstract = {Clustering and analyzing on collected data can improve user experiences and quality of services in big data, IoT applications. However, directly releasing original data brings potential privacy concerns, which raises challenges and opportunities for privacy-preserving clustering. In this paper, we study the problem of non-interactive clustering in distributed setting under the framework of local differential privacy. We first extend the Bit Vector, a novel anonymization mechanism to be functionality-capable and privacy-preserving. Based on the modified encoding mechanism, we propose kCluster algorithm that can be used for clustering in the anonymized space. We show the modified encoding mechanism can be easily implemented in existing clustering algorithms that only rely on distance information, such as DBSCAN. Theoretical analysis and experimental results validate the effectiveness of the proposed schemes.},
  archiveprefix = {arxiv},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Databases},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\8VTXE9HS\\Sun e.a. - 2019 - Distributed Clustering in the Anonymized Space wit.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\IRX6PFZC\\1906.html}
}

@article{sun_privbv_2022,
  title = {{{PrivBV}}: {{Distance-aware}} Encoding for Distributed Data with Local Differential Privacy},
  shorttitle = {{{PrivBV}}},
  author = {Sun, Lin and Ping, Guolou and Ye, Xiaojun},
  year = {2022},
  month = apr,
  journal = {Tsinghua Science and Technology},
  volume = {27},
  number = {2},
  pages = {412--421},
  issn = {1007-0214},
  doi = {10.26599/TST.2021.9010027},
  abstract = {Recently, local differential privacy (LDP) has been used as the de facto standard for data sharing and analyzing with high-level privacy guarantees. Existing LDP-based mechanisms mainly focus on learning statistical information about the entire population from sensitive data. For the first time in the literature, we use LDP for distance estimation between distributed datato support more complicated data analysis. Specifically, we propose PrivBV\textemdash a locally differentially private bit vector mechanism with a distance-aware property in the anonymized space. We also present an optimization strategy for reducing privacy leakage in the high-dimensional space. The distance-aware property of PrivBV brings new insights into complicated data analysis in distributed environments. As study cases, we show the feasibility of applying PrivBV to privacy-preserving record linkage and non-interactive clustering. Theoretical analysis and experimental results demonstrate the effectiveness of the proposed scheme.},
  keywords = {Data analysis,Differential privacy,Distributed databases,Encoding,Estimation,local differential privacy,non-interactive clustering,Privacy,privacy-preserving data publishing,Sun},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\B8WDVH5J\\Sun e.a. - 2022 - PrivBV Distance-aware encoding for distributed da.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\JPL3C98G\\9552667.html}
}

@article{vinh_information_nodate-2,
  title = {Information {{Theoretic Measures}} for {{Clusterings Comparison}}: {{Variants}}, {{Properties}}, {{Normalization}} and {{Correction}} for {{Chance}}},
  author = {Vinh, Nguyen Xuan and Epps, Julien and Bailey, James},
  abstract = {Information theoretic measures form a fundamental class of measures for comparing clusterings, and have recently received increasing interest. Nevertheless, a number of questions concerning their properties and inter-relationships remain unresolved. In this paper, we perform an organized study of information theoretic measures for clustering comparison, including several existing popular measures in the literature, as well as some newly proposed ones. We discuss and prove their important properties, such as the metric property and the normalization property. We then highlight to the clustering community the importance of correcting information theoretic measures for chance, especially when the data size is small compared to the number of clusters present therein. Of the available information theoretic based measures, we advocate the normalized information distance (NID) as a general measure of choice, for it possesses concurrently several important properties, such as being both a metric and a normalized measure, admitting an exact analytical adjusted-for-chance form, and using the nominal [0, 1] range better than other normalized variants.},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\BB3A2I9Q\\Vinh e.a. - Information Theoretic Measures for Clusterings Com.pdf}
}

@article{wagner_comparing_nodate,
  title = {Comparing {{Clusterings}} - {{An Overview}}},
  author = {Wagner, Silke and Wagner, Dorothea},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\P4IVDUGW\\Wagner en Wagner - Comparing Clusterings - An Overview.pdf}
}

@article{warrens_understanding_2022,
  title = {Understanding the {{Adjusted Rand Index}} and {{Other Partition Comparison Indices Based}} on {{Counting Object Pairs}}},
  author = {Warrens, Matthijs J. and {van der Hoef}, Hanneke},
  year = {2022},
  month = nov,
  journal = {Journal of Classification},
  volume = {39},
  number = {3},
  pages = {487--509},
  issn = {1432-1343},
  doi = {10.1007/s00357-022-09413-z},
  abstract = {In unsupervised machine learning, agreement between partitions is commonly assessed with so-called external validity indices. Researchers tend to use and report indices that quantify agreement between two partitions for all clusters simultaneously. Commonly used examples are the Rand index and the adjusted Rand index. Since these overall measures give a general notion of what is going on, their values are usually hard to interpret. The goal of this study is to provide a thorough understanding of the adjusted Rand index as well as many other partition comparison indices based on counting object pairs. It is shown that many overall indices based on the pair-counting approach can be decomposed into indices that reflect the degree of agreement on the level of individual clusters. The decompositions (1) show that the overall indices can be interpreted as summary statistics of the agreement on the cluster level, (2) specify how these overall indices are related to the indices for individual clusters, and (3) show that the overall indices are affected by cluster size imbalance: if cluster sizes are unbalanced these overall measures will primarily reflect the degree of agreement between the partitions on the large clusters, and will provide much less information on the agreement on smaller clusters. Furthermore, the value of Rand-like indices is determined to a large extent by the number of pairs of objects that are not joined in either of the partitions.}
}

@article{wood_differential_2018,
  title = {Differential {{Privacy}}: {{A Primer}} for a {{Non-Technical Audience}}},
  shorttitle = {Differential {{Privacy}}},
  author = {Wood, Alexandra and Altman, Micah and Bembenek, Aaron and Bun, Mark and Gaboardi, Marco and Honaker, James and Nissim, Kobbi and O'Brien, David and Steinke, Thomas and Vadhan, Salil},
  year = {2018},
  journal = {SSRN Electronic Journal},
  issn = {1556-5068},
  doi = {10.2139/ssrn.3338027},
  urldate = {2023-03-17},
  abstract = {This document is a primer on differential privacy, which is a formal mathematical framework for guaranteeing privacy protection when analyzing or releasing statistical data. Recently emerging from the theoretical computer science literature, differential privacy is now in initial stages of implementation and use in various academic, industry, and government settings. Using intuitive illustrations and limited mathematical formalism, this document provides an introduction to differential privacy for non-technical practitioners, who are increasingly tasked with making decisions with respect to differential privacy as it grows more widespread in use. In particular, the examples in this document illustrate ways in which social scientists can conceptualize the guarantees provided by differential privacy with respect to the decisions they make when managing personal data about research subjects and informing them about the privacy protection they will be afforded.},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\Y9WGZU9N\\Wood et al. - 2018 - Differential Privacy A Primer for a Non-Technical.pdf}
}

@article{xia_distributed_2020-1,
  title = {Distributed {{K-Means}} Clustering Guaranteeing Local Differential Privacy},
  author = {Xia, Chang and Hua, Jingyu and Tong, Wei and Zhong, Sheng},
  year = {2020},
  journal = {Computers \& Security},
  volume = {90},
  pages = {101699},
  publisher = {{Elsevier}},
  issn = {0167-4048}
}

@article{yan_efficient_2020,
  title = {An Efficient Unsupervised Feature Selection Procedure through Feature Clustering},
  author = {Yan, Xuyang and Nazmi, Shabnam and Erol, Berat A. and Homaifar, Abdollah and Gebru, Biniam and Tunstel, Edward},
  year = {2020},
  month = mar,
  journal = {Pattern Recognition Letters},
  volume = {131},
  pages = {277--284},
  issn = {01678655},
  doi = {10.1016/j.patrec.2019.12.022},
  urldate = {2023-02-15},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\8Z855R66\\Yan e.a. - 2020 - An efficient unsupervised feature selection proced.pdf}
}

@article{yan_perturb_2022-2,
  title = {Perturb and Optimize Users' Location Privacy Using Geo-Indistinguishability and Location Semantics},
  author = {Yan, Yan and Xu, Fei and Mahmood, Adnan and Dong, Zhuoyue and Sheng, Quan Z.},
  year = {2022},
  month = nov,
  journal = {Scientific Reports},
  volume = {12},
  number = {1},
  pages = {20445},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-24893-0},
  urldate = {2023-02-26},
  abstract = {Location-based services (LBS) are capable of providing location-based information retrieval, traffic navigation, entertainment services, emergency rescues, and several similar services primarily on the premise of the geographic location of users or mobile devices. However, in the process of introducing a new user experience, it is also easy to expose users' specific location which can result in more private information leakage. Hence, the protection of location privacy remains one of the critical issues of the location-based services. Moreover, the areas where humans work and live have different location semantics and sensitivities according to their different social functions. Although the privacy protection of a user's real location can be achieved by the perturbation algorithm, the attackers may employ the semantics information of the perturbed location to infer a user's real location semantics in an attempt to spy on a user's privacy to certain extent. In order to mitigate the above semantics inference attack, and further improve the quality of the location-based services, this paper hereby proposes a user side location perturbation and optimization algorithm based on geo-indistinguishability and location semantics. The perturbation area satisfying geo-indistinguishability is thus generated according to the planar Laplace mechanism and optimized by combining the semantics information and time characteristics of the location. The optimum perturbed location that is able to satisfy the minimum loss of location-based service quality is selected via a linear programming method, and can be employed to replace the real location of the user so as to prevent the leakage of the privacy. Experimental comparison of the actual road network and location semantics dataset manifests that the proposed method reduces approximately 37\% perturbation distance in contrast to the other state-of-the-art methods, maintains considerably lower similarity of location semantics, and improves region counting query accuracy by a margin of around 40\%.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Energy science and technology,Mathematics and computing},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\8VFPAXY2\\Yan et al. - 2022 - Perturb and optimize users’ location privacy using.pdf}
}
