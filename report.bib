@article{DBLP:journals/corr/abs-1212-1984,
  title = {Geo-Indistinguishability: {{Differential}} Privacy for Location-Based Systems},
  author = {Andr{\'e}s, Miguel E. and Bordenabe, Nicol{\'a}s Emilio and Chatzikokolakis, Konstantinos and Palamidessi, Catuscia},
  year = {2012},
  journal = {CoRR},
  volume = {abs/1212.1984},
  eprint = {1212.1984},
  eprinttype = {arxiv},
  archiveprefix = {arXiv},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/journals/corr/abs-1212-1984.bib},
  timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\HVVT4GUR\\Andrés e.a. - 2012 - Geo-indistinguishability Differential privacy for.pdf}
}

@article{del_rey_comprehensive_2020,
  title = {A {{Comprehensive Survey}} on {{Local Differential Privacy}}},
  author = {Xiong, Xingxing and Liu, Shubo and Li, Dan and Cai, Zhaohui and Niu, Xiaoguang},
  editor = {Del Rey, Angel M.},
  year = {2020},
  month = oct,
  journal = {Security and Communication Networks},
  volume = {2020},
  pages = {8829523},
  publisher = {{Hindawi}},
  issn = {1939-0114},
  doi = {10.1155/2020/8829523},
  abstract = {With the advent of the era of big data, privacy issues have been becoming a hot topic in public. Local differential privacy (LDP) is a state-of-the-art privacy preservation technique that allows to perform big data analysis (e.g., statistical estimation, statistical learning, and data mining) while guaranteeing each individual participant\&\#x2019;s privacy. In this paper, we present a comprehensive survey of LDP. We first give an overview on the fundamental knowledge of LDP and its frameworks. We then introduce the mainstream privatization mechanisms and methods in detail from the perspective of frequency oracle and give insights into recent studied on private basic statistical estimation (e.g., frequency estimation and mean estimation) and complex statistical estimation (e.g., multivariate distribution estimation and private estimation over complex data) under LDP. Furthermore, we present current research circumstances on LDP including the private statistical learning/inferencing, private statistical data analysis, privacy amplification techniques for LDP, and some application fields under LDP. Finally, we identify future research directions and open challenges for LDP. This survey can serve as a good reference source for the research of LDP to deal with various privacy-related scenarios to be encountered in practice.}
}

@inproceedings{erlingsson_rappor_2014,
  title = {{{RAPPOR}}: {{Randomized Aggregatable Privacy-Preserving Ordinal Response}}},
  shorttitle = {{{RAPPOR}}},
  booktitle = {Proceedings of the 2014 {{ACM SIGSAC Conference}} on {{Computer}} and {{Communications Security}}},
  author = {Erlingsson, {\'U}lfar and Pihur, Vasyl and Korolova, Aleksandra},
  year = {2014},
  month = nov,
  pages = {1054--1067},
  publisher = {{ACM}},
  address = {{Scottsdale Arizona USA}},
  doi = {10.1145/2660267.2660348},
  abstract = {Randomized Aggregatable Privacy-Preserving Ordinal Response, or RAPPOR, is a technology for crowdsourcing statistics from end-user client software, anonymously, with strong privacy guarantees. In short, RAPPORs allow the forest of client data to be studied, without permitting the possibility of looking at individual trees. By applying randomized response in a novel manner, RAPPOR provides the mechanisms for such collection as well as for efficient, high-utility analysis of the collected data. In particular, RAPPOR permits statistics to be collected on the population of client-side strings with strong privacy guarantees for each client, and without linkability of their reports.},
  isbn = {978-1-4503-2957-6},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\GRMRMG69\\Erlingsson e.a. - 2014 - RAPPOR Randomized Aggregatable Privacy-Preserving.pdf}
}

@inproceedings{jagannathan_privacy-preserving_2005,
  title = {Privacy-Preserving Distributed k-Means Clustering over Arbitrarily Partitioned Data},
  booktitle = {Proceeding of the Eleventh {{ACM SIGKDD}} International Conference on {{Knowledge}} Discovery in Data Mining  - {{KDD}} '05},
  author = {Jagannathan, Geetha and Wright, Rebecca N.},
  year = {2005},
  pages = {593},
  publisher = {{ACM Press}},
  address = {{Chicago, Illinois, USA}},
  doi = {10.1145/1081870.1081942},
  abstract = {Advances in computer networking and database technologies have enabled the collection and storage of vast quantities of data. Data mining can extract valuable knowledge from this data, and organizations have realized that they can often obtain better results by pooling their data together. However, the collected data may contain sensitive or private information about the organizations or their customers, and privacy concerns are exacerbated if data is shared between multiple organizations.},
  isbn = {978-1-59593-135-1},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\A64MLK72\\Jagannathan en Wright - 2005 - Privacy-preserving distributed k-means clustering .pdf}
}

@inproceedings{jagannathan_privacy-preserving_2005-1,
  title = {Privacy-{{Preserving Distributed}} k-{{Means Clustering}} over {{Arbitrarily Partitioned Data}}},
  booktitle = {Proceedings of the {{Eleventh ACM SIGKDD International Conference}} on {{Knowledge Discovery}} in {{Data Mining}}},
  author = {Jagannathan, Geetha and Wright, Rebecca N.},
  year = {2005},
  series = {{{KDD}} '05},
  pages = {593--599},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1081870.1081942},
  abstract = {Advances in computer networking and database technologies have enabled the collection and storage of vast quantities of data. Data mining can extract valuable knowledge from this data, and organizations have realized that they can often obtain better results by pooling their data together. However, the collected data may contain sensitive or private information about the organizations or their customers, and privacy concerns are exacerbated if data is shared between multiple organizations.Distributed data mining is concerned with the computation of models from data that is distributed among multiple participants. Privacy-preserving distributed data mining seeks to allow for the cooperative computation of such models without the cooperating parties revealing any of their individual data items. Our paper makes two contributions in privacy-preserving data mining. First, we introduce the concept of arbitrarily partitioned data, which is a generalization of both horizontally and vertically partitioned data. Second, we provide an efficient privacy-preserving protocol for k-means clustering in the setting of arbitrarily partitioned data.},
  isbn = {1-59593-135-X}
}

@inproceedings{kwatra_k-anonymised_2022,
  title = {A K-{{Anonymised Federated Learning Framework}} with {{Decision Trees}}},
  booktitle = {Data {{Privacy Management}}, {{Cryptocurrencies}} and {{Blockchain Technology}}},
  author = {Kwatra, Saloni and Torra, Vicen{\c c}},
  editor = {{Garcia-Alfaro}, Joaquin and {Mu{\~n}oz-Tapia}, Jose Luis and {Navarro-Arribas}, Guillermo and Soriano, Miguel},
  year = {2022},
  pages = {106--120},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  abstract = {We propose a privacy-preserving framework using Mondrian k-anonymity with decision trees in a Federated Learning (FL) setting for the horizontally partitioned data. Data heterogeneity in FL makes the data non-IID (Non-Independent and Identically Distributed). We use a novel approach to create non-IID partitions of data by solving an optimization problem. In this work, each device trains a decision tree classifier. Devices share the root node of their trees with the aggregator. The aggregator merges the trees by choosing the most common split attribute and grows the branches based on the split values of the chosen split attribute. This recursive process stops when all the nodes to be merged are leaf nodes. After the merging operation, the aggregator sends the merged decision tree to the distributed devices. Therefore, we aim to build a joint machine learning model based on the data from multiple devices while offering k-anonymity to the participants.},
  isbn = {978-3-030-93944-1}
}

@misc{neera_private_2021,
  title = {Private and {{Utility Enhanced Recommendations}} with {{Local Differential Privacy}} and {{Gaussian Mixture Model}}},
  author = {Neera, Jeyamohan and Chen, Xiaomin and Aslam, Nauman and Wang, Kezhi and Shu, Zhan},
  year = {2021},
  month = mar,
  number = {arXiv:2102.13453},
  eprint = {2102.13453},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  abstract = {Recommendation systems rely heavily on users behavioural and preferential data (e.g. ratings, likes) to produce accurate recommendations. However, users experience privacy concerns due to unethical data aggregation and analytical practices carried out by the Service Providers (SP). Local differential privacy (LDP) based perturbation mechanisms add noise to users data at user side before sending it to the SP. The SP then uses the perturbed data to perform recommendations. Although LDP protects the privacy of users from SP, it causes a substantial decline in predictive accuracy. To address this issue, we propose an LDP-based Matrix Factorization (MF) with a Gaussian Mixture Model (MoG). The LDP perturbation mechanism, Bounded Laplace (BLP), regulates the effect of noise by confining the perturbed ratings to a predetermined domain. We derive a sufficient condition of the scale parameter for BLP to satisfy \$\textbackslash epsilon\$ LDP. At the SP, The MoG model estimates the noise added to perturbed ratings and the MF algorithm predicts missing ratings. Our proposed LDP based recommendation system improves the recommendation accuracy without violating LDP principles. The empirical evaluations carried out on three real world datasets, i.e., Movielens, Libimseti and Jester, demonstrate that our method offers a substantial increase in predictive accuracy under strong privacy guarantee.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Machine Learning},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\V7A4IS7T\\Neera e.a. - 2021 - Private and Utility Enhanced Recommendations with .pdf;C\:\\Users\\tjvan\\Zotero\\storage\\5ERLZYHX\\2102.html}
}

@misc{noauthor_wise19_ldppdf_nodate,
  title = {Wise19\_ldp.Pdf},
  journal = {Google Docs},
  howpublished = {https://drive.google.com/file/d/1C4buKvjM6Xf4QxzQfsHScrLtI5hGh830/view?usp=embed\_facebook}
}

@article{rodriguez-barroso_survey_2023,
  title = {Survey on {{Federated Learning Threats}}: Concepts, Taxonomy on Attacks and Defences, Experimental Study and Challenges},
  shorttitle = {Survey on {{Federated Learning Threats}}},
  author = {{Rodr{\'i}guez-Barroso}, Nuria and L{\'o}pez, Daniel Jim{\'e}nez and Luz{\'o}n, M. Victoria and Herrera, Francisco and {Mart{\'i}nez-C{\'a}mara}, Eugenio},
  year = {2023},
  month = feb,
  journal = {Information Fusion},
  volume = {90},
  eprint = {2201.08135},
  eprinttype = {arxiv},
  primaryclass = {cs},
  pages = {148--173},
  issn = {15662535},
  doi = {10.1016/j.inffus.2022.09.011},
  abstract = {Federated learning is a machine learning paradigm that emerges as a solution to the privacy-preservation demands in artificial intelligence. As machine learning, federated learning is threatened by adversarial attacks against the integrity of the learning model and the privacy of data via a distributed approach to tackle local and global learning. This weak point is exacerbated by the inaccessibility of data in federated learning, which makes harder the protection against adversarial attacks and evidences the need to furtherance the research on defence methods to make federated learning a real solution for safeguarding data privacy. In this paper, we present an extensive review of the threats of federated learning, as well as as their corresponding countermeasures, attacks versus defences. This survey provides a taxonomy of adversarial attacks and a taxonomy of defence methods that depict a general picture of this vulnerability of federated learning and how to overcome it. Likewise, we expound guidelines for selecting the most adequate defence method according to the category of the adversarial attack. Besides, we carry out an extensive experimental study from which we draw further conclusions about the behaviour of attacks and defences and the guidelines for selecting the most adequate defence method according to the category of the adversarial attack. This study is finished leading to meditated learned lessons and challenges.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security,Computer Science - Machine Learning},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\WTV9LE2T\\Rodríguez-Barroso e.a. - 2023 - Survey on Federated Learning Threats concepts, ta.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\8R9W2SNA\\2201.html}
}

@misc{truex_ldp-fed_2020,
  title = {{{LDP-Fed}}: {{Federated Learning}} with {{Local Differential Privacy}}},
  shorttitle = {{{LDP-Fed}}},
  author = {Truex, Stacey and Liu, Ling and Chow, Ka-Ho and Gursoy, Mehmet Emre and Wei, Wenqi},
  year = {2020},
  month = jun,
  number = {arXiv:2006.03637},
  eprint = {2006.03637},
  eprinttype = {arxiv},
  primaryclass = {cs, stat},
  publisher = {{arXiv}},
  abstract = {This paper presents LDP-Fed, a novel federated learning system with a formal privacy guarantee using local differential privacy (LDP). Existing LDP protocols are developed primarily to ensure data privacy in the collection of single numerical or categorical values, such as click count in Web access logs. However, in federated learning model parameter updates are collected iteratively from each participant and consist of high dimensional, continuous values with high precision (10s of digits after the decimal point), making existing LDP protocols inapplicable. To address this challenge in LDP-Fed, we design and develop two novel approaches. First, LDP-Fed's LDP Module provides a formal differential privacy guarantee for the repeated collection of model training parameters in the federated training of large-scale neural networks over multiple individual participants' private datasets. Second, LDP-Fed implements a suite of selection and filtering techniques for perturbing and sharing select parameter updates with the parameter server. We validate our system deployed with a condensed LDP protocol in training deep neural networks on public data. We compare this version of LDP-Fed, coined CLDP-Fed, with other state-of-the-art approaches with respect to model accuracy, privacy preservation, and system capabilities.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\YPUHCDTN\\Truex e.a. - 2020 - LDP-Fed Federated Learning with Local Differentia.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\7KYXQWVT\\2006.html}
}

@article{wang_comprehensive_2020,
  title = {A {{Comprehensive Survey}} on {{Local Differential Privacy Toward Data Statistics}} and {{Analysis}} in {{Crowdsensing}}},
  author = {Wang, Teng and Zhang, Xuefeng and Feng, Jingyu and Yang, Xinyu},
  year = {2020},
  journal = {CoRR},
  volume = {abs/2010.05253},
  eprint = {2010.05253},
  eprinttype = {arxiv},
  archiveprefix = {arXiv}
}

@misc{yang_local_2020,
  title = {Local {{Differential Privacy}} and {{Its Applications}}: {{A Comprehensive Survey}}},
  shorttitle = {Local {{Differential Privacy}} and {{Its Applications}}},
  author = {Yang, Mengmeng and Lyu, Lingjuan and Zhao, Jun and Zhu, Tianqing and Lam, Kwok-Yan},
  year = {2020},
  month = aug,
  number = {arXiv:2008.03686},
  eprint = {2008.03686},
  eprinttype = {arxiv},
  primaryclass = {cs},
  publisher = {{arXiv}},
  abstract = {With the fast development of Information Technology, a tremendous amount of data have been generated and collected for research and analysis purposes. As an increasing number of users are growing concerned about their personal information, privacy preservation has become an urgent problem to be solved and has attracted significant attention. Local differential privacy (LDP), as a strong privacy tool, has been widely deployed in the real world in recent years. It breaks the shackles of the trusted third party, and allows users to perturb their data locally, thus providing much stronger privacy protection. This survey provides a comprehensive and structured overview of the local differential privacy technology. We summarise and analyze state-of-the-art research in LDP and compare a range of methods in the context of answering a variety of queries and training different machine learning models. We discuss the practical deployment of local differential privacy and explore its application in various domains. Furthermore, we point out several research gaps, and discuss promising future research directions.},
  archiveprefix = {arXiv},
  keywords = {Computer Science - Cryptography and Security},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\D49D6UZQ\\Yang e.a. - 2020 - Local Differential Privacy and Its Applications A.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\4SNPVQXE\\2008.html}
}
