@inproceedings{10.1145/1835804.1835848,
  title = {Unsupervised Feature Selection for Multi-Cluster Data},
  booktitle = {Proceedings of the 16th {{ACM SIGKDD}} International Conference on Knowledge Discovery and Data Mining},
  author = {Cai, Deng and Zhang, Chiyuan and He, Xiaofei},
  year = {2010},
  series = {{{KDD}} '10},
  pages = {333--342},
  publisher = {{Association for Computing Machinery}},
  address = {{New York, NY, USA}},
  doi = {10.1145/1835804.1835848},
  abstract = {In many data analysis tasks, one is often confronted with very high dimensional data. Feature selection techniques are designed to find the relevant feature subset of the original features which can facilitate clustering, classification and retrieval. In this paper, we consider the feature selection problem in unsupervised learning scenario, which is particularly difficult due to the absence of class labels that would guide the search for relevant information. The feature selection problem is essentially a combinatorial optimization problem which is computationally expensive. Traditional unsupervised feature selection methods address this issue by selecting the top ranked features based on certain scores computed independently for each feature. These approaches neglect the possible correlation between different features and thus can not produce an optimal feature subset. Inspired from the recent developments on manifold learning and L1-regularized models for subset selection, we propose in this paper a new approach, called Multi-Cluster Feature Selection (MCFS), for unsupervised feature selection. Specifically, we select those features such that the multi-cluster structure of the data can be best preserved. The corresponding optimization problem can be efficiently solved since it only involves a sparse eigen-problem and a L1-regularized least squares problem. Extensive experimental results over various real-life data sets have demonstrated the superiority of the proposed algorithm.},
  isbn = {978-1-4503-0055-1},
  keywords = {clustering,feature selection,unsupervised}
}

@article{9646489,
  title = {{{3D}} Geo-Indistinguishability for Indoor Location-Based Services},
  author = {Min, Minghui and Xiao, Liang and Ding, Jiahao and Zhang, Hongliang and Li, Shiyin and Pan, Miao and Han, Zhu},
  year = {2022},
  journal = {IEEE Transactions on Wireless Communications},
  volume = {21},
  number = {7},
  pages = {4682--4694},
  doi = {10.1109/TWC.2021.3132464},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\QPJZTQGX\\Min e.a. - 2022 - 3D geo-indistinguishability for indoor location-ba.pdf}
}

@misc{ahuja_utility-preserving_2019,
  title = {A {{Utility-Preserving}} and {{Scalable Technique}} for {{Protecting Location Data}} with {{Geo-Indistinguishability}}},
  author = {Ahuja, Ritesh and Ghinita, Gabriel and Shahabi, Cyrus},
  year = {2019},
  publisher = {{OpenProceedings.org}},
  doi = {10.5441/002/EDBT.2019.20},
  abstract = {Location-based apps provide users with personalized services tailored to their geographical position. This is highly-beneficial for mobile users, who are able to find points of interest close to their location, or connect with nearby friends. However, sharing location data with service providers also introduces privacy concerns. An adversary with access to fine-grained user locations can infer private details about individuals. Geo-indistinguishability (GeoInd) adapts the popular differential privacy (DP) model to make it suitable for protecting users' location information. However, existing techniques that implement GeoInd have major drawbacks. Some solutions, such as the planar Laplace mechanism, significantly lower data utility by adding excessive noise. Other approaches, such as the optimal mechanism, achieve good utility, but only work for small sets of candidate locations due to the use of computationally-expensive linear programming. In most cases, locations are used to answer online queries, so a quick response time is essential. In this paper, we propose a technique that achieves GeoInd and scales to large datasets while preserving data utility. Our central idea is to use the composability property of GeoInd to create a multiple-step algorithm that can be used in conjunction with a spatial index. We preserve utility by applying accurate GeoInd mechanisms and we achieve scalability by pruning the solution search space with the help of the index when seeking high-utility outcomes. Our extensive performance evaluation on top of real location datasets from social media apps shows that the proposed technique outperforms significantly the benchmark in terms of utility and/or computational overhead.},
  langid = {english},
  keywords = {Database Technology},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\VN38ZL5N\\Ahuja et al. - 2019 - A Utility-Preserving and Scalable Technique for Pr.pdf}
}

@article{chatzikokolakis_efficient_2017,
  title = {Efficient Utility Improvement for Location Privacy},
  author = {Chatzikokolakis, Konstantinos and Elsalamouny, Ehab and Palamidessi, Catuscia},
  year = {2017},
  journal = {Proceedings on Privacy Enhancing Technologies},
  volume = {2017},
  number = {4},
  pages = {308--328}
}

@article{DBLP:journals/corr/abs-1212-1984,
  title = {Geo-Indistinguishability: {{Differential}} Privacy for Location-Based Systems},
  author = {Andr{\'e}s, Miguel E. and Bordenabe, Nicol{\'a}s Emilio and Chatzikokolakis, Konstantinos and Palamidessi, Catuscia},
  year = {2012},
  journal = {CoRR},
  volume = {abs/1212.1984},
  eprint = {1212.1984},
  archiveprefix = {arxiv},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/journals/corr/abs-1212-1984.bib},
  timestamp = {Mon, 13 Aug 2018 16:47:27 +0200},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\HVVT4GUR\\Andr√©s e.a. - 2012 - Geo-indistinguishability Differential privacy for.pdf}
}

@inproceedings{he_laplacian_2005,
  title = {Laplacian {{Score}} for {{Feature Selection}}},
  booktitle = {Advances in {{Neural Information Processing Systems}}},
  author = {He, Xiaofei and Cai, Deng and Niyogi, Partha},
  year = {2005},
  volume = {18},
  publisher = {{MIT Press}},
  abstract = {In supervised learning scenarios, feature selection has been studied widely in the literature. Selecting features in unsupervised learning scenarios is a much harder problem, due to the absence of class labels that would guide the search for relevant information. And, almost all of previous unsupervised feature selection methods are "wrapper" techniques that require a learning algorithm to evaluate the candidate feature subsets. In this paper, we propose a "filter" method for feature selection which is independent of any learning algorithm. Our method can be performed in either supervised or unsupervised fashion. The proposed method is based on the observation that, in many real world classification problems, data from the same class are often close to each other. The importance of a feature is evaluated by its power of locality preserving, or, Laplacian Score. We compare our method with data variance (unsupervised) and Fisher score (supervised) on two data sets. Experimental results demonstrate the effectiveness and efficiency of our algorithm.},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\MEYJS6AX\\He e.a. - 2005 - Laplacian Score for Feature Selection.pdf}
}

@article{kohavi_wrappers_1997,
  title = {Wrappers for Feature Subset Selection},
  author = {Kohavi, Ron and John, George H.},
  year = {1997},
  month = dec,
  journal = {Artificial Intelligence},
  series = {Relevance},
  volume = {97},
  number = {1},
  pages = {273--324},
  issn = {0004-3702},
  doi = {10.1016/S0004-3702(97)00043-X},
  abstract = {In the feature subset selection problem, a learning algorithm is faced with the problem of selecting a relevant subset of features upon which to focus its attention, while ignoring the rest. To achieve the best possible performance with a particular learning algorithm on a particular training set, a feature subset selection method should consider how the algorithm and the training set interact. We explore the relation between optimal feature subset selection and relevance. Our wrapper method searches for an optimal feature subset tailored to a particular algorithm and a domain. We study the strengths and weaknesses of the wrapper approach and show a series of improved designs. We compare the wrapper approach to induction without feature subset selection and to Relief, a filter approach to feature subset selection. Significant improvement in accuracy is achieved for some datasets for the two families of induction algorithms used: decision trees and Naive-Bayes.},
  langid = {english},
  keywords = {Classification,Feature selection,Filter,Wrapper},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\5J9L28B4\\Kohavi en John - 1997 - Wrappers for feature subset selection.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\K2MHWNY7\\S000437029700043X.html}
}

@article{lehtonen_lambert_2016,
  title = {The {{Lambert W}} Function in Ecological and Evolutionary Models},
  author = {Lehtonen, Jussi},
  year = {2016},
  journal = {Methods in Ecology and Evolution},
  volume = {7},
  number = {9},
  pages = {1110--1118},
  issn = {2041-210X},
  doi = {10.1111/2041-210X.12568},
  abstract = {The Lambert W function is a mathematical function with a long history, but which was named and rigorously defined relatively recently. It is closely related to the logarithmic function and arises from many models in the natural sciences, including a surprising number of problems in ecology and evolution. I describe the basic properties of the function and present examples of its application to models of ecological and evolutionary processes. The Lambert W function makes it possible to solve explicitly several models where this is not possible with elementary functions. I present examples of such models from existing literature, as well as novel models. Solving models explicitly with the Lambert W function can provide deeper insight and a new point of view on a biological problem. Explicit solutions with the Lambert W function are easily amenable to further mathematical operations, such as differentiation and integration. These advantages apply to a wide range of models, from the marginal value theorem to population growth rates and disease epidemics.},
  langid = {english},
  keywords = {calculus,explicit solution,fertilization kinetics,Lambert W function,Lotka‚ÄìVolterra model,marginal value theorem,mate search,modelling,population growth rate,SIR model},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\S77QF2U8\\Lehtonen - 2016 - The Lambert W function in ecological and evolution.pdf;C\:\\Users\\tjvan\\Zotero\\storage\\QYQTRQAH\\2041-210X.html}
}

@article{mitra_unsupervised_2002,
  title = {Unsupervised Feature Selection Using Feature Similarity},
  author = {Mitra, P. and Murthy, C.A. and Pal, S.K.},
  year = {2002},
  month = mar,
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  volume = {24},
  number = {3},
  pages = {301--312},
  issn = {01628828},
  doi = {10.1109/34.990133},
  abstract = {\DH In this article, we describe an unsupervised feature selection algorithm suitable for data sets, large in both dimension and size. The method is based on measuring similarity between features whereby redundancy therein is removed. This does not need any search and, therefore, is fast. A new feature similarity measure, called maximum information compression index, is introduced. The algorithm is generic in nature and has the capability of multiscale representation of data sets. The superiority of the algorithm, in terms of speed and performance, is established extensively over various real-life data sets of different sizes and dimensions. It is also demonstrated how redundancy and information loss in feature selection can be quantified with an entropy measure.},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\E9SIXSRR\\Mitra e.a. - 2002 - Unsupervised feature selection using feature simil.pdf}
}

@inproceedings{oya_is_2017,
  title = {Is {{Geo-Indistinguishability What You Are Looking}} For?},
  booktitle = {Proceedings of the 2017 on {{Workshop}} on {{Privacy}} in the {{Electronic Society}}},
  author = {Oya, Simon and Troncoso, Carmela and {P{\'e}rez-Gonz{\'a}lez}, Fernando},
  year = {2017},
  month = oct,
  pages = {137--140},
  publisher = {{ACM}},
  address = {{Dallas Texas USA}},
  doi = {10.1145/3139550.3139555},
  abstract = {Since its proposal in 2013, geo-indistinguishability has been consolidated as a formal notion of location privacy, generating a rich body of literature building on this idea. A problem with most of these follow-up works is that they blindly rely on geo-indistinguishability to provide location privacy, ignoring the numerical interpretation of this privacy guarantee. In this paper we provide an alternative formulation of geo-indistinguishability as an adversary error, and use it to show that the privacy vs. utility trade-off that can be obtained is not as appealing as implied by the literature. We also show that although geo-indistinguishability guarantees a lower bound on the adversary's error, this comes at the cost of achieving poorer performance than other noise generation mechanisms in terms of average error, and enabling the possibility of exposing obfuscated locations that are useless from the quality of service point of view.},
  isbn = {978-1-4503-5175-1},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\YFSMMX5M\\Oya et al. - 2017 - Is Geo-Indistinguishability What You Are Looking f.pdf}
}

@article{solorio-fernandez_review_2020,
  title = {A Review of Unsupervised Feature Selection Methods},
  author = {{Solorio-Fern{\'a}ndez}, Sa{\'u}l and {Carrasco-Ochoa}, J. Ariel and {Mart{\'i}nez-Trinidad}, Jos{\'e} Fco.},
  year = {2020},
  month = feb,
  journal = {Artificial Intelligence Review},
  volume = {53},
  number = {2},
  pages = {907--948},
  issn = {1573-7462},
  doi = {10.1007/s10462-019-09682-y},
  abstract = {In recent years, unsupervised feature selection methods have raised considerable interest in many research areas; this is mainly due to their ability to identify and select relevant features without needing class label information. In this paper, we provide a comprehensive and structured review of the most relevant and recent unsupervised feature selection methods reported in the literature. We present a taxonomy of these methods and describe the main characteristics and the fundamental ideas they are based on. Additionally, we summarized the advantages and disadvantages of the general lines in which we have categorized the methods analyzed in this review. Moreover, an experimental comparison among the most representative methods of each approach is also presented. Finally, we discuss some important open challenges in this research area.}
}

@article{sun_distributed_2019-1,
  title = {Distributed Clustering in the Anonymized Space with Local Differential Privacy},
  author = {Sun, Lin and Zhao, Jun and Ye, Xiaojun},
  year = {2019},
  journal = {arXiv preprint arXiv:1906.11441},
  eprint = {1906.11441},
  archiveprefix = {arxiv}
}

@article{vinh_information_nodate-2,
  title = {Information {{Theoretic Measures}} for {{Clusterings Comparison}}: {{Variants}}, {{Properties}}, {{Normalization}} and {{Correction}} for {{Chance}}},
  author = {Vinh, Nguyen Xuan and Epps, Julien and Bailey, James},
  abstract = {Information theoretic measures form a fundamental class of measures for comparing clusterings, and have recently received increasing interest. Nevertheless, a number of questions concerning their properties and inter-relationships remain unresolved. In this paper, we perform an organized study of information theoretic measures for clustering comparison, including several existing popular measures in the literature, as well as some newly proposed ones. We discuss and prove their important properties, such as the metric property and the normalization property. We then highlight to the clustering community the importance of correcting information theoretic measures for chance, especially when the data size is small compared to the number of clusters present therein. Of the available information theoretic based measures, we advocate the normalized information distance (NID) as a general measure of choice, for it possesses concurrently several important properties, such as being both a metric and a normalized measure, admitting an exact analytical adjusted-for-chance form, and using the nominal [0, 1] range better than other normalized variants.},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\BB3A2I9Q\\Vinh e.a. - Information Theoretic Measures for Clusterings Com.pdf}
}

@article{xia_distributed_2020-1,
  title = {Distributed {{K-Means}} Clustering Guaranteeing Local Differential Privacy},
  author = {Xia, Chang and Hua, Jingyu and Tong, Wei and Zhong, Sheng},
  year = {2020},
  journal = {Computers \& Security},
  volume = {90},
  pages = {101699},
  publisher = {{Elsevier}},
  issn = {0167-4048}
}

@article{yan_efficient_2020,
  title = {An Efficient Unsupervised Feature Selection Procedure through Feature Clustering},
  author = {Yan, Xuyang and Nazmi, Shabnam and Erol, Berat A. and Homaifar, Abdollah and Gebru, Biniam and Tunstel, Edward},
  year = {2020},
  month = mar,
  journal = {Pattern Recognition Letters},
  volume = {131},
  pages = {277--284},
  issn = {01678655},
  doi = {10.1016/j.patrec.2019.12.022},
  langid = {english},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\8Z855R66\\Yan e.a. - 2020 - An efficient unsupervised feature selection proced.pdf}
}

@article{yan_perturb_2022-2,
  title = {Perturb and Optimize Users' Location Privacy Using Geo-Indistinguishability and Location Semantics},
  author = {Yan, Yan and Xu, Fei and Mahmood, Adnan and Dong, Zhuoyue and Sheng, Quan Z.},
  year = {2022},
  month = nov,
  journal = {Scientific Reports},
  volume = {12},
  number = {1},
  pages = {20445},
  publisher = {{Nature Publishing Group}},
  issn = {2045-2322},
  doi = {10.1038/s41598-022-24893-0},
  abstract = {Location-based services (LBS) are capable of providing location-based information retrieval, traffic navigation, entertainment services, emergency rescues, and several similar services primarily on the premise of the geographic location of users or mobile devices. However, in the process of introducing a new user experience, it is also easy to expose users' specific location which can result in more private information leakage. Hence, the protection of location privacy remains one of the critical issues of the location-based services. Moreover, the areas where humans work and live have different location semantics and sensitivities according to their different social functions. Although the privacy protection of a user's real location can be achieved by the perturbation algorithm, the attackers may employ the semantics information of the perturbed location to infer a user's real location semantics in an attempt to spy on a user's privacy to certain extent. In order to mitigate the above semantics inference attack, and further improve the quality of the location-based services, this paper hereby proposes a user side location perturbation and optimization algorithm based on geo-indistinguishability and location semantics. The perturbation area satisfying geo-indistinguishability is thus generated according to the planar Laplace mechanism and optimized by combining the semantics information and time characteristics of the location. The optimum perturbed location that is able to satisfy the minimum loss of location-based service quality is selected via a linear programming method, and can be employed to replace the real location of the user so as to prevent the leakage of the privacy. Experimental comparison of the actual road network and location semantics dataset manifests that the proposed method reduces approximately 37\% perturbation distance in contrast to the other state-of-the-art methods, maintains considerably lower similarity of location semantics, and improves region counting query accuracy by a margin of around 40\%.},
  copyright = {2022 The Author(s)},
  langid = {english},
  keywords = {Energy science and technology,Mathematics and computing},
  file = {C\:\\Users\\tjvan\\Zotero\\storage\\8VFPAXY2\\Yan et al. - 2022 - Perturb and optimize users‚Äô location privacy using.pdf}
}
