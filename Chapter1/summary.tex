\chapter{Summary}
\added{
The need of securing data is emphasized by its significance in our lives.
This led to the development of privacy laws like the US Privacy Act and the GDPR.
Clustering is a method of data processing, however it requires the storage of historical data for training.
This creates problems with these regulations, and differential privacy is a solution (DP).
DP, a technique that enhances data with controlled noise, provides the opportunity to protect privacy while maintaining clustering patterns.
The original data must still be completely copied for this method to work.
LDP, which only affects the local data-view, reduces this privacy concern but increases the noise impact on the data.
}

\added{
Balancing utility and privacy in LDP clustering poses known challenges, often limited by information leaks and cluster algorithms only trained 2/3D datasets. Our research addresses these issues with realistic scenarios and data, aiming to establish a robust privacy framework for secure training of diverse clustering algorithms on distributed n-dimensional data.
}

\added{
 The objective of this work is to improve data clustering using the Geo-indistinguishability framework, a distance-optimized framework for differential privacy. In order to facilitate in training privacy-preserving clustering algorithms on distributed n-dimensional data, the thesis aims to extendÂ a privacy framework called nD-Laplace for clustering. Applying nD-Laplace to different clustering algorithms, introducing optimization approaches utilizing kd-tree, and proving its efficacy and privacy on real-world datasets and attacks are some of the key achievements. In order to do this, the following research question was created: \newline
\textit{How can the nD-Laplace mechanism be applied in training privacy-preserving clustering algorithms on distributed n-dimensional data?}
}

\added{
The research addresses three sub-questions, including adapting nD-Laplace for privacy-preserving clustering algorithms and grid-remapping noise within the data domain. It also investigates how dataset characteristics affect nD-Laplace's utility and privacy, with hypotheses related to data shape, dimensions, and density-based remapping.
To answer the questions, we conducted literature study and experiments to collect quantitative data. \newline
}

\added{
The experimental findings revealed that nD-Laplace achieved a high Adjusted Mutual Information (AMI) score at lower privacy budgets, particularly for real-world datasets. In contrast, the Piecewise mechanism exhibited better utility when applied to synthetic datasets, notably those with Line and Circle shapes. Additionally, there was an observed increase in AMI scores for dimensions exceeding 7. K-Means consistently outperformed other clustering algorithms for both mechanisms.
}
\added{
Regarding privacy, the results highlighted the significant influence of the privacy budget, with higher budgets enhancing utility but reducing privacy.
The privacy experiments also demonstrated substantial data leakage at lower privacy budgets, mitigated by remapping the data within the domain. Of the two remapping variants, grid-nD-Laplace exhibited greater stability. \newline
}

\added{
The research uncovered limitations in using nD-Laplace for using it with the \gls{optics} clustering algorithm due to its sensitivity to uniform noise from nD-Laplace. Limitations related to data dimensionality restricted the focus to 2D and 3D synthetic data, instead of including higher dimensions. Additionally, there was an emphasis on refining privacy metrics, as the current one failed to capture the most important privacy properties. Future work should delve deeper into nD-Laplace's adaptation to diverse data shapes, expand dimensionality beyond current limits, and enhance support for categorical and binary data for broader practical applications.
}
%Data has become a crucial part of our daily lives, with personal and sensitive information often sourced from various data sources. As businesses recognize the potential of data, the need for data protection has increased, leading to regulations like the GDPR and the privacy act. Unsupervised machine learning, such as clustering, is used to gain insights into data. 
%However, encryption is unsuitable for data analysis due to its communication overhead and unreadable nature. Anonymization methods have been explored, but they can still reveal personal information. Differential privacy, which adds noise to the original data to hide the actual value, is an effective way to preserve privacy while preserving data patterns. However, this method has limitations, such as leaking distance information and focusing on 2-dimensional synthetic datasets. The research aims to develop a privacy framework that enables secure training of various clustering algorithms on distributed n-dimensional data, addressing the shortcomings of previous studies and real-world dataset challenges. \newline

%This thesis aims to develop a new privacy framework for training clustering algorithms on distributed n-dimensional data. It aims to extend the use of \gls{gi} to optimize specifically the clustering of data. The proposed method relies on distance-based considerations, ensuring the shape and structure of the data are preserved during the clustering process. The thesis includes a research question titled "How can the nD-Laplace mechanism be applied in training privacy-preserving clustering algorithms on distributed n-dimensional data?" and a series of experiments using real-world datasets and synthetic datasets. The research uses both external and internal validation methods to assess the utility and privacy of the privacy mechanism. The qualitative data from these experiments is analyzed to compare various privacy mechanisms and their performance concerning clustering tasks.