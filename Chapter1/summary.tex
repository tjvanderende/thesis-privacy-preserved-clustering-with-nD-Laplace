\chapter{Summary}
Data has become a crucial part of our daily lives, with personal and sensitive information often sourced from various data sources. As businesses recognize the potential of data, the need for data protection has increased, leading to regulations like the GDPR and the privacy act. Unsupervised machine learning, such as clustering, is used to gain insights into data. However, encryption is unsuitable for data analysis due to its communication overhead and unreadable nature. Anonymization methods have been explored, but they can still reveal personal information. Differential privacy, which adds noise to the original data to hide the actual value, is an effective way to preserve privacy while preserving data patterns. However, this method has limitations, such as leaking distance information and focusing on 2-dimensional synthetic datasets. The research aims to develop a privacy framework that enables secure training of various clustering algorithms on distributed n-dimensional data, addressing the shortcomings of previous studies and real-world dataset challenges. \newline

This thesis aims to develop a new privacy framework for training clustering algorithms on distributed n-dimensional data. It aims to extend the use of \gls{gi} to optimize specifically the clustering of data. The proposed method relies on distance-based considerations, ensuring the shape and structure of the data are preserved during the clustering process. The thesis includes a research question titled "How can the nD-Laplace mechanism be applied in training privacy-preserving clustering algorithms on distributed n-dimensional data?" and a series of experiments using real-world datasets and synthetic datasets. The research uses both external and internal validation methods to assess the utility and privacy of the privacy mechanism. The qualitative data from these experiments is analyzed to compare various privacy mechanisms and their performance concerning clustering tasks.