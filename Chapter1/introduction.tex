\chapter{Introduction} \label{chapter:introduction}
Data has become an increasingly important part of our daily lives, and its applications are continuously growing.
Personal and sensitive information, such as scrolling through Facebook or Instagram, is often sourced from various structured and unstructured data origins.
As many businesses see the potential of data \citep{noauthor_global_nodate}, the urgency of protecting sensitive information also increases.
This development is why there have been several regulations regarding data and privacy. Therefore, the European Union created the GDPR \citep{noauthor_eur-lex_nodate}, and the United States created the privacy act \citep{division_privacy_2007}.
For instance, the GDPR describes in Article 34 that data should always be stored in an "incomprehensible way for unauthorized people".
Due to these regulations, it is challenging for companies to store and analyze data to gain insights.

A method for gaining insights into data is using unsupervised machine learning.
It can be used to find a structure or pattern in uncategorized data \citep{dridi_unsupervised_2021}.
Clustering is a type of unsupervised learning commonly applied to group similar data points and reveal patterns and structures \citep{dridi_unsupervised_2021}.
Cluster algorithms need to be trained on an adequate amount of historical data, so the data needs to be stored and processed in an accessible location.

A common solution for hiding data from unauthorized access is encryption.
Although this method is widely used for databases, it is unsuitable for data analysis.
The data is unreadable for examination, and it adds communication overhead \citep{liu_when_2022}.
For this reason, researchers have explored methods for anonymizing data to protect the privacy of individuals \citep{sweeney_k-anonymity_2002}.
But, this can still reveal much information about a person, as the range of possible values is limited.
A more effective way to preserve privacy is by using differential privacy.
This mechanism adds noise to the original data to hide the actual value, controlled by a privacy budget \citep{dwork_differential_2006}.
Due to the configurability of this mechanism, it is possible to trade off privacy and utility in such a way it is possible to preserve data patterns.
%The noise is added after saving all the data, making it vulnerable to data breaches. \newline
In recent years, the method was extended to add noise locally before sending it to a central server and called \gls{ldp} \citep{kasiviswanathan_what_2010}.
Although this method reduces privacy leakage risks because no plain data is stored on the server, the amount of data is limited in the local view.
This makes the noise more significant, impacting the data utility \citep{yang_local_2020}.

\newpage

\subsection*{Related work}
\todo[inline]{Tell something about other mechanisms}
The difficulty in preserving utility for clustering while preserving privacy is a well-known problem in the literature.
A study that focuses on preserving the cluster shapes sends the featureâ€™s distance information to the server instead of the feature value \citep{sun_distributed_2019}.
Their method works on multiple cluster algorithms, compared to other studies focusing on a single cluster algorithm.
However, their method leaks distance information. Another study aimed to improve this using a distance-aware randomization algorithm \cite{xia_distributed_2020}.
This study was extended by Huang et al. to reduce the difference between actual and perturbed values \citep{9679364}.
Both studies focus on K-means and \gls{ldp} but do not have direct support for other algorithms. \newline

Existing literature focuses primarily on K-Means, without considering different cluster algorithms.
Also, most of the work uses 2-dimensional synthetic, which is not representative of real-world data.
Due to this inflexibility and lack of practical testing in the current literature, developing a solution closer to practical applicability becomes essential.
Our research incorporates realistic attacks and datasets to test privacy and utility to bridge this gap and move towards a practically deployable \gls{ldp} mechanism.
Therefore, the overarching goal of this thesis is to develop a privacy framework that facilitates secure training of cluster algorithms on distributed n-dimensional data.

\subsection*{Research objective}
Another take on \gls{dp} is called \gls{gi} and is specifically used for geographical data  \citep{DBLP:journals/corr/abs-1212-1984}.
The 2D-Laplace mechanism adds noise to two data points (latitude/longitude) by generating random locations based on the amount of distance.
The mechanism is configurable by a privacy budget and holds within a radius of the original location.
An extension of this mechanism, called 3D-Laplace, added support for including the altitude to support indoor navigation \citep{9646489}.
The mechanism has also been extended to nD-Laplace to support n-dimensional data; however, its application focuses entirely on text vectors \citep{fernandes_generalised_2019}. \newline
Because the proposed method relies on distance-based considerations, it is plausible that the shape and structure of the data will be preserved during the clustering process.
Consequently, we expect this algorithm to perform well for data clustering tasks.
To our knowledge, \gls{gi} has never been previously applied for data clustering.
Therefore, the primary research objective of this study is to extend the use of \gls{gi} to optimize specifically the clustering of data. \newline

This thesis aims at developing a new privacy framework for training cluster algorithms on distributed n-dimensional data.
It does so by extending and optimizing the three variants of nD-Laplace to support cluster algorithms.
Our contribution to the current literature is as follows:
\begin{enumerate}
  \item We aim to create a new privacy framework named kd-Laplace using the three variants of Laplace to train privacy-preserving cluster algorithms on distributed n-dimensional data.
  \item In addition to K-means, we also demonstrate the working of our method on multiple other cluster algorithms.
  \item We introduce different optimization techniques to improve the utility of kd-Laplace using kd-tree.
  \item We demonstrate the privacy of kd-Laplace using real-world datasets and attacks.
\end{enumerate}

\subsection*{Research question and methods}
To reach our goals and objectives, we have formulated the following main question: \newline \newline
\textit{"How can the kD-Laplace algorithm be applied in training privacy-preserving clustering algorithms on distributed k-dimensional data?"} \newline

Much literature is consulted to answer this research question, and we experiment extensively to gather enough qualitative data.
Both external and internal validation methods are employed to assess the utility and privacy of the privacy mechanism.
The qualitative data from these experiments are analyzed to compare the different privacy mechanisms and their performance concerning clustering tasks.

\subsection*{Roadmap}
The first chapter is devoted to literature study and review.
We explain the various concepts related to clustering and differential privacy.
This chapter concludes with a literature review.
The second chapter explicitly focuses on the kd-Laplace part, explaining the relevant algorithms and concepts.
We then delve deeper into privacy attacks and how they can be evaluated. \newline
The following chapter is dedicated to describing the research itself and the methodology.
Subsequently, we present the results, and finally, we conclude with the discussion and conclusions.


