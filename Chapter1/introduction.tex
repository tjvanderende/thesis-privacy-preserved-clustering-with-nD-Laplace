\chapter{Introduction} \label{chapter:introduction}
Data has become an increasingly important part of our daily lives, and its applications are continuously growing.
Personal and sensitive information, such as scrolling through Facebook or Instagram, is often sourced from various structured and unstructured data origins.
As many businesses see the potential of data \citep{noauthor_global_nodate}, the urgency of protecting sensitive information also increases.
This development is why there have been several regulations regarding data and privacy.
Therefore, the European Union created the GDPR \citep{noauthor_eur-lex_nodate}, and the United States created the privacy act \citep{division_privacy_2007}.
For instance, Article 34 of the GDPR mandates that data should always be stored in a manner that is "incomprehensible to unauthorized individuals".
Due to these regulations, it is challenging for companies to store and analyze data to gain insights.

A method for gaining insights into data is using unsupervised machine learning.
It can be used to find a structure or pattern in uncategorized data \citep{dridi_unsupervised_2021}.
Clustering is a type of unsupervised learning commonly applied to group similar data points and reveal patterns and structures \citep{dridi_unsupervised_2021}.
Clustering algorithms need to be trained on an adequate amount of historical data, so the data needs to be stored and processed in an accessible location.

A common solution for hiding data from unauthorized access is encryption.
Although this method is widely used for databases, it is unsuitable for data analysis.
The data is unreadable for examination, and it adds communication overhead \citep{liu_when_2022}.
For this reason, researchers have explored methods for anonymizing data to protect the privacy of individuals \citep{sweeney_k-anonymity_2002}.
But, this can still reveal much information about a person, as the range of possible values is limited.
A more effective way to preserve privacy is by using differential privacy.
This mechanism adds noise to the original data to hide the actual value, controlled by a privacy budget \citep{dwork_differential_2006}.
Due to the configurability of this mechanism, it is possible to trade off privacy and utility in such a way it is possible to preserve data patterns.
%The noise is added after saving all the data, making it vulnerable to data breaches. \newline
In recent years, the method was extended to add noise locally before sending it to a central server and called \gls{ldp} \citep{kasiviswanathan_what_2010}.
Although this method reduces privacy leakage risks because no plain data is stored on the server, the amount of data is limited in the local view.
This makes the noise more significant, impacting the data utility \citep{yang_local_2020}.

\newpage

\subsection*{\replaced{Research context}{Related work}}
%\todo[inline]{Tell something about other mechanisms}
Preserving utility in clustering while ensuring privacy is a well-known challenge in the existing literature.
Previous studies have attempted to address this issue, with some focusing on preserving cluster shapes by sending feature distance information to the server rather than the feature values \citep{sun_distributed_2019}.
However, this method was found to leak distance information, compromising privacy.

Another line of research focused on improving privacy preservation using a distance-aware randomization algorithm proposed \citep{xia_distributed_2020}.
This approach was later extended by Huang et al. to minimize the difference between actual and perturbed values \citep{9679364}.
Nevertheless, these studies have a limited scope, mainly focusing on K-means and \gls{ldp} algorithms without directly supporting other clustering algorithms.

Moreover, the existing literature concentrates on using 2-dimensional synthetic datasets, which may not fully capture the complexity and diversity of real-world data.
This inflexibility and lack of practical testing in the current literature highlight the need for a more comprehensive solution with broader applicability.

Our research incorporates realistic attacks and datasets to assess privacy and utility to bridge this gap and move towards a practically deployable \gls{ldp} mechanism.
By doing so, we aim to develop a privacy framework that enables secure training of various clustering algorithms on distributed n-dimensional data.
By addressing the shortcomings of previous studies and considering the challenges posed by real-world datasets, our goal is to advance the field and facilitate the adoption of privacy-preserving clustering techniques in practical settings.

\subsection*{Research objective}
Another take on \gls{dp} is called \gls{gi} and is specifically used for geographical data  \citep{DBLP:journals/corr/abs-1212-1984}.
The 2D-Laplace mechanism adds noise to 2 data points (latitude/longitude) by generating random locations based on the amount of distance.
The mechanism is configurable by a privacy budget and holds within a radius of the original location.
An extension of this mechanism, 3D-Laplace, added support for including the altitude to support indoor navigation \citep{9646489}.
The mechanism has also been extended to nD-Laplace to support n-dimensional data; however, its application focuses entirely on text vectors \citep{fernandes_generalised_2019}. \newline
Because the proposed method relies on distance-based considerations, it is plausible that the shape and structure of the data will be preserved during the clustering process.
Consequently, we expect this algorithm to perform well for data clustering tasks.
To our knowledge, \gls{gi} has never been previously applied for data clustering.
Therefore, the primary research objective of this study is to extend the use of \gls{gi} to optimize specifically the clustering of data. \newline

This thesis aims at developing a new privacy framework for training clustering algorithms on distributed n-dimensional data.
It does so by extending and optimizing the three variants of nD-Laplace to support clustering algorithms.
Our contribution to the current literature is as follows:
\begin{enumerate}
  \item We aim to create a new privacy framework named nD-Laplace using the three variants of Laplace to train privacy-preserving clustering algorithms on distributed n-dimensional data.
  \item In addition to K-means, we also demonstrate the working of our method on multiple other clustering algorithms.
  \item We introduce different optimization techniques to improve the utility of nD-Laplace using kd-tree.
  \item We demonstrate the effectiveness and privacy of nD-Laplace using real-world datasets and attacks.
\end{enumerate}

\subsection*{Research question and methods}
To reach our goals and objectives, we have formulated the following main question: \newline \newline
\textit{"How can the nD-Laplace mechanism be applied in training privacy-preserving clustering algorithms on distributed n-dimensional data?"} \newline

\replaced{We review a significant amount of existing literature to address our research question and gather qualitative data for analysis. 
To acquire this qualitative data, we conduct a series of experiments that include both cluster utility and mechanism utility/privacy. These experiments are conducted using real-world datasets and synthetic datasets.

In order to ensure a comprehensive evaluation of utility, we utilize a combination of external and internal validation methods. For evaluating privacy we focus on real-world attacks to acquire quantitative information about the privacy for our mechanism.
By carefully analyzing the qualitative data from these experiments, we conduct a detailed comparison of various privacy mechanisms for both clustering and mechanism performance.}
{Much literature is consulted to answer this research question, and we experiment extensively to gather enough qualitative data. Both external and internal validation methods are employed to assess the utility and privacy of the privacy mechanism. The qualitative data from these experiments are analyzed to compare the different privacy mechanisms and their performance concerning clustering tasks.}

\subsection*{Roadmap}
The first chapter is devoted to literature study and review.
We explain the various concepts related to clustering and differential privacy.
This chapter concludes with a literature review.
The second chapter explicitly focuses on the nD-Laplace part, explaining the relevant algorithms and concepts.
We then delve deeper into privacy attacks and how they can be evaluated. \newline
The following chapter is dedicated to describing the research itself and the methodology.
Subsequently, we present the results, and finally, we conclude with the discussion and conclusions.


